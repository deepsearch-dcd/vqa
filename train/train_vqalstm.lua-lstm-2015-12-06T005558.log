[program started on Sun Dec  6 00:55:58 2015] 
[command line arguments] 
[----------------------] 
-------------------------------------------------------------------------------- 
LSTM for VQA 
-------------------------------------------------------------------------------- 
loading datasets 
process data at: /home/deepnet/lyt/vqa/dataset/data/DAQUAR/DAQUAR-ALL 
Process_all_totable ... 
load train set ... 
total lines: 13590 
max length: 31 min length: 7 
#images: 6795 #questions: 6795 #answers: 6795 
normalize image: 6808 
load test set ... 
total lines: 11346 
max length: 28 min length: 7 
#images: 5673 #questions: 5673 #answers: 5673 
normalize image: 5681 
build vocabulary ... 
word vocabulary: 856 
answer vocabulary: 969 
image vocabulary: 1447 
num train = 6795 
num test  = 5673 
loading features 
-------------------------------------------------------------------------------- 
model configuration 
-------------------------------------------------------------------------------- 
max epochs                = 70 
num params                = 867519 
num compositional params  = 721200 
word vector dim           = 50 
LSTM memory dim           = 150 
LSTM structure            = lstm 
LSTM layers               = 1 
regularization strength   = 1.00e-04 
minibatch size            = 1 
learning rate             = 5.00e-02 
word vector learning rate = 1.00e-01 
dropout                   = true 
cuda                      = true 
image feature dim         = 1000 
-------------------------------------------------------------------------------- 
Training model 
-------------------------------------------------------------------------------- 
-- epoch 1 
-- finished epoch in 75.72s 
-- train score: 0.040029433406917, cost 88.15s 
-- test score: 0.049709148598625, cost 73.22s 
-- epoch 2 
-- finished epoch in 76.29s 
-- train score: 0.040029433406917, cost 87.91s 
-- test score: 0.049709148598625, cost 73.12s 
-- epoch 3 
-- finished epoch in 74.59s 
-- train score: 0.040029433406917, cost 89.09s 
-- test score: 0.049709148598625, cost 73.74s 
-- epoch 4 
-- finished epoch in 73.74s 
-- train score: 0.043561442236939, cost 87.77s 
-- test score: 0.049885422175216, cost 73.03s 
-- epoch 5 
-- finished epoch in 73.90s 
-- train score: 0.047829286239882, cost 87.82s 
-- test score: 0.058170280274987, cost 75.53s 
-- epoch 6 
-- finished epoch in 75.97s 
-- train score: 0.084032376747609, cost 88.05s 
-- test score: 0.07703155297021, cost 72.80s 
-- epoch 7 
-- finished epoch in 74.65s 
-- train score: 0.093009565857248, cost 92.23s 
-- test score: 0.078618015159528, cost 76.39s 
-- epoch 8 
-- finished epoch in 82.26s 
-- train score: 0.10478292862399, cost 88.06s 
-- test score: 0.10629296668429, cost 72.80s 
-- epoch 9 
-- finished epoch in 73.65s 
-- train score: 0.11935246504783, cost 87.51s 
-- test score: 0.1196897585052, cost 72.78s 
-- epoch 10 
-- finished epoch in 74.64s 
-- train score: 0.14628403237675, cost 88.19s 
-- test score: 0.14190022915565, cost 73.27s 
-- epoch 11 
-- finished epoch in 75.10s 
-- train score: 0.16482707873436, cost 88.24s 
-- test score: 0.14630706857042, cost 73.08s 
-- epoch 12 
-- finished epoch in 74.00s 
-- train score: 0.18484179543782, cost 87.84s 
-- test score: 0.16463952053587, cost 73.10s 
-- epoch 13 
-- finished epoch in 73.97s 
-- train score: 0.2027961736571, cost 87.82s 
-- test score: 0.18402961396087, cost 73.50s 
-- epoch 14 
-- finished epoch in 73.95s 
-- train score: 0.22133922001472, cost 87.96s 
-- test score: 0.189141547682, cost 73.15s 
-- epoch 15 
-- finished epoch in 73.95s 
-- train score: 0.23340691685063, cost 87.85s 
-- test score: 0.19284329279041, cost 73.09s 
-- epoch 16 
-- finished epoch in 75.00s 
-- train score: 0.25342163355408, cost 88.44s 
-- test score: 0.20765027322404, cost 73.16s 
-- epoch 17 
-- finished epoch in 74.08s 
-- train score: 0.27446651949963, cost 87.76s 
-- test score: 0.21276220694518, cost 73.14s 
-- epoch 18 
-- finished epoch in 75.00s 
-- train score: 0.29506990434143, cost 88.63s 
-- test score: 0.21258593336859, cost 73.30s 
-- epoch 19 
-- finished epoch in 75.08s 
-- train score: 0.32582781456954, cost 88.59s 
-- test score: 0.20994182971973, cost 73.30s 
-- epoch 20 
-- finished epoch in 75.65s 
-- train score: 0.33215599705666, cost 88.72s 
-- test score: 0.21875550854927, cost 73.08s 
-- epoch 21 
-- finished epoch in 73.85s 
-- train score: 0.35540838852097, cost 88.90s 
-- test score: 0.21963687643222, cost 73.40s 
-- epoch 22 
-- finished epoch in 74.88s 
-- train score: 0.37777777777778, cost 88.09s 
-- test score: 0.21575885774722, cost 74.00s 
-- epoch 23 
-- finished epoch in 74.67s 
-- train score: 0.40058866813834, cost 88.21s 
-- test score: 0.21205711263882, cost 74.16s 
-- epoch 24 
-- finished epoch in 73.77s 
-- train score: 0.42281089036056, cost 87.74s 
-- test score: 0.220165697162, cost 72.98s 
-- epoch 25 
-- finished epoch in 74.66s 
-- train score: 0.42384105960265, cost 88.19s 
-- test score: 0.22034197073859, cost 72.96s 
-- epoch 26 
-- finished epoch in 75.62s 
-- train score: 0.46092715231788, cost 88.80s 
-- test score: 0.22175215935131, cost 72.85s 
-- epoch 27 
-- finished epoch in 73.72s 
-- train score: 0.4663723325975, cost 87.53s 
-- test score: 0.22351489511722, cost 72.78s 
-- epoch 28 
-- finished epoch in 73.88s 
-- train score: 0.48918322295806, cost 87.58s 
-- test score: 0.2199894235854, cost 74.00s 
-- epoch 29 
-- finished epoch in 74.87s 
-- train score: 0.51111111111111, cost 88.28s 
-- test score: 0.21505376344086, cost 72.89s 
-- epoch 30 
-- finished epoch in 73.85s 
-- train score: 0.52582781456954, cost 88.34s 
-- test score: 0.21223338621541, cost 73.52s 
-- epoch 31 
-- finished epoch in 74.96s 
-- train score: 0.5654157468727, cost 87.29s 
-- test score: 0.21293848052177, cost 75.02s 
-- epoch 32 
-- finished epoch in 73.95s 
-- train score: 0.573804267844, cost 87.48s 
-- test score: 0.21857923497268, cost 72.75s 
-- epoch 33 
-- finished epoch in 73.75s 
-- train score: 0.5888153053716, cost 87.41s 
-- test score: 0.21910805570245, cost 72.73s 
-- epoch 34 
-- finished epoch in 75.01s 
-- train score: 0.60014716703458, cost 89.32s 
-- test score: 0.21364357482813, cost 72.85s 
-- epoch 35 
-- finished epoch in 73.97s 
-- train score: 0.6186902133922, cost 87.60s 
-- test score: 0.20606381103473, cost 72.85s 
-- epoch 36 
-- finished epoch in 73.91s 
-- train score: 0.62855040470935, cost 87.55s 
-- test score: 0.21381984840472, cost 72.86s 
-- epoch 37 
-- finished epoch in 73.90s 
-- train score: 0.64724061810155, cost 87.60s 
-- test score: 0.21099947117927, cost 72.84s 
-- epoch 38 
-- finished epoch in 76.70s 
-- train score: 0.66195732155997, cost 91.72s 
-- test score: 0.20906046183677, cost 74.94s 
-- epoch 39 
-- finished epoch in 75.59s 
-- train score: 0.6691685062546, cost 87.57s 
-- test score: 0.21346730125154, cost 73.83s 
-- epoch 40 
-- finished epoch in 75.53s 
-- train score: 0.68844738778514, cost 87.61s 
-- test score: 0.20571126388154, cost 72.83s 
-- epoch 41 
-- finished epoch in 73.90s 
-- train score: 0.7074319352465, cost 87.57s 
-- test score: 0.2027146130795, cost 74.40s 
-- epoch 42 
-- finished epoch in 74.19s 
-- train score: 0.70919793966152, cost 90.66s 
-- test score: 0.21346730125154, cost 74.26s 
-- epoch 43 
-- finished epoch in 75.67s 
-- train score: 0.71891096394408, cost 89.73s 
-- test score: 0.21558258417063, cost 73.76s 
-- epoch 44 
-- finished epoch in 74.96s 
-- train score: 0.73701250919794, cost 89.26s 
-- test score: 0.20817909395382, cost 73.04s 
-- epoch 45 
-- finished epoch in 73.66s 
-- train score: 0.75055187637969, cost 87.87s 
-- test score: 0.20482989599859, cost 72.96s 
-- epoch 46 
-- finished epoch in 73.64s 
-- train score: 0.75055187637969, cost 87.77s 
-- test score: 0.20870791468359, cost 72.96s 
-- epoch 47 
-- finished epoch in 75.43s 
-- train score: 0.76144223693893, cost 88.69s 
-- test score: 0.20888418826018, cost 73.04s 
-- epoch 48 
-- finished epoch in 73.60s 
-- train score: 0.77557027225901, cost 87.81s 
-- test score: 0.20218579234973, cost 73.02s 
-- epoch 49 
-- finished epoch in 74.60s 
-- train score: 0.76085356880059, cost 88.25s 
-- test score: 0.20641635818791, cost 74.19s 
-- epoch 50 
-- finished epoch in 74.45s 
-- train score: 0.78219278881531, cost 88.31s 
-- test score: 0.20394852811564, cost 73.01s 
-- epoch 51 
-- finished epoch in 74.91s 
-- train score: 0.79278881530537, cost 88.00s 
-- test score: 0.20941300898995, cost 73.03s 
-- epoch 52 
-- finished epoch in 73.64s 
-- train score: 0.79632082413539, cost 87.80s 
-- test score: 0.20412480169223, cost 73.04s 
-- epoch 53 
-- finished epoch in 75.66s 
-- train score: 0.80412067696836, cost 87.77s 
-- test score: 0.204653622422, cost 72.96s 
-- epoch 54 
-- finished epoch in 73.68s 
-- train score: 0.81353936718175, cost 87.68s 
-- test score: 0.2027146130795, cost 72.96s 
-- epoch 55 
-- finished epoch in 73.54s 
-- train score: 0.81662987490802, cost 87.64s 
-- test score: 0.208531641107, cost 73.37s 
-- epoch 56 
-- finished epoch in 73.51s 
-- train score: 0.8139808682855, cost 88.77s 
-- test score: 0.19989423585405, cost 72.95s 
-- epoch 57 
-- finished epoch in 76.16s 
-- train score: 0.82796173657101, cost 89.73s 
-- test score: 0.19901286797109, cost 72.98s 
-- epoch 58 
-- finished epoch in 74.53s 
-- train score: 0.83355408388521, cost 92.49s 
-- test score: 0.20289088665609, cost 76.64s 
-- epoch 59 
-- finished epoch in 74.10s 
-- train score: 0.84429727740986, cost 90.30s 
-- test score: 0.20042305658382, cost 76.20s 
-- epoch 60 
-- finished epoch in 74.00s 
-- train score: 0.84591611479029, cost 87.65s 
-- test score: 0.19813150008814, cost 72.91s 
-- epoch 61 
-- finished epoch in 73.92s 
-- train score: 0.85268579838116, cost 87.68s 
-- test score: 0.19936541512427, cost 72.90s 
-- epoch 62 
-- finished epoch in 73.92s 
-- train score: 0.85960264900662, cost 87.64s 
-- test score: 0.19848404724132, cost 72.90s 
-- epoch 63 
-- finished epoch in 75.05s 
-- train score: 0.86534216335541, cost 91.02s 
-- test score: 0.19178565133087, cost 76.53s 
-- epoch 64 
-- finished epoch in 82.53s 
-- train score: 0.86681383370125, cost 91.34s 
-- test score: 0.19901286797109, cost 77.57s 
-- epoch 65 
-- finished epoch in 77.84s 
-- train score: 0.86799116997792, cost 91.91s 
-- test score: 0.200775603737, cost 76.47s 
-- epoch 66 
-- finished epoch in 82.17s 
-- train score: 0.87564385577631, cost 87.80s 
-- test score: 0.19249074563723, cost 72.97s 
-- epoch 67 
-- finished epoch in 73.69s 
-- train score: 0.86342899190581, cost 91.96s 
-- test score: 0.19566367001586, cost 76.16s 
-- epoch 68 
-- finished epoch in 82.03s 
-- train score: 0.87270051508462, cost 89.97s 
-- test score: 0.19848404724132, cost 75.53s 
-- epoch 69 
-- finished epoch in 82.04s 
-- train score: 0.87019867549669, cost 91.48s 
-- test score: 0.20218579234973, cost 73.85s 
-- epoch 70 
-- finished epoch in 74.69s 
-- train score: 0.8719646799117, cost 90.75s 
-- test score: 0.1910805570245, cost 76.24s 
finished training in 16622.54s 
best dev score is: 0.22351489511722 
writing model to ./done/vqalstm-lstm.l1.d150.e27.c1-2015-12-06T053302.t7 
