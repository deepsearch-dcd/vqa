[program started on Tue Dec  1 16:59:53 2015] 
[command line arguments] 
[----------------------] 
-------------------------------------------------------------------------------- 
LSTM for VQA 
-------------------------------------------------------------------------------- 
loading datasets 
process data at: /home/deepnet/lyt/vqa/dataset/data/DAQUAR/DAQUAR-ALL 
Process_all_totable ... 
load train set ... 
total lines: 13590 
max length: 31 min length: 7 
#images: 6795 #questions: 6795 #answers: 6795 
normalize image: 6808 
load test set ... 
total lines: 11346 
max length: 28 min length: 7 
#images: 5673 #questions: 5673 #answers: 5673 
normalize image: 5681 
build vocabulary ... 
word vocabulary: 856 
answer vocabulary: 969 
image vocabulary: 1447 
num train = 6795 
num test  = 5673 
loading features 
-------------------------------------------------------------------------------- 
model configuration 
-------------------------------------------------------------------------------- 
max epochs                = 100 
num params                = 347569 
num compositional params  = 201250 
word vector dim           = 50 
LSTM memory dim           = 150 
LSTM structure            = lstm 
LSTM layers               = 1 
regularization strength   = 1.00e-04 
minibatch size            = 1 
learning rate             = 5.00e-02 
word vector learning rate = 1.00e-01 
dropout                   = true 
cuda                      = true 
image feature dim         = 1000 
-------------------------------------------------------------------------------- 
Training model 
-------------------------------------------------------------------------------- 
-- epoch 1 
-- finished epoch in 71.02s 
-- train score: 0.042678440029433, cost 87.08s 
-- test score: 0.051471884364534, cost 72.47s 
-- epoch 2 
-- finished epoch in 72.62s 
-- train score: 0.049742457689478, cost 87.66s 
-- test score: 0.041248016922263, cost 72.94s 
-- epoch 3 
-- finished epoch in 71.20s 
-- train score: 0.046946284032377, cost 89.72s 
-- test score: 0.048298959985898, cost 70.73s 
-- epoch 4 
-- finished epoch in 71.97s 
-- train score: 0.054157468727005, cost 85.35s 
-- test score: 0.047417592102944, cost 70.28s 
-- epoch 5 
-- finished epoch in 69.48s 
-- train score: 0.057247976453274, cost 86.06s 
-- test score: 0.049180327868852, cost 70.25s 
-- epoch 6 
-- finished epoch in 69.57s 
-- train score: 0.06019131714496, cost 84.29s 
-- test score: 0.050590516481579, cost 70.24s 
-- epoch 7 
-- finished epoch in 69.55s 
-- train score: 0.061074319352465, cost 87.92s 
-- test score: 0.053234620130442, cost 70.06s 
-- epoch 8 
-- finished epoch in 69.32s 
-- train score: 0.059602649006623, cost 83.87s 
-- test score: 0.048298959985898, cost 69.88s 
-- epoch 9 
-- finished epoch in 69.18s 
-- train score: 0.062251655629139, cost 84.03s 
-- test score: 0.051295610787943, cost 69.96s 
-- epoch 10 
-- finished epoch in 69.21s 
-- train score: 0.063281824871229, cost 83.95s 
-- test score: 0.056407544509078, cost 69.90s 
-- epoch 11 
-- finished epoch in 69.41s 
-- train score: 0.065783664459161, cost 84.29s 
-- test score: 0.053234620130442, cost 70.22s 
-- epoch 12 
-- finished epoch in 69.53s 
-- train score: 0.070493009565857, cost 84.31s 
-- test score: 0.057641459545214, cost 70.22s 
-- epoch 13 
-- finished epoch in 69.69s 
-- train score: 0.1112582781457, cost 83.93s 
-- test score: 0.096069099242024, cost 69.98s 
-- epoch 14 
-- finished epoch in 69.19s 
-- train score: 0.10949227373068, cost 83.98s 
-- test score: 0.099947117927023, cost 69.96s 
-- epoch 15 
-- finished epoch in 69.25s 
-- train score: 0.11008094186902, cost 83.90s 
-- test score: 0.097655561431341, cost 69.90s 
-- epoch 16 
-- finished epoch in 69.12s 
-- train score: 0.11552612214864, cost 83.98s 
-- test score: 0.096069099242024, cost 70.05s 
-- epoch 17 
-- finished epoch in 69.26s 
-- train score: 0.12200147167035, cost 84.11s 
-- test score: 0.10453023091839, cost 70.05s 
-- epoch 18 
-- finished epoch in 69.39s 
-- train score: 0.13524650478293, cost 84.27s 
-- test score: 0.11845584346906, cost 70.17s 
-- epoch 19 
-- finished epoch in 69.34s 
-- train score: 0.1439293598234, cost 84.00s 
-- test score: 0.12903225806452, cost 70.02s 
-- epoch 20 
-- finished epoch in 69.53s 
-- train score: 0.1673289183223, cost 84.23s 
-- test score: 0.1313238145602, cost 70.10s 
-- epoch 21 
-- finished epoch in 69.60s 
-- train score: 0.16644591611479, cost 83.81s 
-- test score: 0.14225277630883, cost 69.83s 
-- epoch 22 
-- finished epoch in 69.35s 
-- train score: 0.1785136129507, cost 83.90s 
-- test score: 0.14789353075974, cost 69.94s 
-- epoch 23 
-- finished epoch in 69.23s 
-- train score: 0.18955114054452, cost 83.86s 
-- test score: 0.15582584170633, cost 69.83s 
-- epoch 24 
-- finished epoch in 69.15s 
-- train score: 0.19882266372333, cost 83.85s 
-- test score: 0.15371055878724, cost 69.88s 
-- epoch 25 
-- finished epoch in 69.13s 
-- train score: 0.21353936718175, cost 83.96s 
-- test score: 0.15988013396792, cost 69.96s 
-- epoch 26 
-- finished epoch in 69.15s 
-- train score: 0.2075055187638, cost 83.91s 
-- test score: 0.16569716199542, cost 69.89s 
-- epoch 27 
-- finished epoch in 69.54s 
-- train score: 0.21707137601177, cost 84.15s 
-- test score: 0.16199541688701, cost 70.01s 
-- epoch 28 
-- finished epoch in 69.56s 
-- train score: 0.1626195732156, cost 84.18s 
-- test score: 0.14383923849815, cost 70.06s 
-- epoch 29 
-- finished epoch in 69.53s 
-- train score: 0.24091243561442, cost 84.13s 
-- test score: 0.17080909571655, cost 70.08s 
-- epoch 30 
-- finished epoch in 69.29s 
-- train score: 0.24709345106696, cost 83.86s 
-- test score: 0.17063282213996, cost 69.84s 
-- epoch 31 
-- finished epoch in 69.17s 
-- train score: 0.26136865342163, cost 84.14s 
-- test score: 0.17627357659087, cost 70.07s 
-- epoch 32 
-- finished epoch in 69.19s 
-- train score: 0.28064753495217, cost 83.86s 
-- test score: 0.18244315177155, cost 69.84s 
-- epoch 33 
-- finished epoch in 69.19s 
-- train score: 0.29330389992642, cost 83.99s 
-- test score: 0.18032786885246, cost 69.97s 
-- epoch 34 
-- finished epoch in 69.51s 
-- train score: 0.29963208241354, cost 84.19s 
-- test score: 0.18402961396087, cost 70.09s 
-- epoch 35 
-- finished epoch in 69.56s 
-- train score: 0.30242825607064, cost 84.18s 
-- test score: 0.19390093424996, cost 70.06s 
-- epoch 36 
-- finished epoch in 69.48s 
-- train score: 0.32729948491538, cost 84.18s 
-- test score: 0.18596862330337, cost 70.09s 
-- epoch 37 
-- finished epoch in 69.49s 
-- train score: 0.34260485651214, cost 85.07s 
-- test score: 0.18561607615019, cost 71.12s 
-- epoch 38 
-- finished epoch in 69.47s 
-- train score: 0.35275938189845, cost 84.06s 
-- test score: 0.18790763264587, cost 70.08s 
-- epoch 39 
-- finished epoch in 69.34s 
-- train score: 0.36600441501104, cost 83.78s 
-- test score: 0.18596862330337, cost 69.73s 
-- epoch 40 
-- finished epoch in 69.25s 
-- train score: 0.36100073583517, cost 84.11s 
-- test score: 0.19460602855632, cost 70.07s 
-- epoch 41 
-- finished epoch in 69.27s 
-- train score: 0.3916114790287, cost 83.75s 
-- test score: 0.19654503789882, cost 69.83s 
-- epoch 42 
-- finished epoch in 69.06s 
-- train score: 0.39337748344371, cost 83.86s 
-- test score: 0.19213819848405, cost 69.72s 
-- epoch 43 
-- finished epoch in 69.37s 
-- train score: 0.37689477557027, cost 84.10s 
-- test score: 0.19055173629473, cost 70.06s 
-- epoch 44 
-- finished epoch in 69.21s 
-- train score: 0.38999264164827, cost 84.14s 
-- test score: 0.18808390622246, cost 70.08s 
-- epoch 45 
-- finished epoch in 69.35s 
-- train score: 0.43134657836645, cost 83.85s 
-- test score: 0.19548739643927, cost 69.93s 
-- epoch 46 
-- finished epoch in 69.35s 
-- train score: 0.44223693892568, cost 84.08s 
-- test score: 0.19196192490746, cost 69.97s 
-- epoch 47 
-- finished epoch in 69.47s 
-- train score: 0.45121412803532, cost 84.10s 
-- test score: 0.19918914154768, cost 70.07s 
-- epoch 48 
-- finished epoch in 69.29s 
-- train score: 0.45106696100074, cost 83.81s 
-- test score: 0.19636876432223, cost 69.80s 
-- epoch 49 
-- finished epoch in 69.28s 
-- train score: 0.47181751287712, cost 83.94s 
-- test score: 0.19566367001586, cost 69.87s 
-- epoch 50 
-- finished epoch in 69.28s 
-- train score: 0.34775570272259, cost 83.94s 
-- test score: 0.19160937775427, cost 69.94s 
-- epoch 51 
-- finished epoch in 69.20s 
-- train score: 0.45592347314202, cost 83.97s 
-- test score: 0.19918914154768, cost 69.95s 
-- epoch 52 
-- finished epoch in 69.20s 
-- train score: 0.50213392200147, cost 83.89s 
-- test score: 0.20218579234973, cost 69.89s 
-- epoch 53 
-- finished epoch in 69.47s 
-- train score: 0.51317144959529, cost 84.18s 
-- test score: 0.20059933016041, cost 70.05s 
-- epoch 54 
-- finished epoch in 69.66s 
-- train score: 0.51729212656365, cost 84.14s 
-- test score: 0.19866032081791, cost 70.04s 
-- epoch 55 
-- finished epoch in 69.61s 
-- train score: 0.52185430463576, cost 84.02s 
-- test score: 0.20183324519655, cost 70.04s 
-- epoch 56 
-- finished epoch in 69.61s 
-- train score: 0.49874908020603, cost 84.09s 
-- test score: 0.19636876432223, cost 70.05s 
-- epoch 57 
-- finished epoch in 70.23s 
-- train score: 0.54805003679176, cost 84.01s 
-- test score: 0.19266701921382, cost 69.95s 
-- epoch 58 
-- finished epoch in 69.40s 
-- train score: 0.55761589403974, cost 83.98s 
-- test score: 0.1988365943945, cost 69.91s 
-- epoch 59 
-- finished epoch in 69.51s 
-- train score: 0.53215599705666, cost 84.01s 
-- test score: 0.20130442446677, cost 69.97s 
-- epoch 60 
-- finished epoch in 69.46s 
-- train score: 0.5168506254599, cost 83.92s 
-- test score: 0.20095187731359, cost 69.93s 
-- epoch 61 
-- finished epoch in 69.59s 
-- train score: 0.58572479764533, cost 83.91s 
-- test score: 0.19848404724132, cost 86.75s 
-- epoch 62 
-- finished epoch in 69.44s 
-- train score: 0.53038999264165, cost 84.06s 
-- test score: 0.18896527410541, cost 70.05s 
-- epoch 63 
-- finished epoch in 69.57s 
-- train score: 0.56938925680648, cost 84.04s 
-- test score: 0.19196192490746, cost 70.08s 
-- epoch 64 
-- finished epoch in 69.53s 
-- train score: 0.62384105960265, cost 84.14s 
-- test score: 0.19742640578177, cost 70.05s 
-- epoch 65 
-- finished epoch in 69.46s 
-- train score: 0.63355408388521, cost 84.07s 
-- test score: 0.19196192490746, cost 70.09s 
-- epoch 66 
-- finished epoch in 69.53s 
-- train score: 0.61751287711553, cost 84.09s 
-- test score: 0.19037546271814, cost 70.05s 
-- epoch 67 
-- finished epoch in 71.62s 
-- train score: 0.65062545989698, cost 84.08s 
-- test score: 0.19848404724132, cost 70.00s 
-- epoch 68 
-- finished epoch in 69.57s 
-- train score: 0.51891096394408, cost 84.08s 
-- test score: 0.19390093424996, cost 70.04s 
-- epoch 69 
-- finished epoch in 69.60s 
-- train score: 0.61972038263429, cost 84.10s 
-- test score: 0.20218579234973, cost 69.99s 
-- epoch 70 
-- finished epoch in 69.48s 
-- train score: 0.66931567328918, cost 84.01s 
-- test score: 0.19601621716905, cost 69.94s 
-- epoch 71 
-- finished epoch in 69.54s 
-- train score: 0.66843267108168, cost 84.16s 
-- test score: 0.19531112286268, cost 70.08s 
-- epoch 72 
-- finished epoch in 69.48s 
-- train score: 0.68771155261221, cost 84.12s 
-- test score: 0.19319583994359, cost 70.04s 
-- epoch 73 
-- finished epoch in 69.64s 
-- train score: 0.68108903605592, cost 84.11s 
-- test score: 0.19249074563723, cost 70.04s 
-- epoch 74 
-- finished epoch in 69.50s 
-- train score: 0.67255334805004, cost 84.12s 
-- test score: 0.19442975497973, cost 70.08s 
-- epoch 75 
-- finished epoch in 69.70s 
-- train score: 0.68344370860927, cost 84.01s 
-- test score: 0.19160937775427, cost 70.01s 
-- epoch 76 
-- finished epoch in 69.60s 
-- train score: 0.67740986019132, cost 84.08s 
-- test score: 0.18843645337564, cost 70.04s 
-- epoch 77 
-- finished epoch in 69.63s 
-- train score: 0.68609271523179, cost 84.12s 
-- test score: 0.19319583994359, cost 70.10s 
-- epoch 78 
-- finished epoch in 69.65s 
-- train score: 0.73406916850625, cost 84.12s 
-- test score: 0.19284329279041, cost 70.05s 
-- epoch 79 
-- finished epoch in 69.60s 
-- train score: 0.69197939661516, cost 84.10s 
-- test score: 0.19143310417768, cost 70.03s 
-- epoch 80 
-- finished epoch in 69.67s 
-- train score: 0.72759381898455, cost 84.16s 
-- test score: 0.19407720782655, cost 70.06s 
-- epoch 81 
-- finished epoch in 69.59s 
-- train score: 0.693451066961, cost 84.22s 
-- test score: 0.1988365943945, cost 70.16s 
-- epoch 82 
-- finished epoch in 69.72s 
-- train score: 0.75467255334805, cost 84.17s 
-- test score: 0.19460602855632, cost 70.11s 
-- epoch 83 
-- finished epoch in 69.64s 
-- train score: 0.72788815305372, cost 84.23s 
-- test score: 0.19971796227745, cost 70.09s 
-- epoch 84 
-- finished epoch in 69.64s 
-- train score: 0.76247240618102, cost 84.18s 
-- test score: 0.19672131147541, cost 70.10s 
-- epoch 85 
-- finished epoch in 69.78s 
-- train score: 0.77895511405445, cost 84.18s 
-- test score: 0.19372466067337, cost 71.41s 
-- epoch 86 
-- finished epoch in 69.31s 
-- train score: 0.77542310522443, cost 84.04s 
-- test score: 0.19566367001586, cost 69.94s 
-- epoch 87 
-- finished epoch in 69.42s 
-- train score: 0.78175128771155, cost 83.87s 
-- test score: 0.19143310417768, cost 69.83s 
-- epoch 88 
-- finished epoch in 69.31s 
-- train score: 0.78233995584989, cost 83.86s 
-- test score: 0.18931782125859, cost 69.83s 
-- epoch 89 
-- finished epoch in 69.44s 
-- train score: 0.78704930095659, cost 83.99s 
-- test score: 0.18878900052882, cost 69.92s 
-- epoch 90 
-- finished epoch in 69.46s 
-- train score: 0.786902133922, cost 84.04s 
-- test score: 0.19760267935836, cost 69.96s 
-- epoch 91 
-- finished epoch in 69.45s 
-- train score: 0.73701250919794, cost 84.00s 
-- test score: 0.19601621716905, cost 69.99s 
-- epoch 92 
-- finished epoch in 69.39s 
-- train score: 0.80117733627667, cost 83.91s 
-- test score: 0.19566367001586, cost 69.86s 
-- epoch 93 
-- finished epoch in 69.55s 
-- train score: 0.80147167034584, cost 83.76s 
-- test score: 0.18949409483518, cost 69.81s 
-- epoch 94 
-- finished epoch in 69.40s 
-- train score: 0.81898454746137, cost 84.01s 
-- test score: 0.19002291556496, cost 69.95s 
-- epoch 95 
-- finished epoch in 69.33s 
-- train score: 0.78631346578366, cost 84.02s 
-- test score: 0.20042305658382, cost 69.97s 
-- epoch 96 
-- finished epoch in 69.53s 
-- train score: 0.78749080206034, cost 84.06s 
-- test score: 0.193019566367, cost 70.01s 
-- epoch 97 
-- finished epoch in 70.38s 
-- train score: 0.82457689477557, cost 83.89s 
-- test score: 0.19583994359246, cost 69.88s 
-- epoch 98 
-- finished epoch in 69.61s 
-- train score: 0.82545989698308, cost 83.88s 
-- test score: 0.18896527410541, cost 69.85s 
-- epoch 99 
-- finished epoch in 69.38s 
-- train score: 0.82693156732892, cost 83.90s 
-- test score: 0.19072800987132, cost 69.88s 
-- epoch 100 
-- finished epoch in 69.44s 
-- train score: 0.83134657836645, cost 83.93s 
-- test score: 0.18438216111405, cost 69.90s 
finished training in 22406.36s 
writing model to ./done/vqalstm-lstm.l1.d150.e52.c1-2015-12-01T231320.t7 
