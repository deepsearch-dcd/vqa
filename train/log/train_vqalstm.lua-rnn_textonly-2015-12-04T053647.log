[program started on Fri Dec  4 05:36:47 2015] 
[command line arguments] 
[----------------------] 
-------------------------------------------------------------------------------- 
LSTM for VQA with text only 
-------------------------------------------------------------------------------- 
loading datasets 
process data at: /home/deepnet/lyt/vqa/dataset/data/DAQUAR/DAQUAR-ALL 
Process_all_totable ... 
load train set ... 
total lines: 13590 
max length: 31 min length: 7 
#images: 6795 #questions: 6795 #answers: 6795 
normalize image: 6808 
load test set ... 
total lines: 11346 
max length: 28 min length: 7 
#images: 5673 #questions: 5673 #answers: 5673 
normalize image: 5681 
build vocabulary ... 
word vocabulary: 856 
answer vocabulary: 969 
image vocabulary: 1447 
num train = 6795 
num test  = 5673 
-------------------------------------------------------------------------------- 
model configuration 
-------------------------------------------------------------------------------- 
max epochs                = 70 
num params                = 176619 
num compositional params  = 30300 
word vector dim           = 50 
LSTM memory dim           = 150 
LSTM structure            = rnn 
LSTM layers               = 1 
regularization strength   = 1.00e-04 
minibatch size            = 1 
learning rate             = 5.00e-02 
word vector learning rate = 1.00e-01 
dropout                   = true 
cuda                      = true 
-------------------------------------------------------------------------------- 
Training model 
-------------------------------------------------------------------------------- 
-- epoch 1 
-- finished epoch in 17.66s 
-- train score: 0.032671081677704, cost 67.76s 
-- test score: 0.035078441741583, cost 55.44s 
-- epoch 2 
-- finished epoch in 17.33s 
-- train score: 0.022516556291391, cost 66.38s 
-- test score: 0.019566367001586, cost 55.30s 
-- epoch 3 
-- finished epoch in 17.02s 
-- train score: 0.042236938925681, cost 66.20s 
-- test score: 0.046183677066808, cost 55.23s 
-- epoch 4 
-- finished epoch in 17.00s 
-- train score: 0.065783664459161, cost 66.13s 
-- test score: 0.076679005817028, cost 55.15s 
-- epoch 5 
-- finished epoch in 17.05s 
-- train score: 0.092862398822664, cost 66.20s 
-- test score: 0.1061166931077, cost 55.24s 
-- epoch 6 
-- finished epoch in 16.97s 
-- train score: 0.10139808682855, cost 66.13s 
-- test score: 0.10646924026088, cost 55.15s 
-- epoch 7 
-- finished epoch in 16.99s 
-- train score: 0.11464311994113, cost 66.32s 
-- test score: 0.1099947117927, cost 55.34s 
-- epoch 8 
-- finished epoch in 17.03s 
-- train score: 0.14319352465048, cost 66.24s 
-- test score: 0.15071390798519, cost 55.26s 
-- epoch 9 
-- finished epoch in 17.05s 
-- train score: 0.14805003679176, cost 66.12s 
-- test score: 0.15124272871497, cost 55.20s 
-- epoch 10 
-- finished epoch in 16.97s 
-- train score: 0.15923473142016, cost 66.19s 
-- test score: 0.15335801163406, cost 55.24s 
-- epoch 11 
-- finished epoch in 17.04s 
-- train score: 0.16835908756439, cost 66.22s 
-- test score: 0.16587343557201, cost 55.26s 
-- epoch 12 
-- finished epoch in 16.96s 
-- train score: 0.18072111846946, cost 66.20s 
-- test score: 0.17098536929314, cost 55.23s 
-- epoch 13 
-- finished epoch in 16.97s 
-- train score: 0.18793230316409, cost 66.19s 
-- test score: 0.17327692578882, cost 55.23s 
-- epoch 14 
-- finished epoch in 17.02s 
-- train score: 0.19587932303164, cost 66.22s 
-- test score: 0.17415829367178, cost 55.24s 
-- epoch 15 
-- finished epoch in 17.01s 
-- train score: 0.19705665930831, cost 66.31s 
-- test score: 0.17927022739291, cost 55.32s 
-- epoch 16 
-- finished epoch in 17.00s 
-- train score: 0.20485651214128, cost 66.18s 
-- test score: 0.17662612374405, cost 55.26s 
-- epoch 17 
-- finished epoch in 16.99s 
-- train score: 0.21559970566593, cost 66.19s 
-- test score: 0.18032786885246, cost 55.20s 
-- epoch 18 
-- finished epoch in 17.04s 
-- train score: 0.23046357615894, cost 66.22s 
-- test score: 0.19090428344791, cost 55.23s 
-- epoch 19 
-- finished epoch in 17.00s 
-- train score: 0.23399558498896, cost 66.17s 
-- test score: 0.18843645337564, cost 55.18s 
-- epoch 20 
-- finished epoch in 16.99s 
-- train score: 0.24724061810155, cost 66.18s 
-- test score: 0.1910805570245, cost 55.25s 
-- epoch 21 
-- finished epoch in 16.98s 
-- train score: 0.25415746872701, cost 66.19s 
-- test score: 0.18261942534814, cost 55.20s 
-- epoch 22 
-- finished epoch in 17.02s 
-- train score: 0.25592347314202, cost 66.33s 
-- test score: 0.19002291556496, cost 55.28s 
-- epoch 23 
-- finished epoch in 17.02s 
-- train score: 0.26490066225166, cost 66.19s 
-- test score: 0.19583994359246, cost 55.20s 
-- epoch 24 
-- finished epoch in 16.98s 
-- train score: 0.27829286239882, cost 66.23s 
-- test score: 0.18438216111405, cost 55.26s 
-- epoch 25 
-- finished epoch in 17.00s 
-- train score: 0.29139072847682, cost 66.17s 
-- test score: 0.18755508549268, cost 55.21s 
-- epoch 26 
-- finished epoch in 17.00s 
-- train score: 0.29874908020603, cost 66.19s 
-- test score: 0.19160937775427, cost 55.20s 
-- epoch 27 
-- finished epoch in 17.00s 
-- train score: 0.28947755702723, cost 66.19s 
-- test score: 0.18967036841178, cost 55.23s 
-- epoch 28 
-- finished epoch in 16.99s 
-- train score: 0.31169977924945, cost 66.16s 
-- test score: 0.19601621716905, cost 55.23s 
-- epoch 29 
-- finished epoch in 16.94s 
-- train score: 0.32641648270787, cost 66.16s 
-- test score: 0.19143310417768, cost 55.21s 
-- epoch 30 
-- finished epoch in 17.01s 
-- train score: 0.34025018395879, cost 66.23s 
-- test score: 0.19002291556496, cost 55.23s 
-- epoch 31 
-- finished epoch in 17.06s 
-- train score: 0.32582781456954, cost 66.17s 
-- test score: 0.19513484928609, cost 55.21s 
-- epoch 32 
-- finished epoch in 17.05s 
-- train score: 0.34083885209713, cost 66.21s 
-- test score: 0.19249074563723, cost 55.23s 
-- epoch 33 
-- finished epoch in 17.02s 
-- train score: 0.35467255334805, cost 66.20s 
-- test score: 0.196897585052, cost 55.24s 
-- epoch 34 
-- finished epoch in 17.00s 
-- train score: 0.36100073583517, cost 66.34s 
-- test score: 0.18861272695223, cost 55.36s 
-- epoch 35 
-- finished epoch in 16.99s 
-- train score: 0.3757174392936, cost 66.16s 
-- test score: 0.19848404724132, cost 55.17s 
-- epoch 36 
-- finished epoch in 16.96s 
-- train score: 0.37718910963944, cost 66.18s 
-- test score: 0.19390093424996, cost 55.22s 
-- epoch 37 
-- finished epoch in 17.02s 
-- train score: 0.39102281089036, cost 66.21s 
-- test score: 0.19918914154768, cost 55.26s 
-- epoch 38 
-- finished epoch in 17.02s 
-- train score: 0.38543046357616, cost 66.22s 
-- test score: 0.18702626476291, cost 55.25s 
-- epoch 39 
-- finished epoch in 16.98s 
-- train score: 0.4019131714496, cost 66.15s 
-- test score: 0.19901286797109, cost 55.21s 
-- epoch 40 
-- finished epoch in 16.99s 
-- train score: 0.4047093451067, cost 66.16s 
-- test score: 0.19213819848405, cost 55.17s 
-- epoch 41 
-- finished epoch in 17.03s 
-- train score: 0.41059602649007, cost 66.21s 
-- test score: 0.19442975497973, cost 55.22s 
-- epoch 42 
-- finished epoch in 17.01s 
-- train score: 0.39970566593083, cost 66.18s 
-- test score: 0.19866032081791, cost 55.22s 
-- epoch 43 
-- finished epoch in 17.02s 
-- train score: 0.41986754966887, cost 66.16s 
-- test score: 0.19407720782655, cost 55.19s 
-- epoch 44 
-- finished epoch in 17.02s 
-- train score: 0.4317880794702, cost 66.19s 
-- test score: 0.19319583994359, cost 55.22s 
-- epoch 45 
-- finished epoch in 17.02s 
-- train score: 0.43281824871229, cost 66.22s 
-- test score: 0.19143310417768, cost 55.21s 
-- epoch 46 
-- finished epoch in 17.02s 
-- train score: 0.439293598234, cost 66.17s 
-- test score: 0.19354838709677, cost 55.23s 
-- epoch 47 
-- finished epoch in 17.03s 
-- train score: 0.45062545989698, cost 66.22s 
-- test score: 0.19160937775427, cost 55.24s 
-- epoch 48 
-- finished epoch in 17.01s 
-- train score: 0.45239146431199, cost 66.20s 
-- test score: 0.19372466067337, cost 55.19s 
-- epoch 49 
-- finished epoch in 17.04s 
-- train score: 0.44120676968359, cost 66.17s 
-- test score: 0.18843645337564, cost 55.23s 
-- epoch 50 
-- finished epoch in 17.01s 
-- train score: 0.467255334805, cost 66.20s 
-- test score: 0.185263528997, cost 55.23s 
-- epoch 51 
-- finished epoch in 17.01s 
-- train score: 0.46136865342163, cost 66.16s 
-- test score: 0.18843645337564, cost 55.20s 
-- epoch 52 
-- finished epoch in 17.03s 
-- train score: 0.47181751287712, cost 66.20s 
-- test score: 0.19619249074564, cost 55.21s 
-- epoch 53 
-- finished epoch in 17.01s 
-- train score: 0.47785136129507, cost 66.17s 
-- test score: 0.19231447206064, cost 55.23s 
-- epoch 54 
-- finished epoch in 17.03s 
-- train score: 0.48005886681383, cost 66.15s 
-- test score: 0.19037546271814, cost 55.19s 
-- epoch 55 
-- finished epoch in 17.00s 
-- train score: 0.49683590875644, cost 66.19s 
-- test score: 0.19354838709677, cost 55.20s 
-- epoch 56 
-- finished epoch in 17.02s 
-- train score: 0.49124356144224, cost 66.19s 
-- test score: 0.19460602855632, cost 55.23s 
-- epoch 57 
-- finished epoch in 17.02s 
-- train score: 0.49168506254599, cost 66.17s 
-- test score: 0.19196192490746, cost 55.22s 
-- epoch 58 
-- finished epoch in 17.00s 
-- train score: 0.5121412803532, cost 66.17s 
-- test score: 0.18508725542041, cost 55.23s 
-- epoch 59 
-- finished epoch in 17.02s 
-- train score: 0.50139808682855, cost 66.17s 
-- test score: 0.19918914154768, cost 55.20s 
-- epoch 60 
-- finished epoch in 17.02s 
-- train score: 0.51243561442237, cost 66.18s 
-- test score: 0.18773135906928, cost 55.22s 
-- epoch 61 
-- finished epoch in 17.02s 
-- train score: 0.51317144959529, cost 66.18s 
-- test score: 0.18878900052882, cost 55.22s 
-- epoch 62 
-- finished epoch in 17.01s 
-- train score: 0.51022810890361, cost 66.13s 
-- test score: 0.18773135906928, cost 55.19s 
-- epoch 63 
-- finished epoch in 18.71s 
-- train score: 0.52347314201619, cost 68.07s 
-- test score: 0.18790763264587, cost 57.11s 
-- epoch 64 
-- finished epoch in 19.28s 
-- train score: 0.52303164091244, cost 68.46s 
-- test score: 0.18896527410541, cost 57.10s 
-- epoch 65 
-- finished epoch in 19.27s 
-- train score: 0.52141280353201, cost 68.48s 
-- test score: 0.19390093424996, cost 57.11s 
-- epoch 66 
-- finished epoch in 19.26s 
-- train score: 0.53289183222958, cost 68.37s 
-- test score: 0.18684999118632, cost 57.05s 
-- epoch 67 
-- finished epoch in 19.25s 
-- train score: 0.53848417954378, cost 68.38s 
-- test score: 0.19213819848405, cost 57.03s 
-- epoch 68 
-- finished epoch in 19.25s 
-- train score: 0.4766740250184, cost 68.41s 
-- test score: 0.18596862330337, cost 57.03s 
-- epoch 69 
-- finished epoch in 19.25s 
-- train score: 0.53186166298749, cost 68.39s 
-- test score: 0.19178565133087, cost 57.02s 
-- epoch 70 
-- finished epoch in 19.26s 
-- train score: 0.53789551140545, cost 68.38s 
-- test score: 0.18508725542041, cost 57.05s 
finished training in 9743.49s 
writing model to ./done/vqalstm_textonly-rnn.l1.d150.e37.c1-2015-12-04T081911.t7 
