[program started on Thu Dec 31 02:46:14 2015] 
[command line arguments] 
[----------------------] 
-------------------------------------------------------------------------------- 
LSTM for VQA 
-------------------------------------------------------------------------------- 
loading COCOQA datasets 
Remove determiner done. 
num train = 78736 
num test  = 38948 
loading features 
-------------------------------------------------------------------------------- 
model configuration 
-------------------------------------------------------------------------------- 
max epochs                = 70 
num params                = 800530 
num compositional params  = 735600 
word vector dim           = 50 
LSTM memory dim           = 150 
LSTM structure            = lstm 
LSTM layers               = 1 
regularization strength   = 1.00e-04 
minibatch size            = 1 
learning rate             = 5.00e-02 
word vector learning rate = 1.00e-01 
dropout                   = true 
cuda                      = true 
image feature dim         = 1024 
-------------------------------------------------------------------------------- 
Training model 
-------------------------------------------------------------------------------- 
-- epoch 1 
-- finished epoch in 581.09s 
-- train score: 0.26028754318228, cost 511.25s 
-- test score: 0.24863921125603, cost 249.12s 
-- epoch 2 
-- finished epoch in 562.25s 
-- train score: 0.28454582401951, cost 504.45s 
-- test score: 0.27084831056794, cost 252.09s 
-- epoch 3 
-- finished epoch in 557.42s 
-- train score: 0.31210627921154, cost 504.33s 
-- test score: 0.2923641778782, cost 248.61s 
-- epoch 4 
-- finished epoch in 565.95s 
-- train score: 0.35953058321479, cost 503.93s 
-- test score: 0.33608914450036, cost 249.09s 
-- epoch 5 
-- finished epoch in 560.75s 
-- train score: 0.40419884169884, cost 503.03s 
-- test score: 0.37393447673822, cost 250.21s 
-- epoch 6 
-- finished epoch in 564.84s 
-- train score: 0.42843172119488, cost 503.33s 
-- test score: 0.39360172537743, cost 248.09s 
-- epoch 7 
-- finished epoch in 552.88s 
-- train score: 0.44341851249746, cost 504.40s 
-- test score: 0.40163808154462, cost 248.74s 
-- epoch 8 
-- finished epoch in 557.12s 
-- train score: 0.45514123145702, cost 503.86s 
-- test score: 0.41088117489987, cost 248.67s 
-- epoch 9 
-- finished epoch in 567.66s 
-- train score: 0.46095813858972, cost 505.76s 
-- test score: 0.41270411831159, cost 248.64s 
-- epoch 10 
-- finished epoch in 557.83s 
-- train score: 0.48416226376753, cost 507.74s 
-- test score: 0.42990654205607, cost 250.85s 
-- epoch 11 
-- finished epoch in 561.87s 
-- train score: 0.50232422271896, cost 505.97s 
-- test score: 0.44787922358016, cost 248.73s 
-- epoch 12 
-- finished epoch in 564.30s 
-- train score: 0.52076559642349, cost 504.30s 
-- test score: 0.45927903871829, cost 250.49s 
-- epoch 13 
-- finished epoch in 561.72s 
-- train score: 0.5326407234302, cost 507.40s 
-- test score: 0.47106398274623, cost 252.27s 
-- epoch 14 
-- finished epoch in 557.69s 
-- train score: 0.54630664499086, cost 504.84s 
-- test score: 0.4783044058745, cost 249.00s 
-- epoch 15 
-- finished epoch in 563.64s 
-- train score: 0.55995986588092, cost 502.51s 
-- test score: 0.48610968470782, cost 248.24s 
-- epoch 16 
-- finished epoch in 559.56s 
-- train score: 0.56771997561471, cost 514.14s 
-- test score: 0.49150148916504, cost 255.02s 
-- epoch 17 
-- finished epoch in 568.59s 
-- train score: 0.57683905710221, cost 502.14s 
-- test score: 0.49612303584266, cost 248.06s 
-- epoch 18 
-- finished epoch in 554.35s 
-- train score: 0.58558981914245, cost 502.33s 
-- test score: 0.50046215466776, cost 247.96s 
-- epoch 19 
-- finished epoch in 565.60s 
-- train score: 0.59224497053444, cost 509.47s 
-- test score: 0.50241347437609, cost 248.85s 
-- epoch 20 
-- finished epoch in 557.62s 
-- train score: 0.59945895143264, cost 501.39s 
-- test score: 0.50690664475711, cost 247.86s 
-- epoch 21 
-- finished epoch in 557.53s 
-- train score: 0.60937817516765, cost 501.61s 
-- test score: 0.51055253158057, cost 247.88s 
-- epoch 22 
-- finished epoch in 556.23s 
-- train score: 0.61515698028856, cost 502.44s 
-- test score: 0.51188764506522, cost 247.85s 
-- epoch 23 
-- finished epoch in 560.11s 
-- train score: 0.6197419223735, cost 501.31s 
-- test score: 0.51396734107014, cost 247.79s 
-- epoch 24 
-- finished epoch in 567.48s 
-- train score: 0.62470788457631, cost 505.42s 
-- test score: 0.51445517099723, cost 248.84s 
-- epoch 25 
-- finished epoch in 554.62s 
-- train score: 0.62823867100183, cost 502.79s 
-- test score: 0.5169713464106, cost 248.97s 
-- epoch 26 
-- finished epoch in 570.74s 
-- train score: 0.6335856533225, cost 503.36s 
-- test score: 0.51707404744788, cost 252.11s 
-- epoch 27 
-- finished epoch in 565.08s 
-- train score: 0.64022810404389, cost 505.04s 
-- test score: 0.52015507856629, cost 253.23s 
-- epoch 28 
-- finished epoch in 555.95s 
-- train score: 0.64394940052835, cost 504.85s 
-- test score: 0.51925644449009, cost 251.03s 
-- epoch 29 
-- finished epoch in 560.34s 
-- train score: 0.64204429993904, cost 505.00s 
-- test score: 0.51730512478176, cost 249.35s 
-- epoch 30 
-- finished epoch in 557.50s 
-- train score: 0.64664194269457, cost 507.35s 
-- test score: 0.5205402074561, cost 250.24s 
-- epoch 31 
-- finished epoch in 556.55s 
-- train score: 0.65023623247307, cost 504.31s 
-- test score: 0.52020642908493, cost 248.10s 
-- epoch 32 
-- finished epoch in 561.98s 
-- train score: 0.65986334078439, cost 511.82s 
-- test score: 0.52462257368799, cost 248.89s 
-- epoch 33 
-- finished epoch in 565.87s 
-- train score: 0.66881731355416, cost 510.18s 
-- test score: 0.52451987265071, cost 248.50s 
-- epoch 34 
-- finished epoch in 554.41s 
-- train score: 0.67103993090835, cost 501.75s 
-- test score: 0.52744685221321, cost 247.92s 
-- epoch 35 
-- finished epoch in 560.03s 
-- train score: 0.67434210526316, cost 502.93s 
-- test score: 0.52906439355037, cost 248.64s 
-- epoch 36 
-- finished epoch in 556.23s 
-- train score: 0.676983844747, cost 502.30s 
-- test score: 0.52978330081134, cost 248.23s 
-- epoch 37 
-- finished epoch in 558.88s 
-- train score: 0.6847312538102, cost 503.30s 
-- test score: 0.5301170791825, cost 249.80s 
-- epoch 38 
-- finished epoch in 563.01s 
-- train score: 0.68330877870352, cost 506.88s 
-- test score: 0.53104138851802, cost 250.46s 
-- epoch 39 
-- finished epoch in 568.27s 
-- train score: 0.69004013411908, cost 504.27s 
-- test score: 0.53250487829927, cost 248.86s 
-- epoch 40 
-- finished epoch in 565.51s 
-- train score: 0.7010516155253, cost 509.10s 
-- test score: 0.53155489370443, cost 250.00s 
-- epoch 41 
-- finished epoch in 562.29s 
-- train score: 0.70027687461898, cost 502.47s 
-- test score: 0.53265892985519, cost 247.73s 
-- epoch 42 
-- finished epoch in 551.42s 
-- train score: 0.70639859784597, cost 501.51s 
-- test score: 0.53150354318579, cost 247.90s 
-- epoch 43 
-- finished epoch in 554.19s 
-- train score: 0.70929435074172, cost 503.75s 
-- test score: 0.53425079593304, cost 249.41s 
-- epoch 44 
-- finished epoch in 562.94s 
-- train score: 0.7151493598862, cost 501.70s 
-- test score: 0.53299270822635, cost 249.35s 
-- epoch 45 
-- finished epoch in 555.83s 
-- train score: 0.71789270473481, cost 502.62s 
-- test score: 0.53612508986341, cost 248.33s 
-- epoch 46 
-- finished epoch in 567.78s 
-- train score: 0.72228713676082, cost 503.78s 
-- test score: 0.53383999178392, cost 248.26s 
-- epoch 47 
-- finished epoch in 564.81s 
-- train score: 0.7240017272912, cost 501.52s 
-- test score: 0.5340710691178, cost 247.80s 
-- epoch 48 
-- finished epoch in 564.37s 
-- train score: 0.72947571631782, cost 505.57s 
-- test score: 0.53373729074664, cost 248.78s 
-- epoch 49 
