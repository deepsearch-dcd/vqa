[program started on Tue Jan 19 16:55:53 2016] 
[command line arguments] 
[----------------------] 
-------------------------------------------------------------------------------- 
LSTM for VQA 
-------------------------------------------------------------------------------- 
loading COCOQA datasets 
Remove determiner done. 
loading features 
num train = 78736 
num test  = 38948 
-------------------------------------------------------------------------------- 
model configuration 
-------------------------------------------------------------------------------- 
max epochs                = 100 
num params                = 786130 
num compositional params  = 721200 
word vector dim           = 50 
LSTM memory dim           = 150 
LSTM structure            = lstm 
LSTM layers               = 1 
regularization strength   = 1.00e-04 
minibatch size            = 1 
learning rate             = 5.00e-02 
word vector learning rate = 1.00e-01 
dropout                   = true 
cuda                      = true 
image feature dim         = 1000 
-------------------------------------------------------------------------------- 
Training model 
-------------------------------------------------------------------------------- 
-- epoch 1 
-- finished epoch in 1397.42s 
-- train score: 0.41100640113798, cost 912.65s 
-- test score: 0.39090582314881, cost 447.99s 
-- epoch 2 
-- finished epoch in 1329.61s 
-- train score: 0.46310455192034, cost 903.98s 
-- test score: 0.43285919687789, cost 446.59s 
-- epoch 3 
-- finished epoch in 1346.79s 
-- train score: 0.50142247510669, cost 995.97s 
-- test score: 0.45419533737291, cost 491.88s 
-- epoch 4 
-- finished epoch in 1354.30s 
-- train score: 0.52409317211949, cost 996.05s 
-- test score: 0.46574920406696, cost 492.02s 
-- epoch 5 
-- finished epoch in 1368.19s 
-- train score: 0.54456665311928, cost 996.85s 
-- test score: 0.47252747252747, cost 492.55s 
-- epoch 6 
-- finished epoch in 1355.64s 
-- train score: 0.55505740703109, cost 996.91s 
-- test score: 0.47524905001541, cost 492.76s 
-- epoch 7 
-- finished epoch in 1353.94s 
-- train score: 0.5735622840886, cost 997.19s 
-- test score: 0.48243812262504, cost 492.15s 
-- epoch 8 
-- finished epoch in 1353.08s 
-- train score: 0.58558981914245, cost 996.20s 
-- test score: 0.48554482900277, cost 492.02s 
-- epoch 9 
-- finished epoch in 1352.81s 
-- train score: 0.59775706157285, cost 970.71s 
-- test score: 0.48641778781966, cost 481.41s 
-- epoch 10 
-- finished epoch in 1353.34s 
-- train score: 0.60815891079049, cost 941.83s 
-- test score: 0.48888261271439, cost 449.42s 
-- epoch 11 
-- finished epoch in 1331.17s 
-- train score: 0.61868776671408, cost 907.91s 
-- test score: 0.48867721063983, cost 448.54s 
-- epoch 12 
-- finished epoch in 1340.92s 
-- train score: 0.62458087787035, cost 908.62s 
-- test score: 0.48895963849235, cost 448.51s 
-- epoch 13 
-- finished epoch in 1329.02s 
-- train score: 0.63811979272506, cost 906.92s 
-- test score: 0.49060285508884, cost 447.99s 
-- epoch 14 
-- finished epoch in 1329.80s 
-- train score: 0.64543537898801, cost 907.34s 
-- test score: 0.48877991167711, cost 448.84s 
-- epoch 15 
-- finished epoch in 1331.32s 
-- train score: 0.65253505385084, cost 906.93s 
-- test score: 0.48842045804663, cost 477.92s 
-- epoch 16 
-- finished epoch in 1353.71s 
-- train score: 0.65991414346678, cost 997.13s 
-- test score: 0.48818938071275, cost 493.94s 
-- epoch 17 
-- finished epoch in 1356.94s 
-- train score: 0.66903322495428, cost 998.14s 
-- test score: 0.49070555612612, cost 494.01s 
-- epoch 18 
-- finished epoch in 1357.68s 
-- train score: 0.67402458849827, cost 1000.02s 
-- test score: 0.49134743760912, cost 493.96s 
-- epoch 19 
-- finished epoch in 1359.07s 
-- train score: 0.67913025807763, cost 999.28s 
-- test score: 0.49391496354113, cost 493.88s 
-- epoch 20 
-- finished epoch in 1355.81s 
-- train score: 0.68656015037594, cost 1000.22s 
-- test score: 0.49011502516175, cost 493.97s 
-- epoch 21 
-- finished epoch in 1355.73s 
-- train score: 0.68488366185735, cost 998.69s 
-- test score: 0.49021772619903, cost 493.47s 
-- epoch 22 
-- finished epoch in 1355.56s 
-- train score: 0.69885439951229, cost 973.42s 
-- test score: 0.49109068501592, cost 479.08s 
-- epoch 23 
-- finished epoch in 1353.80s 
-- train score: 0.69929892298313, cost 996.79s 
-- test score: 0.49057717982952, cost 492.55s 
-- epoch 24 
-- finished epoch in 1353.23s 
-- train score: 0.70525553749238, cost 997.07s 
-- test score: 0.49165554072096, cost 492.94s 
-- epoch 25 
-- finished epoch in 1353.18s 
-- train score: 0.70811318837635, cost 998.20s 
-- test score: 0.49155283968368, cost 493.21s 
-- epoch 26 
-- finished epoch in 1354.22s 
-- train score: 0.71602570615729, cost 997.85s 
-- test score: 0.4910650097566, cost 492.98s 
-- epoch 27 
-- finished epoch in 1354.32s 
-- train score: 0.72318888437309, cost 949.22s 
-- test score: 0.48803532915682, cost 448.25s 
-- epoch 28 
-- finished epoch in 1329.30s 
-- train score: 0.72729120097541, cost 908.50s 
-- test score: 0.48939611790079, cost 448.98s 
-- epoch 29 
-- finished epoch in 1340.80s 
-- train score: 0.73261278195489, cost 978.57s 
-- test score: 0.49044880353292, cost 490.47s 
-- epoch 30 
-- finished epoch in 1350.89s 
-- train score: 0.73253657793131, cost 996.86s 
-- test score: 0.48931909212283, cost 491.30s 
-- epoch 31 
-- finished epoch in 1351.29s 
-- train score: 0.73681670392197, cost 996.57s 
-- test score: 0.48628941152306, cost 492.69s 
-- epoch 32 
-- finished epoch in 1352.20s 
-- train score: 0.738950416582, cost 997.13s 
-- test score: 0.48415836499949, cost 492.80s 
-- epoch 33 
-- finished epoch in 1356.55s 
-- train score: 0.74635490753912, cost 998.13s 
-- test score: 0.48539077744685, cost 493.02s 
-- epoch 34 
-- finished epoch in 1355.03s 
-- train score: 0.75317516764885, cost 996.39s 
-- test score: 0.48798397863818, cost 492.91s 
-- epoch 35 
