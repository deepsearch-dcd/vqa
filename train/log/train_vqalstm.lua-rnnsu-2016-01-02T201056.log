[program started on Sat Jan  2 20:10:56 2016] 
[command line arguments] 
[----------------------] 
-------------------------------------------------------------------------------- 
LSTM for VQA 
-------------------------------------------------------------------------------- 
loading COCOQA datasets 
Remove determiner done. 
loading features 
num train = 78736 
num test  = 38948 
-------------------------------------------------------------------------------- 
model configuration 
-------------------------------------------------------------------------------- 
max epochs                = 80 
num params                = 226180 
num compositional params  = 161250 
word vector dim           = 50 
LSTM memory dim           = 150 
LSTM structure            = rnnsu 
LSTM layers               = 1 
regularization strength   = 1.00e-04 
minibatch size            = 1 
learning rate             = 5.00e-02 
word vector learning rate = 1.00e-01 
dropout                   = true 
cuda                      = true 
image feature dim         = 1024 
-------------------------------------------------------------------------------- 
Training model 
-------------------------------------------------------------------------------- 
-- epoch 1 
-- finished epoch in 164.42s 
-- train score: 0.14619741922374, cost 363.52s 
-- test score: 0.14534764301119, cost 179.82s 
-- epoch 2 
-- finished epoch in 146.57s 
-- train score: 0.21440002032107, cost 362.84s 
-- test score: 0.21354113176543, cost 179.31s 
-- epoch 3 
-- finished epoch in 146.19s 
-- train score: 0.23502590936801, cost 364.42s 
-- test score: 0.22981924617439, cost 177.93s 
-- epoch 4 
-- finished epoch in 150.77s 
-- train score: 0.25449603739077, cost 371.34s 
-- test score: 0.24699599465955, cost 183.34s 
-- epoch 5 
-- finished epoch in 148.89s 
-- train score: 0.27358514529567, cost 364.80s 
-- test score: 0.26509705248023, cost 180.62s 
-- epoch 6 
-- finished epoch in 146.06s 
-- train score: 0.29268695387116, cost 360.32s 
-- test score: 0.28414809489576, cost 179.44s 
-- epoch 7 
-- finished epoch in 147.91s 
-- train score: 0.31967587888641, cost 364.70s 
-- test score: 0.30191537434528, cost 178.00s 
-- epoch 8 
-- finished epoch in 149.40s 
-- train score: 0.33786323917903, cost 371.82s 
-- test score: 0.31390572044778, cost 181.26s 
-- epoch 9 
-- finished epoch in 151.23s 
-- train score: 0.34804917699655, cost 362.64s 
-- test score: 0.3222245044675, cost 176.34s 
-- epoch 10 
-- finished epoch in 151.13s 
-- train score: 0.36528398699451, cost 364.42s 
-- test score: 0.33393242271747, cost 179.43s 
-- epoch 11 
-- finished epoch in 152.03s 
-- train score: 0.37591444828287, cost 369.48s 
-- test score: 0.34207147992195, cost 183.05s 
-- epoch 12 
-- finished epoch in 153.40s 
-- train score: 0.38509703312335, cost 359.99s 
-- test score: 0.34818219164014, cost 177.77s 
-- epoch 13 
-- finished epoch in 151.00s 
-- train score: 0.39652763665922, cost 359.35s 
-- test score: 0.35483208380405, cost 177.34s 
-- epoch 14 
-- finished epoch in 144.41s 
-- train score: 0.40633255435887, cost 361.43s 
-- test score: 0.36122522337476, cost 178.55s 
-- epoch 15 
-- finished epoch in 143.89s 
-- train score: 0.41749644381223, cost 359.36s 
-- test score: 0.36392112560337, cost 185.62s 
-- epoch 16 
-- finished epoch in 145.77s 
-- train score: 0.42689494005283, cost 368.81s 
-- test score: 0.36879942487419, cost 177.54s 
-- epoch 17 
-- finished epoch in 149.82s 
-- train score: 0.43525198130461, cost 365.30s 
-- test score: 0.37378042518229, cost 180.23s 
-- epoch 18 
-- finished epoch in 151.80s 
-- train score: 0.44325340377972, cost 369.59s 
-- test score: 0.37616822429907, cost 179.54s 
-- epoch 19 
-- finished epoch in 147.70s 
-- train score: 0.45529363950417, cost 364.59s 
-- test score: 0.37973708534456, cost 178.21s 
-- epoch 20 
-- finished epoch in 147.35s 
-- train score: 0.45627159114001, cost 363.25s 
-- test score: 0.38138030194105, cost 180.28s 
-- epoch 21 
-- finished epoch in 143.79s 
-- train score: 0.4681975208291, cost 361.89s 
-- test score: 0.38587347232207, cost 177.86s 
-- epoch 22 
-- finished epoch in 149.56s 
-- train score: 0.4726173541963, cost 359.95s 
-- test score: 0.38918558077437, cost 177.23s 
-- epoch 23 
-- finished epoch in 141.29s 
-- train score: 0.47878988010567, cost 361.75s 
-- test score: 0.38972476122009, cost 177.88s 
-- epoch 24 
-- finished epoch in 154.50s 
-- train score: 0.48762954684007, cost 369.55s 
-- test score: 0.39393550374859, cost 177.97s 
-- epoch 25 
-- finished epoch in 147.86s 
-- train score: 0.49016968095915, cost 481.86s 
-- test score: 0.39706788538564, cost 247.47s 
-- epoch 26 
-- finished epoch in 149.17s 
-- train score: 0.49630410485674, cost 540.86s 
-- test score: 0.39670843175516, cost 245.51s 
-- epoch 27 
-- finished epoch in 163.88s 
-- train score: 0.50445793537899, cost 541.98s 
-- test score: 0.40086782376502, cost 246.25s 
-- epoch 28 
-- finished epoch in 164.13s 
-- train score: 0.50584230847389, cost 543.45s 
-- test score: 0.39968676183629, cost 247.43s 
-- epoch 29 
-- finished epoch in 164.66s 
-- train score: 0.5140977443609, cost 543.66s 
-- test score: 0.40289616925131, cost 246.70s 
-- epoch 30 
-- finished epoch in 189.63s 
-- train score: 0.51774283682178, cost 527.26s 
-- test score: 0.40433398377324, cost 246.17s 
-- epoch 31 
-- finished epoch in 217.25s 
-- train score: 0.52228967689494, cost 506.77s 
-- test score: 0.40374345280887, cost 245.66s 
-- epoch 32 
-- finished epoch in 230.83s 
-- train score: 0.5276620605568, cost 493.46s 
-- test score: 0.4053096436274, cost 248.63s 
-- epoch 33 
-- finished epoch in 218.10s 
-- train score: 0.5323613086771, cost 493.51s 
-- test score: 0.40731231385437, cost 256.91s 
-- epoch 34 
-- finished epoch in 205.89s 
-- train score: 0.53661603332656, cost 497.03s 
-- test score: 0.40872445311698, cost 273.41s 
-- epoch 35 
-- finished epoch in 192.34s 
-- train score: 0.53952448689291, cost 498.24s 
-- test score: 0.40836499948649, cost 291.53s 
-- epoch 36 
-- finished epoch in 162.52s 
-- train score: 0.54450314976631, cost 496.61s 
-- test score: 0.40928930882202, cost 291.45s 
-- epoch 37 
-- finished epoch in 164.10s 
-- train score: 0.54816094289779, cost 496.79s 
-- test score: 0.4097771387491, cost 292.23s 
-- epoch 38 
-- finished epoch in 162.44s 
-- train score: 0.55092968908758, cost 516.49s 
-- test score: 0.41090685015919, cost 272.22s 
-- epoch 39 
-- finished epoch in 162.27s 
-- train score: 0.55811826864458, cost 542.96s 
-- test score: 0.41329464927596, cost 246.04s 
-- epoch 40 
-- finished epoch in 162.25s 
-- train score: 0.55942643771591, cost 543.64s 
-- test score: 0.4130892472014, cost 245.99s 
-- epoch 41 
-- finished epoch in 165.46s 
-- train score: 0.5641510871774, cost 541.62s 
-- test score: 0.41581082468933, cost 246.81s 
-- epoch 42 
-- finished epoch in 163.80s 
-- train score: 0.56873602926235, cost 542.27s 
-- test score: 0.41514326794701, cost 246.23s 
-- epoch 43 
-- finished epoch in 164.93s 
-- train score: 0.57193659825239, cost 545.59s 
-- test score: 0.41468111327924, cost 244.03s 
-- epoch 44 
-- finished epoch in 157.66s 
-- train score: 0.56985368827474, cost 540.62s 
-- test score: 0.41565677313341, cost 244.00s 
-- epoch 45 
-- finished epoch in 158.94s 
-- train score: 0.57626752692542, cost 543.06s 
-- test score: 0.4170432371367, cost 246.32s 
-- epoch 46 
-- finished epoch in 170.30s 
-- train score: 0.58000152408047, cost 543.41s 
-- test score: 0.41504056690973, cost 246.10s 
-- epoch 47 
-- finished epoch in 203.84s 
-- train score: 0.58207173338752, cost 518.85s 
-- test score: 0.41727431447058, cost 245.97s 
-- epoch 48 
-- finished epoch in 227.88s 
-- train score: 0.58581843121317, cost 501.79s 
-- test score: 0.41791619595358, cost 248.01s 
-- epoch 49 
-- finished epoch in 227.86s 
-- train score: 0.5923719772404, cost 495.85s 
-- test score: 0.41688918558077, cost 258.73s 
-- epoch 50 
-- finished epoch in 207.91s 
-- train score: 0.59277839869945, cost 497.47s 
-- test score: 0.41789052069426, cost 279.99s 
-- epoch 51 
-- finished epoch in 182.80s 
-- train score: 0.5973379394432, cost 493.35s 
-- test score: 0.41694053609941, cost 289.34s 
-- epoch 52 
-- finished epoch in 148.00s 
-- train score: 0.59948435277383, cost 495.91s 
-- test score: 0.41691486084009, cost 292.52s 
-- epoch 53 
-- finished epoch in 167.18s 
-- train score: 0.59798567364357, cost 497.43s 
-- test score: 0.41886618054842, cost 289.68s 
-- epoch 54 
-- finished epoch in 158.93s 
-- train score: 0.60653322495428, cost 501.79s 
-- test score: 0.41902023210434, cost 289.56s 
-- epoch 55 
-- finished epoch in 164.54s 
-- train score: 0.60881934566145, cost 538.19s 
-- test score: 0.42056074766355, cost 252.80s 
-- epoch 56 
-- finished epoch in 163.23s 
-- train score: 0.61124517374517, cost 544.32s 
-- test score: 0.41881483002978, cost 246.73s 
-- epoch 57 
-- finished epoch in 166.79s 
-- train score: 0.61480136151189, cost 544.01s 
-- test score: 0.41822429906542, cost 245.72s 
-- epoch 58 
-- finished epoch in 163.94s 
-- train score: 0.61570310912416, cost 542.01s 
-- test score: 0.42053507240423, cost 246.89s 
-- epoch 59 
-- finished epoch in 165.01s 
-- train score: 0.61749390367811, cost 543.71s 
-- test score: 0.41912293314162, cost 246.21s 
-- epoch 60 
-- finished epoch in 162.48s 
-- train score: 0.62059286730339, cost 543.86s 
-- test score: 0.41922563417891, cost 244.62s 
-- epoch 61 
-- finished epoch in 166.92s 
-- train score: 0.62286628733997, cost 546.19s 
-- test score: 0.42130533018383, cost 246.25s 
-- epoch 62 
-- finished epoch in 183.67s 
-- train score: 0.62696860394229, cost 536.40s 
-- test score: 0.42171613433296, cost 245.70s 
-- epoch 63 
-- finished epoch in 209.12s 
-- train score: 0.62836567770778, cost 515.95s 
-- test score: 0.42045804662627, cost 245.94s 
-- epoch 64 
-- finished epoch in 233.35s 
-- train score: 0.63060099573257, cost 497.92s 
-- test score: 0.42115127862791, cost 252.11s 
-- epoch 65 
-- finished epoch in 230.96s 
-- train score: 0.63259500101605, cost 500.06s 
-- test score: 0.42071479921947, cost 275.17s 
-- epoch 66 
-- finished epoch in 192.22s 
-- train score: 0.63747205852469, cost 499.37s 
-- test score: 0.42235801581596, cost 293.51s 
-- epoch 67 
-- finished epoch in 166.40s 
-- train score: 0.63747205852469, cost 498.65s 
-- test score: 0.42027831981103, cost 293.09s 
-- epoch 68 
-- finished epoch in 158.01s 
-- train score: 0.63996138996139, cost 498.38s 
-- test score: 0.42068912396015, cost 290.82s 
-- epoch 69 
-- finished epoch in 168.80s 
-- train score: 0.64264123145702, cost 523.53s 
-- test score: 0.42328232515148, cost 265.21s 
-- epoch 70 
-- finished epoch in 155.99s 
-- train score: 0.64543537898801, cost 541.76s 
-- test score: 0.42161343329568, cost 247.28s 
-- epoch 71 
-- finished epoch in 166.08s 
-- train score: 0.64967740296688, cost 540.98s 
-- test score: 0.42246071685324, cost 246.03s 
-- epoch 72 
-- finished epoch in 166.12s 
-- train score: 0.64900426742532, cost 543.31s 
-- test score: 0.42089452603471, cost 245.29s 
-- epoch 73 
-- finished epoch in 161.24s 
-- train score: 0.65239534647429, cost 540.60s 
-- test score: 0.4218958611482, cost 246.04s 
-- epoch 74 
-- finished epoch in 162.02s 
-- train score: 0.65447825645194, cost 540.97s 
-- test score: 0.42097155181267, cost 243.95s 
-- epoch 75 
-- finished epoch in 163.52s 
-- train score: 0.65811064824223, cost 545.81s 
-- test score: 0.42145938173976, cost 245.94s 
-- epoch 76 
-- finished epoch in 163.27s 
-- train score: 0.66048567364357, cost 546.19s 
-- test score: 0.42210126322276, cost 245.91s 
-- epoch 77 
-- finished epoch in 178.88s 
-- train score: 0.66220026417395, cost 534.96s 
-- test score: 0.42199856218548, cost 243.89s 
-- epoch 78 
-- finished epoch in 190.38s 
-- train score: 0.66441018085755, cost 516.89s 
-- test score: 0.4226661189278, cost 244.32s 
-- epoch 79 
-- finished epoch in 223.59s 
-- train score: 0.66435937817517, cost 504.43s 
-- test score: 0.4220242374448, cost 245.93s 
-- epoch 80 
-- finished epoch in 232.12s 
-- train score: 0.66815687868319, cost 494.49s 
-- test score: 0.4213823559618, cost 255.05s 
finished training in 70310.03s 
best dev score is: 0.42328232515148 
writing model to ./done/vqalstm-COCOQA-rnnsu.l1.d150.e69.c1-2016-01-03T154251.t7 
