[program started on Sat Jan  9 22:48:02 2016] 
[command line arguments] 
[----------------------] 
-------------------------------------------------------------------------------- 
LSTM for VQA with text only 
-------------------------------------------------------------------------------- 
loading COCOQA datasets 
Append captions with question done. 
Remove determiner done. 
num train = 78736 
num test  = 38948 
-------------------------------------------------------------------------------- 
model configuration 
-------------------------------------------------------------------------------- 
max epochs                = 100 
num params                = 72580 
num compositional params  = 7650 
word vector dim           = 50 
LSTM memory dim           = 150 
LSTM structure            = bow 
LSTM layers               = 1 
regularization strength   = 1.00e-04 
minibatch size            = 1 
learning rate             = 5.00e-02 
word vector learning rate = 1.00e-01 
dropout                   = true 
cuda                      = true 
image feature dim         = [text only] 
-------------------------------------------------------------------------------- 
Training model 
-------------------------------------------------------------------------------- 
-- epoch 1 
-- finished epoch in 204.58s 
-- train score: 0.5437030075188, cost 389.51s 
-- test score: 0.51191332032454, cost 191.49s 
-- epoch 2 
-- finished epoch in 195.14s 
-- train score: 0.58524690103637, cost 373.33s 
-- test score: 0.53951422409366, cost 184.55s 
-- epoch 3 
-- finished epoch in 201.00s 
-- train score: 0.61438223938224, cost 385.89s 
-- test score: 0.55337886412653, cost 190.76s 
-- epoch 4 
-- finished epoch in 210.32s 
-- train score: 0.62901341190815, cost 386.24s 
-- test score: 0.55669097257882, cost 190.90s 
-- epoch 5 
-- finished epoch in 207.18s 
-- train score: 0.63811979272506, cost 366.32s 
-- test score: 0.55592071479922, cost 180.39s 
-- epoch 6 
-- finished epoch in 190.46s 
-- train score: 0.65215403373298, cost 370.39s 
-- test score: 0.5607476635514, cost 181.73s 
-- epoch 7 
-- finished epoch in 191.11s 
-- train score: 0.66386405202195, cost 367.56s 
-- test score: 0.56290438533429, cost 184.88s 
-- epoch 8 
-- finished epoch in 193.72s 
-- train score: 0.66872840885999, cost 362.33s 
-- test score: 0.56195440073945, cost 179.23s 
-- epoch 9 
-- finished epoch in 190.10s 
-- train score: 0.67652662060557, cost 362.37s 
-- test score: 0.56218547807333, cost 179.28s 
-- epoch 10 
-- finished epoch in 189.98s 
-- train score: 0.68248323511481, cost 362.21s 
-- test score: 0.56429084933758, cost 179.14s 
-- epoch 11 
-- finished epoch in 189.79s 
-- train score: 0.69034495021337, cost 363.16s 
-- test score: 0.56249358118517, cost 191.12s 
-- epoch 12 
-- finished epoch in 210.81s 
-- train score: 0.7004927860191, cost 368.12s 
-- test score: 0.56382869466982, cost 181.16s 
-- epoch 13 
-- finished epoch in 198.36s 
-- train score: 0.70011176590124, cost 377.17s 
-- test score: 0.55961795214132, cost 189.88s 
-- epoch 14 
-- finished epoch in 210.20s 
-- train score: 0.70596677504572, cost 385.61s 
-- test score: 0.56362329259526, cost 189.27s 
-- epoch 15 
-- finished epoch in 199.16s 
-- train score: 0.71126295468401, cost 365.11s 
-- test score: 0.5611327924412, cost 180.10s 
-- epoch 16 
-- finished epoch in 190.23s 
-- train score: 0.71455242836822, cost 363.62s 
-- test score: 0.56020848310568, cost 178.96s 
-- epoch 17 
-- finished epoch in 188.63s 
-- train score: 0.72048364153627, cost 367.62s 
-- test score: 0.56151792133101, cost 179.94s 
-- epoch 18 
-- finished epoch in 189.99s 
-- train score: 0.72645295671611, cost 364.98s 
-- test score: 0.56056793673616, cost 180.01s 
-- epoch 19 
-- finished epoch in 190.15s 
-- train score: 0.7300853485064, cost 365.02s 
-- test score: 0.55936119954812, cost 180.01s 
-- epoch 20 
-- finished epoch in 190.05s 
-- train score: 0.72970432838854, cost 364.63s 
-- test score: 0.55807743658211, cost 179.81s 
-- epoch 21 
-- finished epoch in 194.30s 
-- train score: 0.7356101402154, cost 362.72s 
-- test score: 0.55769230769231, cost 178.99s 
-- epoch 22 
-- finished epoch in 188.33s 
-- train score: 0.73576254826255, cost 370.92s 
-- test score: 0.55841121495327, cost 181.36s 
-- epoch 23 
-- finished epoch in 193.30s 
-- train score: 0.74298922983134, cost 363.03s 
-- test score: 0.559592276882, cost 181.62s 
-- epoch 24 
-- finished epoch in 190.45s 
-- train score: 0.74222718959561, cost 363.78s 
-- test score: 0.55255725582828, cost 179.79s 
-- epoch 25 
-- finished epoch in 189.88s 
-- train score: 0.74660892095103, cost 363.80s 
-- test score: 0.55730717880251, cost 179.81s 
-- epoch 26 
-- finished epoch in 189.60s 
-- train score: 0.74785358666938, cost 363.87s 
-- test score: 0.5561517921331, cost 179.89s 
-- epoch 27 
-- finished epoch in 189.68s 
-- train score: 0.75233692338955, cost 370.54s 
-- test score: 0.55651124576358, cost 182.30s 
-- epoch 28 
-- finished epoch in 188.96s 
-- train score: 0.75805222515749, cost 363.03s 
-- test score: 0.55461127657389, cost 179.41s 
-- epoch 29 
-- finished epoch in 188.89s 
-- train score: 0.76047805324121, cost 379.45s 
-- test score: 0.55486802916709, cost 189.35s 
-- epoch 30 
-- finished epoch in 191.06s 
-- train score: 0.76419934972567, cost 369.25s 
-- test score: 0.55458560131457, cost 182.29s 
-- epoch 31 
-- finished epoch in 189.49s 
-- train score: 0.76559642349116, cost 363.66s 
-- test score: 0.55579233850262, cost 179.79s 
-- epoch 32 
-- finished epoch in 198.67s 
-- train score: 0.77063858971754, cost 364.55s 
-- test score: 0.55846256547191, cost 187.12s 
-- epoch 33 
-- finished epoch in 211.16s 
-- train score: 0.77258179231863, cost 374.26s 
-- test score: 0.55604909109582, cost 182.45s 
-- epoch 34 
-- finished epoch in 188.57s 
-- train score: 0.76892399918716, cost 367.83s 
-- test score: 0.55661394680086, cost 180.41s 
-- epoch 35 
-- finished epoch in 189.16s 
-- train score: 0.7685175777281, cost 364.64s 
-- test score: 0.55052891034199, cost 180.27s 
-- epoch 36 
-- finished epoch in 188.62s 
-- train score: 0.77786527128632, cost 368.11s 
-- test score: 0.5527113073842, cost 181.14s 
-- epoch 37 
-- finished epoch in 201.66s 
-- train score: 0.77532513716724, cost 367.82s 
-- test score: 0.5525829310876, cost 181.15s 
-- epoch 38 
-- finished epoch in 190.01s 
-- train score: 0.77785257061573, cost 366.45s 
-- test score: 0.55124781760296, cost 181.08s 
-- epoch 39 
-- finished epoch in 191.10s 
-- train score: 0.78276773013615, cost 365.20s 
-- test score: 0.5516842970114, cost 180.50s 
-- epoch 40 
-- finished epoch in 188.75s 
-- train score: 0.77881782158098, cost 365.19s 
-- test score: 0.55045188456403, cost 180.57s 
-- epoch 41 
-- finished epoch in 188.69s 
-- train score: 0.78387268847795, cost 366.89s 
-- test score: 0.55158159597412, cost 182.23s 
-- epoch 42 
-- finished epoch in 188.70s 
-- train score: 0.78356787238366, cost 365.31s 
-- test score: 0.54847488959638, cost 180.58s 
-- epoch 43 
-- finished epoch in 195.62s 
-- train score: 0.78885135135135, cost 366.92s 
-- test score: 0.55440587449933, cost 183.61s 
-- epoch 44 
-- finished epoch in 194.67s 
-- train score: 0.78961339158708, cost 364.41s 
-- test score: 0.55047755982335, cost 180.10s 
-- epoch 45 
-- finished epoch in 191.07s 
-- train score: 0.79245834180045, cost 365.51s 
-- test score: 0.54770463181678, cost 183.10s 
-- epoch 46 
-- finished epoch in 192.45s 
-- train score: 0.79144228815281, cost 362.61s 
-- test score: 0.55230050323508, cost 183.39s 
