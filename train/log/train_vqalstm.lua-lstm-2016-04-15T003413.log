[program started on Fri Apr 15 00:34:13 2016] 
[command line arguments] 
rmdeter false 
caponly false 
dataset COCOQA 
cuda true 
caption false 
epochs 50 
modelclass ImageVQA 
capopt origin 
model lstm 
textonly false 
layers 1 
im_fea_dim 1024 
dim 150 
[----------------------] 
-------------------------------------------------------------------------------- 
LSTM for VQA 
-------------------------------------------------------------------------------- 
loading COCOQA datasets 
loading features 
num train = 78736 
num test  = 38948 
-------------------------------------------------------------------------------- 
model configuration 
-------------------------------------------------------------------------------- 
max epochs                = 50 
num params                = 440750 
num compositional params  = 0 
regularization strength   = 1.00e-04 
minibatch size            = 1 
learning rate             = 5.00e-02 
dropout                   = true 
cuda                      = true 
image (only) feature dim  = 1024 
-------------------------------------------------------------------------------- 
Training model 
-------------------------------------------------------------------------------- 
-- epoch 1 
-- finished epoch in 48.90s 
-- train score: 0.34046687665109, cost 377.65s 
-- test score: 0.27012940330697, cost 192.10s 
-- epoch 2 
-- finished epoch in 46.87s 
-- train score: 0.37646057711847, cost 390.18s 
-- test score: 0.28386566704324, cost 183.15s 
-- epoch 3 
-- finished epoch in 46.86s 
-- train score: 0.39698486080065, cost 396.47s 
-- test score: 0.29161959535791, cost 189.17s 
-- epoch 4 
-- finished epoch in 47.11s 
-- train score: 0.41134931924406, cost 383.34s 
-- test score: 0.29159392009859, cost 186.47s 
-- epoch 5 
-- finished epoch in 46.09s 
-- train score: 0.42482473074578, cost 385.06s 
-- test score: 0.29583033788641, cost 195.14s 
-- epoch 6 
-- finished epoch in 45.06s 
-- train score: 0.42981609428978, cost 382.05s 
-- test score: 0.29749922974222, cost 188.38s 
-- epoch 7 
-- finished epoch in 45.18s 
-- train score: 0.43601402154034, cost 384.93s 
-- test score: 0.29916812159803, cost 188.89s 
-- epoch 8 
-- finished epoch in 45.69s 
-- train score: 0.44420595407438, cost 387.82s 
-- test score: 0.30545856013146, cost 185.83s 
-- epoch 9 
-- finished epoch in 45.57s 
-- train score: 0.44501879699248, cost 387.48s 
-- test score: 0.30438019924001, cost 190.03s 
-- epoch 10 
-- finished epoch in 44.79s 
-- train score: 0.44675878886405, cost 378.26s 
-- test score: 0.30448290027729, cost 191.48s 
-- epoch 11 
-- finished epoch in 45.65s 
-- train score: 0.45114052021947, cost 377.97s 
-- test score: 0.30663962206018, cost 188.19s 
-- epoch 12 
-- finished epoch in 44.61s 
-- train score: 0.44898140621825, cost 382.29s 
-- test score: 0.30504775598234, cost 187.94s 
-- epoch 13 
-- finished epoch in 45.94s 
-- train score: 0.45646210119894, cost 380.33s 
-- test score: 0.30995173051248, cost 192.33s 
-- epoch 14 
-- finished epoch in 45.61s 
-- train score: 0.45618268644584, cost 381.64s 
-- test score: 0.30656259628222, cost 189.94s 
-- epoch 15 
-- finished epoch in 46.64s 
-- train score: 0.45689392399919, cost 385.40s 
-- test score: 0.3051247817603, cost 191.70s 
-- epoch 16 
-- finished epoch in 45.40s 
-- train score: 0.45836720178825, cost 385.77s 
-- test score: 0.30859094176851, cost 189.93s 
-- epoch 17 
-- finished epoch in 47.45s 
-- train score: 0.45727494411705, cost 382.05s 
-- test score: 0.30366129197905, cost 188.56s 
-- epoch 18 
-- finished epoch in 46.08s 
-- train score: 0.46042471042471, cost 382.11s 
-- test score: 0.30586936428058, cost 191.44s 
-- epoch 19 
-- finished epoch in 45.48s 
-- train score: 0.45813858971754, cost 379.39s 
-- test score: 0.30820581287871, cost 187.08s 
-- epoch 20 
-- finished epoch in 45.72s 
-- train score: 0.46113594797805, cost 381.47s 
-- test score: 0.30746123035843, cost 187.28s 
-- epoch 21 
-- finished epoch in 43.97s 
-- train score: 0.46138996138996, cost 384.42s 
-- test score: 0.31051658621752, cost 185.85s 
-- epoch 22 
-- finished epoch in 45.02s 
-- train score: 0.46899766307661, cost 382.16s 
-- test score: 0.31339221526137, cost 191.20s 
-- epoch 23 
-- finished epoch in 44.55s 
-- train score: 0.46469213574477, cost 376.11s 
-- test score: 0.30951525110404, cost 184.71s 
-- epoch 24 
-- finished epoch in 45.96s 
-- train score: 0.46880715301768, cost 371.38s 
-- test score: 0.31077333881072, cost 196.54s 
-- epoch 25 
-- finished epoch in 46.96s 
-- train score: 0.46481914245072, cost 384.89s 
-- test score: 0.3104909109582, cost 184.73s 
-- epoch 26 
-- finished epoch in 46.69s 
-- train score: 0.46946758788864, cost 376.28s 
-- test score: 0.31208277703605, cost 185.83s 
-- epoch 27 
-- finished epoch in 44.68s 
-- train score: 0.4673592765698, cost 373.64s 
-- test score: 0.31208277703605, cost 188.43s 
-- epoch 28 
-- finished epoch in 43.61s 
-- train score: 0.46413330623857, cost 375.86s 
-- test score: 0.30848824073123, cost 186.58s 
-- epoch 29 
-- finished epoch in 44.59s 
-- train score: 0.47024232879496, cost 375.48s 
-- test score: 0.31251925644449, cost 187.35s 
-- epoch 30 
-- finished epoch in 44.50s 
-- train score: 0.46915007112376, cost 376.66s 
-- test score: 0.31298141111225, cost 181.92s 
-- epoch 31 
-- finished epoch in 43.91s 
-- train score: 0.47330319040845, cost 381.67s 
-- test score: 0.31257060696313, cost 186.67s 
-- epoch 32 
-- finished epoch in 44.40s 
-- train score: 0.46578439341597, cost 375.21s 
-- test score: 0.31000308103112, cost 184.89s 
-- epoch 33 
-- finished epoch in 44.59s 
-- train score: 0.46695285511075, cost 378.33s 
-- test score: 0.30825716339735, cost 187.01s 
-- epoch 34 
-- finished epoch in 44.71s 
-- train score: 0.46916277179435, cost 377.48s 
-- test score: 0.31267330800041, cost 187.97s 
-- epoch 35 
-- finished epoch in 43.92s 
-- train score: 0.47203312334891, cost 377.37s 
-- test score: 0.31085036458868, cost 186.23s 
-- epoch 36 
-- finished epoch in 43.74s 
-- train score: 0.47050904287746, cost 381.98s 
-- test score: 0.31120981821916, cost 184.68s 
-- epoch 37 
-- finished epoch in 44.99s 
-- train score: 0.4698613086771, cost 377.53s 
-- test score: 0.31413679778166, cost 186.14s 
-- epoch 38 
-- finished epoch in 43.69s 
-- train score: 0.47193151798415, cost 371.34s 
-- test score: 0.31120981821916, cost 189.03s 
-- epoch 39 
-- finished epoch in 44.20s 
-- train score: 0.47242684413737, cost 375.21s 
-- test score: 0.31459895244942, cost 185.23s 
-- epoch 40 
-- finished epoch in 43.37s 
-- train score: 0.473442897785, cost 375.85s 
-- test score: 0.31328951422409, cost 186.87s 
-- epoch 41 
-- finished epoch in 43.52s 
-- train score: 0.47312538102012, cost 380.99s 
-- test score: 0.31182602444285, cost 184.34s 
-- epoch 42 
-- finished epoch in 50.77s 
-- train score: 0.47491617557407, cost 380.20s 
-- test score: 0.31567731334086, cost 189.50s 
-- epoch 43 
-- finished epoch in 46.88s 
-- train score: 0.47437004673847, cost 379.90s 
-- test score: 0.31334086474273, cost 185.29s 
-- epoch 44 
-- finished epoch in 50.35s 
-- train score: 0.47377311522048, cost 377.26s 
-- test score: 0.31192872548013, cost 188.10s 
-- epoch 45 
-- finished epoch in 45.08s 
-- train score: 0.47523369233896, cost 376.39s 
-- test score: 0.31336654000205, cost 186.04s 
-- epoch 46 
-- finished epoch in 50.50s 
-- train score: 0.47184261328998, cost 372.86s 
-- test score: 0.31364896785458, cost 187.36s 
-- epoch 47 
-- finished epoch in 45.81s 
-- train score: 0.47147429384271, cost 383.44s 
-- test score: 0.31423949881894, cost 185.85s 
-- epoch 48 
-- finished epoch in 50.75s 
-- train score: 0.47190611664296, cost 374.43s 
-- test score: 0.31472732874602, cost 187.59s 
-- epoch 49 
-- finished epoch in 43.03s 
-- train score: 0.47550040642146, cost 379.43s 
-- test score: 0.31231385436993, cost 188.62s 
-- epoch 50 
-- finished epoch in 51.26s 
-- train score: 0.47339209510262, cost 377.29s 
-- test score: 0.31328951422409, cost 187.72s 
finished training in 30687.14s 
best dev score is: 0.31567731334086 
writing model to ./done/vqalstm-COCOQA-lstm.l1.d150.e42.c1-2016-04-15T090547.t7 
