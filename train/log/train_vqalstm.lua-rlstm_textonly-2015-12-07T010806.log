[program started on Mon Dec  7 01:08:06 2015] 
[command line arguments] 
[----------------------] 
-------------------------------------------------------------------------------- 
LSTM for VQA with text only 
-------------------------------------------------------------------------------- 
loading datasets 
process data at: /home/deepnet/lyt/vqa/dataset/data/DAQUAR/DAQUAR-ALL 
Process_all_totable ... 
load train set ... 
total lines: 13590 
max length: 31 min length: 7 
#images: 6795 #questions: 6795 #answers: 6795 
normalize image: 6808 
load test set ... 
total lines: 11346 
max length: 28 min length: 7 
#images: 5673 #questions: 5673 #answers: 5673 
normalize image: 5681 
build vocabulary ... 
word vocabulary: 856 
answer vocabulary: 969 
image vocabulary: 1447 
num train = 6795 
num test  = 5673 
-------------------------------------------------------------------------------- 
model configuration 
-------------------------------------------------------------------------------- 
max epochs                = 70 
num params                = 267519 
num compositional params  = 121200 
word vector dim           = 50 
LSTM memory dim           = 150 
LSTM structure            = rlstm 
LSTM layers               = 1 
regularization strength   = 1.00e-04 
minibatch size            = 1 
learning rate             = 5.00e-02 
word vector learning rate = 1.00e-01 
dropout                   = true 
cuda                      = true 
image feature dim         = [text only] 
-------------------------------------------------------------------------------- 
Training model 
-------------------------------------------------------------------------------- 
-- epoch 1 
-- finished epoch in 63.70s 
-- train score: 0.087417218543046, cost 82.05s 
-- test score: 0.094658910629297, cost 67.21s 
-- epoch 2 
-- finished epoch in 63.54s 
-- train score: 0.07785136129507, cost 84.07s 
-- test score: 0.075268817204301, cost 69.10s 
-- epoch 3 
-- finished epoch in 66.39s 
-- train score: 0.098896247240618, cost 81.08s 
-- test score: 0.10946589106293, cost 66.32s 
-- epoch 4 
-- finished epoch in 62.11s 
-- train score: 0.10684326710817, cost 79.43s 
-- test score: 0.10646924026088, cost 66.16s 
-- epoch 5 
-- finished epoch in 64.64s 
-- train score: 0.11832229580574, cost 79.48s 
-- test score: 0.11792702273929, cost 67.73s 
-- epoch 6 
-- finished epoch in 62.35s 
-- train score: 0.12862398822664, cost 79.45s 
-- test score: 0.12533051295611, cost 66.19s 
-- epoch 7 
-- finished epoch in 61.95s 
-- train score: 0.14172185430464, cost 79.46s 
-- test score: 0.13379164463247, cost 66.19s 
-- epoch 8 
-- finished epoch in 62.80s 
-- train score: 0.14378219278882, cost 79.40s 
-- test score: 0.14066631411951, cost 66.17s 
-- epoch 9 
-- finished epoch in 61.89s 
-- train score: 0.15320088300221, cost 79.53s 
-- test score: 0.14983254010224, cost 66.25s 
-- epoch 10 
-- finished epoch in 61.83s 
-- train score: 0.16085356880059, cost 79.34s 
-- test score: 0.15194782302133, cost 66.13s 
-- epoch 11 
-- finished epoch in 61.86s 
-- train score: 0.1757174392936, cost 79.59s 
-- test score: 0.15846994535519, cost 66.23s 
-- epoch 12 
-- finished epoch in 61.82s 
-- train score: 0.17969094922737, cost 79.61s 
-- test score: 0.16393442622951, cost 66.28s 
-- epoch 13 
-- finished epoch in 62.18s 
-- train score: 0.18528329654157, cost 79.55s 
-- test score: 0.15846994535519, cost 66.25s 
-- epoch 14 
-- finished epoch in 61.76s 
-- train score: 0.19867549668874, cost 79.57s 
-- test score: 0.17010400141019, cost 66.24s 
-- epoch 15 
-- finished epoch in 62.20s 
-- train score: 0.20927152317881, cost 79.63s 
-- test score: 0.17398202009519, cost 66.32s 
-- epoch 16 
-- finished epoch in 61.95s 
-- train score: 0.22266372332597, cost 79.39s 
-- test score: 0.1833245196545, cost 66.11s 
-- epoch 17 
-- finished epoch in 61.79s 
-- train score: 0.23119941133186, cost 79.36s 
-- test score: 0.18209060461837, cost 66.14s 
-- epoch 18 
-- finished epoch in 61.87s 
-- train score: 0.23988226637233, cost 79.39s 
-- test score: 0.18209060461837, cost 66.16s 
-- epoch 19 
-- finished epoch in 61.87s 
-- train score: 0.25003679175865, cost 79.33s 
-- test score: 0.19178565133087, cost 66.09s 
-- epoch 20 
-- finished epoch in 61.85s 
-- train score: 0.26019131714496, cost 79.32s 
-- test score: 0.19460602855632, cost 66.08s 
-- epoch 21 
-- finished epoch in 61.80s 
-- train score: 0.27652685798381, cost 79.36s 
-- test score: 0.19654503789882, cost 66.10s 
-- epoch 22 
-- finished epoch in 61.84s 
-- train score: 0.28550404709345, cost 79.43s 
-- test score: 0.19795522651155, cost 66.16s 
-- epoch 23 
-- finished epoch in 61.81s 
-- train score: 0.30125091979397, cost 79.46s 
-- test score: 0.19760267935836, cost 66.15s 
-- epoch 24 
-- finished epoch in 61.84s 
-- train score: 0.31699779249448, cost 79.45s 
-- test score: 0.19901286797109, cost 66.17s 
-- epoch 25 
-- finished epoch in 61.82s 
-- train score: 0.32685798381163, cost 79.30s 
-- test score: 0.19725013220518, cost 66.08s 
-- epoch 26 
-- finished epoch in 61.93s 
-- train score: 0.33877851361295, cost 79.30s 
-- test score: 0.19777895293496, cost 66.04s 
-- epoch 27 
-- finished epoch in 61.84s 
-- train score: 0.35290654893304, cost 79.39s 
-- test score: 0.19954168870086, cost 66.08s 
-- epoch 28 
-- finished epoch in 61.78s 
-- train score: 0.36364974245769, cost 79.35s 
-- test score: 0.20412480169223, cost 66.14s 
-- epoch 29 
-- finished epoch in 61.84s 
-- train score: 0.37821927888153, cost 79.33s 
-- test score: 0.19954168870086, cost 66.08s 
-- epoch 30 
-- finished epoch in 61.82s 
-- train score: 0.3972038263429, cost 79.30s 
-- test score: 0.20112815089018, cost 66.10s 
-- epoch 31 
-- finished epoch in 61.81s 
-- train score: 0.40573951434879, cost 79.27s 
-- test score: 0.20641635818791, cost 66.10s 
-- epoch 32 
-- finished epoch in 61.83s 
-- train score: 0.41339220014717, cost 79.31s 
-- test score: 0.20218579234973, cost 66.09s 
-- epoch 33 
-- finished epoch in 61.82s 
-- train score: 0.42222222222222, cost 79.34s 
-- test score: 0.204653622422, cost 66.11s 
-- epoch 34 
-- finished epoch in 61.82s 
-- train score: 0.43532008830022, cost 79.39s 
-- test score: 0.19866032081791, cost 66.13s 
-- epoch 35 
-- finished epoch in 61.91s 
-- train score: 0.43443708609272, cost 79.29s 
-- test score: 0.20606381103473, cost 66.10s 
-- epoch 36 
-- finished epoch in 61.77s 
-- train score: 0.4513612950699, cost 79.35s 
-- test score: 0.20218579234973, cost 66.11s 
-- epoch 37 
-- finished epoch in 63.95s 
-- train score: 0.46284032376748, cost 306.88s 
-- test score: 0.20676890534109, cost 520.66s 
-- epoch 38 
-- finished epoch in 62.19s 
-- train score: 0.46828550404709, cost 79.40s 
-- test score: 0.20377225453904, cost 66.19s 
-- epoch 39 
-- finished epoch in 62.43s 
-- train score: 0.4766740250184, cost 79.40s 
-- test score: 0.20870791468359, cost 66.20s 
-- epoch 40 
-- finished epoch in 61.83s 
-- train score: 0.49183222958057, cost 79.59s 
-- test score: 0.20835536753041, cost 66.33s 
-- epoch 41 
-- finished epoch in 61.87s 
-- train score: 0.49168506254599, cost 79.51s 
-- test score: 0.20535871672836, cost 66.21s 
-- epoch 42 
-- finished epoch in 61.91s 
-- train score: 0.49948491537896, cost 79.45s 
-- test score: 0.20641635818791, cost 66.24s 
-- epoch 43 
-- finished epoch in 61.86s 
-- train score: 0.50419426048565, cost 79.51s 
-- test score: 0.20095187731359, cost 66.25s 
-- epoch 44 
-- finished epoch in 61.87s 
-- train score: 0.50905077262693, cost 79.50s 
-- test score: 0.20394852811564, cost 66.20s 
-- epoch 45 
-- finished epoch in 61.81s 
-- train score: 0.51920529801324, cost 79.60s 
-- test score: 0.20024678300723, cost 66.26s 
-- epoch 46 
-- finished epoch in 62.22s 
-- train score: 0.51567328918322, cost 79.53s 
-- test score: 0.20553499030495, cost 282.57s 
-- epoch 47 
-- finished epoch in 61.86s 
-- train score: 0.52891832229581, cost 79.45s 
-- test score: 0.19777895293496, cost 66.13s 
-- epoch 48 
-- finished epoch in 61.86s 
-- train score: 0.53259749816041, cost 79.39s 
-- test score: 0.20835536753041, cost 66.12s 
-- epoch 49 
-- finished epoch in 61.78s 
-- train score: 0.53451066961001, cost 79.44s 
-- test score: 0.20994182971973, cost 66.13s 
-- epoch 50 
-- finished epoch in 61.89s 
-- train score: 0.55055187637969, cost 79.32s 
-- test score: 0.2027146130795, cost 66.14s 
-- epoch 51 
-- finished epoch in 63.99s 
-- train score: 0.55305371596762, cost 81.60s 
-- test score: 0.20553499030495, cost 66.11s 
-- epoch 52 
-- finished epoch in 61.90s 
-- train score: 0.55540838852097, cost 79.32s 
-- test score: 0.20253833950291, cost 66.12s 
-- epoch 53 
-- finished epoch in 61.82s 
-- train score: 0.5579102281089, cost 79.31s 
-- test score: 0.20007050943064, cost 66.09s 
-- epoch 54 
-- finished epoch in 61.89s 
-- train score: 0.56144223693893, cost 79.31s 
-- test score: 0.204653622422, cost 66.14s 
-- epoch 55 
-- finished epoch in 61.92s 
-- train score: 0.56482707873436, cost 79.32s 
-- test score: 0.20430107526882, cost 66.12s 
-- epoch 56 
-- finished epoch in 61.82s 
-- train score: 0.57130242825607, cost 79.33s 
-- test score: 0.20641635818791, cost 66.10s 
-- epoch 57 
-- finished epoch in 61.86s 
-- train score: 0.57601177336277, cost 79.32s 
-- test score: 0.20976555614313, cost 66.10s 
-- epoch 58 
-- finished epoch in 61.90s 
-- train score: 0.5793966151582, cost 79.32s 
-- test score: 0.20747399964745, cost 66.11s 
-- epoch 59 
-- finished epoch in 61.82s 
-- train score: 0.586902133922, cost 79.35s 
-- test score: 0.21064692402609, cost 66.12s 
-- epoch 60 
-- finished epoch in 61.77s 
-- train score: 0.5841059602649, cost 79.39s 
-- test score: 0.208531641107, cost 66.16s 
-- epoch 61 
-- finished epoch in 61.77s 
-- train score: 0.58925680647535, cost 79.42s 
-- test score: 0.208531641107, cost 66.15s 
-- epoch 62 
-- finished epoch in 61.81s 
-- train score: 0.59426048565121, cost 79.39s 
-- test score: 0.20782654680063, cost 66.11s 
-- epoch 63 
-- finished epoch in 62.15s 
-- train score: 0.59411331861663, cost 79.45s 
-- test score: 0.20800282037723, cost 66.20s 
-- epoch 64 
-- finished epoch in 61.88s 
-- train score: 0.5980868285504, cost 79.42s 
-- test score: 0.20906046183677, cost 66.21s 
-- epoch 65 
-- finished epoch in 61.86s 
-- train score: 0.60544518027962, cost 79.40s 
-- test score: 0.20976555614313, cost 66.13s 
-- epoch 66 
-- finished epoch in 61.78s 
-- train score: 0.60456217807211, cost 79.35s 
-- test score: 0.20800282037723, cost 66.12s 
-- epoch 67 
-- finished epoch in 61.84s 
-- train score: 0.6047093451067, cost 79.39s 
-- test score: 0.20800282037723, cost 66.19s 
-- epoch 68 
-- finished epoch in 62.09s 
-- train score: 0.60735835172921, cost 79.39s 
-- test score: 0.20694517891768, cost 66.17s 
-- epoch 69 
-- finished epoch in 63.30s 
-- train score: 0.61707137601177, cost 80.30s 
-- test score: 0.20130442446677, cost 66.11s 
-- epoch 70 
-- finished epoch in 61.75s 
-- train score: 0.62001471670346, cost 79.32s 
-- test score: 0.21011810329632, cost 66.09s 
finished training in 15456.57s 
best dev score is: 0.21064692402609 
writing model to ./done/vqalstm-rlstm_textonly.l1.d150.e59.c1-2015-12-07T052544.t7 
