[program started on Sun Dec  6 12:48:23 2015] 
[command line arguments] 
[----------------------] 
-------------------------------------------------------------------------------- 
LSTM for VQA with text only 
-------------------------------------------------------------------------------- 
loading datasets 
process data at: /home/deepnet/lyt/vqa/dataset/data/DAQUAR/DAQUAR-ALL 
Process_all_totable ... 
load train set ... 
total lines: 13590 
max length: 31 min length: 7 
#images: 6795 #questions: 6795 #answers: 6795 
normalize image: 6808 
load test set ... 
total lines: 11346 
max length: 28 min length: 7 
#images: 5673 #questions: 5673 #answers: 5673 
normalize image: 5681 
build vocabulary ... 
word vocabulary: 856 
answer vocabulary: 969 
image vocabulary: 1447 
num train = 6795 
num test  = 5673 
-------------------------------------------------------------------------------- 
model configuration 
-------------------------------------------------------------------------------- 
max epochs                = 70 
num params                = 153969 
num compositional params  = 7650 
word vector dim           = 50 
LSTM memory dim           = 150 
LSTM structure            = rnnsu 
LSTM layers               = 1 
regularization strength   = 1.00e-04 
minibatch size            = 1 
learning rate             = 5.00e-02 
word vector learning rate = 1.00e-01 
dropout                   = true 
cuda                      = true 
image feature dim         = [text only] 
-------------------------------------------------------------------------------- 
Training model 
-------------------------------------------------------------------------------- 
-- epoch 1 
-- finished epoch in 36.44s 
-- train score: 0.040029433406917, cost 205.92s 
-- test score: 0.049709148598625, cost 137.08s 
-- epoch 2 
-- finished epoch in 20.77s 
-- train score: 0.040029433406917, cost 221.31s 
-- test score: 0.049709148598625, cost 160.39s 
-- epoch 3 
-- finished epoch in 18.40s 
-- train score: 0.040029433406917, cost 204.75s 
-- test score: 0.049709148598625, cost 174.46s 
-- epoch 4 
-- finished epoch in 19.22s 
-- train score: 0.090213392200147, cost 153.05s 
-- test score: 0.10153358011634, cost 233.17s 
-- epoch 5 
-- finished epoch in 19.15s 
-- train score: 0.09551140544518, cost 152.84s 
-- test score: 0.10629296668429, cost 261.93s 
-- epoch 6 
-- finished epoch in 19.39s 
-- train score: 0.14275202354673, cost 154.89s 
-- test score: 0.14965626652565, cost 189.11s 
-- epoch 7 
-- finished epoch in 36.54s 
-- train score: 0.15261221486387, cost 190.98s 
-- test score: 0.16129032258065, cost 129.78s 
-- epoch 8 
-- finished epoch in 31.41s 
-- train score: 0.12906548933039, cost 244.03s 
-- test score: 0.13802221047065, cost 129.42s 
-- epoch 9 
-- finished epoch in 20.94s 
-- train score: 0.16409124356144, cost 223.34s 
-- test score: 0.15864621893178, cost 159.73s 
-- epoch 10 
-- finished epoch in 18.44s 
-- train score: 0.18646063281825, cost 190.91s 
-- test score: 0.19002291556496, cost 195.52s 
-- epoch 11 
-- finished epoch in 17.58s 
-- train score: 0.19205298013245, cost 189.94s 
-- test score: 0.19636876432223, cost 157.86s 
-- epoch 12 
-- finished epoch in 35.35s 
-- train score: 0.19411331861663, cost 202.03s 
-- test score: 0.19777895293496, cost 135.08s 
-- epoch 13 
-- finished epoch in 17.51s 
-- train score: 0.18646063281825, cost 220.19s 
-- test score: 0.19672131147541, cost 165.42s 
-- epoch 14 
-- finished epoch in 20.44s 
-- train score: 0.20618101545254, cost 201.86s 
-- test score: 0.21311475409836, cost 182.21s 
-- epoch 15 
-- finished epoch in 19.18s 
-- train score: 0.21707137601177, cost 154.43s 
-- test score: 0.21170456548563, cost 262.96s 
-- epoch 16 
-- finished epoch in 21.51s 
-- train score: 0.2158940397351, cost 154.54s 
-- test score: 0.2065926317645, cost 251.62s 
-- epoch 17 
-- finished epoch in 19.82s 
-- train score: 0.20235467255335, cost 154.91s 
-- test score: 0.19583994359246, cost 191.77s 
-- epoch 18 
-- finished epoch in 37.06s 
-- train score: 0.21456953642384, cost 177.26s 
-- test score: 0.19954168870086, cost 164.59s 
-- epoch 19 
-- finished epoch in 20.73s 
-- train score: 0.22236938925681, cost 214.12s 
-- test score: 0.20747399964745, cost 160.52s 
-- epoch 20 
-- finished epoch in 23.85s 
-- train score: 0.22545989698308, cost 186.86s 
-- test score: 0.21893178212586, cost 165.71s 
-- epoch 21 
-- finished epoch in 34.87s 
-- train score: 0.23487858719647, cost 168.01s 
-- test score: 0.21787414066631, cost 192.96s 
-- epoch 22 
-- finished epoch in 18.36s 
-- train score: 0.2457689477557, cost 191.02s 
-- test score: 0.21928432927904, cost 132.47s 
-- epoch 23 
-- finished epoch in 35.29s 
-- train score: 0.23296541574687, cost 245.46s 
-- test score: 0.21452494271109, cost 128.31s 
-- epoch 24 
-- finished epoch in 17.57s 
-- train score: 0.2429727740986, cost 288.73s 
-- test score: 0.2199894235854, cost 131.46s 
-- epoch 25 
-- finished epoch in 17.87s 
-- train score: 0.21898454746137, cost 259.74s 
-- test score: 0.19513484928609, cost 129.58s 
-- epoch 26 
-- finished epoch in 18.92s 
-- train score: 0.24415011037528, cost 199.43s 
-- test score: 0.21593513132381, cost 187.88s 
-- epoch 27 
-- finished epoch in 19.84s 
-- train score: 0.24532744665195, cost 192.14s 
-- test score: 0.21293848052177, cost 187.03s 
-- epoch 28 
-- finished epoch in 25.83s 
-- train score: 0.25842531272995, cost 190.17s 
-- test score: 0.22280980081086, cost 130.20s 
-- epoch 29 
-- finished epoch in 22.05s 
-- train score: 0.26387049300957, cost 233.90s 
-- test score: 0.22104706504495, cost 150.03s 
-- epoch 30 
-- finished epoch in 18.35s 
-- train score: 0.2616629874908, cost 120.00s 
-- test score: 0.21963687643222, cost 99.77s 
-- epoch 31 
-- finished epoch in 16.00s 
-- train score: 0.27785136129507, cost 92.68s 
-- test score: 0.22615899876608, cost 80.91s 
-- epoch 32 
-- finished epoch in 34.14s 
-- train score: 0.27564385577631, cost 101.23s 
-- test score: 0.21910805570245, cost 77.68s 
-- epoch 33 
-- finished epoch in 15.70s 
-- train score: 0.26872700515085, cost 115.01s 
-- test score: 0.21223338621541, cost 77.36s 
-- epoch 34 
-- finished epoch in 16.18s 
-- train score: 0.27446651949963, cost 97.90s 
-- test score: 0.21470121628768, cost 94.53s 
-- epoch 35 
-- finished epoch in 16.14s 
-- train score: 0.29565857247976, cost 92.97s 
-- test score: 0.22157588577472, cost 93.90s 
-- epoch 36 
-- finished epoch in 26.48s 
-- train score: 0.28609271523179, cost 92.90s 
-- test score: 0.21752159351313, cost 77.56s 
-- epoch 37 
-- finished epoch in 15.87s 
-- train score: 0.29654157468727, cost 114.96s 
-- test score: 0.22245725365768, cost 77.34s 
-- epoch 38 
-- finished epoch in 15.89s 
-- train score: 0.28991905813098, cost 108.83s 
-- test score: 0.22228098008109, cost 83.39s 
-- epoch 39 
-- finished epoch in 15.94s 
-- train score: 0.29595290654893, cost 92.96s 
-- test score: 0.22862682883836, cost 99.63s 
-- epoch 40 
-- finished epoch in 16.21s 
-- train score: 0.29109639440765, cost 92.67s 
-- test score: 0.21875550854927, cost 77.97s 
-- epoch 41 
-- finished epoch in 34.06s 
-- train score: 0.30581309786608, cost 104.45s 
-- test score: 0.22034197073859, cost 77.45s 
-- epoch 42 
-- finished epoch in 15.74s 
-- train score: 0.31243561442237, cost 114.86s 
-- test score: 0.21558258417063, cost 77.20s 
-- epoch 43 
-- finished epoch in 15.95s 
-- train score: 0.30949227373068, cost 94.71s 
-- test score: 0.21223338621541, cost 97.99s 
-- epoch 44 
-- finished epoch in 16.12s 
-- train score: 0.30772626931567, cost 93.02s 
-- test score: 0.21152829190904, cost 90.14s 
-- epoch 45 
-- finished epoch in 32.84s 
-- train score: 0.30316409124356, cost 92.81s 
-- test score: 0.21928432927904, cost 77.37s 
-- epoch 46 
-- finished epoch in 28.24s 
-- train score: 0.31464311994113, cost 113.48s 
-- test score: 0.22668781949586, cost 77.59s 
-- epoch 47 
-- finished epoch in 19.74s 
-- train score: 0.30507726269316, cost 115.02s 
-- test score: 0.20976555614313, cost 77.60s 
-- epoch 48 
-- finished epoch in 20.60s 
-- train score: 0.30669610007358, cost 92.95s 
-- test score: 0.21928432927904, cost 92.87s 
-- epoch 49 
-- finished epoch in 17.58s 
-- train score: 0.33509933774834, cost 90.80s 
-- test score: 0.21946060285563, cost 75.77s 
-- epoch 50 
-- finished epoch in 23.47s 
-- train score: 0.32788815305372, cost 101.41s 
-- test score: 0.22615899876608, cost 75.84s 
-- epoch 51 
-- finished epoch in 16.09s 
-- train score: 0.33436350257542, cost 94.22s 
-- test score: 0.20729772607086, cost 85.60s 
-- epoch 52 
-- finished epoch in 17.09s 
-- train score: 0.32818248712288, cost 90.76s 
-- test score: 0.20941300898995, cost 76.97s 
-- epoch 53 
-- finished epoch in 28.39s 
-- train score: 0.3355408388521, cost 98.26s 
-- test score: 0.21893178212586, cost 75.80s 
-- epoch 54 
-- finished epoch in 18.37s 
-- train score: 0.34039735099338, cost 97.74s 
-- test score: 0.21258593336859, cost 81.93s 
-- epoch 55 
-- finished epoch in 16.44s 
-- train score: 0.34319352465048, cost 90.59s 
-- test score: 0.20535871672836, cost 80.29s 
-- epoch 56 
-- finished epoch in 28.12s 
-- train score: 0.33804267844003, cost 94.67s 
-- test score: 0.21787414066631, cost 75.66s 
-- epoch 57 
-- finished epoch in 23.61s 
-- train score: 0.34304635761589, cost 102.20s 
-- test score: 0.21928432927904, cost 77.11s 
-- epoch 58 
-- finished epoch in 15.49s 
-- train score: 0.34805003679176, cost 90.56s 
-- test score: 0.21135201833245, cost 84.60s 
-- epoch 59 
-- finished epoch in 27.27s 
-- train score: 0.34908020603385, cost 90.57s 
-- test score: 0.22122333862154, cost 75.59s 
-- epoch 60 
-- finished epoch in 15.55s 
-- train score: 0.35246504782929, cost 103.75s 
-- test score: 0.21135201833245, cost 75.51s 
-- epoch 61 
-- finished epoch in 15.69s 
-- train score: 0.34569536423841, cost 90.55s 
-- test score: 0.22051824431518, cost 86.97s 
-- epoch 62 
-- finished epoch in 20.80s 
-- train score: 0.35805739514349, cost 90.49s 
-- test score: 0.20765027322404, cost 75.54s 
-- epoch 63 
-- finished epoch in 15.67s 
-- train score: 0.33774834437086, cost 103.75s 
-- test score: 0.22228098008109, cost 75.52s 
-- epoch 64 
-- finished epoch in 15.72s 
-- train score: 0.36188373804268, cost 90.59s 
-- test score: 0.22615899876608, cost 88.46s 
-- epoch 65 
-- finished epoch in 16.66s 
-- train score: 0.36100073583517, cost 90.53s 
-- test score: 0.22351489511722, cost 75.66s 
-- epoch 66 
-- finished epoch in 15.67s 
-- train score: 0.36409124356144, cost 103.83s 
-- test score: 0.2180504142429, cost 75.52s 
-- epoch 67 
-- finished epoch in 15.69s 
-- train score: 0.37306843267108, cost 90.63s 
-- test score: 0.21716904635995, cost 88.60s 
-- epoch 68 
-- finished epoch in 15.90s 
-- train score: 0.36512141280353, cost 90.54s 
-- test score: 0.2180504142429, cost 75.64s 
-- epoch 69 
-- finished epoch in 15.68s 
-- train score: 0.35717439293598, cost 103.83s 
-- test score: 0.21152829190904, cost 75.53s 
-- epoch 70 
-- finished epoch in 15.65s 
-- train score: 0.35570272259014, cost 90.64s 
-- test score: 0.2199894235854, cost 88.78s 
finished training in 19620.34s 
best dev score is: 0.22862682883836 
writing model to ./done/vqalstm_textonly-rnnsu.l1.d150.e39.c1-2015-12-06T181527.t7 
