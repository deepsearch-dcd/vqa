[program started on Fri Jan 22 10:33:18 2016] 
[command line arguments] 
[----------------------] 
-------------------------------------------------------------------------------- 
LSTM for VQA 
-------------------------------------------------------------------------------- 
loading COCOQA datasets 
Remove determiner done. 
loading features 
num train = 78736 
num test  = 38948 
-------------------------------------------------------------------------------- 
model configuration 
-------------------------------------------------------------------------------- 
max epochs                = 100 
num params                = 786130 
num compositional params  = 721200 
word vector dim           = 50 
LSTM memory dim           = 150 
LSTM structure            = lstm 
LSTM layers               = 1 
regularization strength   = 1.00e-04 
minibatch size            = 1 
learning rate             = 5.00e-02 
word vector learning rate = 1.00e-01 
dropout                   = true 
cuda                      = true 
image feature dim         = 1000 
-------------------------------------------------------------------------------- 
Training model 
-------------------------------------------------------------------------------- 
-- epoch 1 
-- finished epoch in 1362.15s 
-- train score: 0.19237705750864, cost 903.01s 
-- test score: 0.1901509705248, cost 446.02s 
-- epoch 2 
-- finished epoch in 1353.62s 
-- train score: 0.20951026214184, cost 902.92s 
-- test score: 0.20542774982027, cost 446.09s 
-- epoch 3 
-- finished epoch in 1351.00s 
-- train score: 0.22955192034139, cost 904.40s 
-- test score: 0.22201396734107, cost 446.99s 
-- epoch 4 
-- finished epoch in 1351.59s 
-- train score: 0.23950924608819, cost 904.08s 
-- test score: 0.23005032350827, cost 446.72s 
-- epoch 5 
-- finished epoch in 1341.76s 
-- train score: 0.24908555171713, cost 902.46s 
-- test score: 0.24060285508884, cost 446.97s 
-- epoch 6 
-- finished epoch in 1351.94s 
-- train score: 0.25579150579151, cost 904.44s 
-- test score: 0.24584060799014, cost 446.75s 
-- epoch 7 
-- finished epoch in 1350.81s 
-- train score: 0.25694726681569, cost 904.48s 
-- test score: 0.24697031940023, cost 446.64s 
-- epoch 8 
-- finished epoch in 1353.27s 
-- train score: 0.26545671611461, cost 906.25s 
-- test score: 0.25377426312006, cost 447.62s 
-- epoch 9 
-- finished epoch in 1353.05s 
-- train score: 0.26944472668157, cost 904.13s 
-- test score: 0.25310670637773, cost 467.04s 
-- epoch 10 
-- finished epoch in 1358.36s 
-- train score: 0.27216267018899, cost 921.20s 
-- test score: 0.25798500564856, cost 449.05s 
-- epoch 11 
-- finished epoch in 1352.02s 
-- train score: 0.27891942694574, cost 904.10s 
-- test score: 0.26219574817706, cost 446.63s 
-- epoch 12 
-- finished epoch in 1356.01s 
-- train score: 0.3163737045316, cost 905.02s 
-- test score: 0.29380199240012, cost 447.34s 
-- epoch 13 
-- finished epoch in 1354.22s 
-- train score: 0.33614864864865, cost 903.69s 
-- test score: 0.31388004518846, cost 480.81s 
-- epoch 14 
-- finished epoch in 1351.36s 
-- train score: 0.34290540540541, cost 905.84s 
-- test score: 0.31909212283044, cost 463.17s 
-- epoch 15 
-- finished epoch in 1362.01s 
-- train score: 0.34769355821987, cost 909.75s 
-- test score: 0.31952860223888, cost 447.39s 
-- epoch 16 
-- finished epoch in 1366.56s 
-- train score: 0.34991617557407, cost 923.79s 
-- test score: 0.32332854061826, cost 478.63s 
-- epoch 17 
-- finished epoch in 1379.62s 
-- train score: 0.35462812436497, cost 906.33s 
-- test score: 0.32468932936223, cost 446.74s 
-- epoch 18 
-- finished epoch in 1356.49s 
-- train score: 0.3614610851453, cost 905.09s 
-- test score: 0.32723118003492, cost 447.50s 
-- epoch 19 
-- finished epoch in 1355.35s 
-- train score: 0.36951331030278, cost 905.89s 
-- test score: 0.33822019102393, cost 447.40s 
-- epoch 20 
-- finished epoch in 1354.34s 
-- train score: 0.39116795366795, cost 903.99s 
-- test score: 0.35503748587861, cost 447.23s 
-- epoch 21 
-- finished epoch in 1351.86s 
-- train score: 0.39726427555375, cost 904.17s 
-- test score: 0.36132792441204, cost 447.53s 
-- epoch 22 
-- finished epoch in 1352.05s 
-- train score: 0.40149359886202, cost 904.04s 
-- test score: 0.3672845845743, cost 446.61s 
-- epoch 23 
-- finished epoch in 1350.93s 
-- train score: 0.40666277179435, cost 904.16s 
-- test score: 0.36923590428263, cost 446.59s 
-- epoch 24 
-- finished epoch in 1353.42s 
-- train score: 0.41225106685633, cost 905.51s 
-- test score: 0.36987778576564, cost 446.85s 
-- epoch 25 
-- finished epoch in 1354.89s 
-- train score: 0.41435937817517, cost 902.75s 
-- test score: 0.37218855910445, cost 445.87s 
-- epoch 26 
-- finished epoch in 1351.02s 
-- train score: 0.41907132696606, cost 903.38s 
-- test score: 0.37665605422615, cost 446.10s 
-- epoch 27 
-- finished epoch in 1350.25s 
-- train score: 0.41970636049583, cost 903.06s 
-- test score: 0.37788846667351, cost 446.16s 
-- epoch 28 
-- finished epoch in 1350.12s 
-- train score: 0.42485013208697, cost 902.11s 
-- test score: 0.37819656978535, cost 445.70s 
-- epoch 29 
-- finished epoch in 1349.32s 
-- train score: 0.426983844747, cost 902.34s 
-- test score: 0.37919790489884, cost 445.66s 
-- epoch 30 
-- finished epoch in 1348.64s 
-- train score: 0.43052733184312, cost 902.11s 
-- test score: 0.38102084831057, cost 446.03s 
-- epoch 31 
-- finished epoch in 1349.62s 
-- train score: 0.43402001625686, cost 902.32s 
-- test score: 0.38233028653589, cost 445.91s 
-- epoch 32 
-- finished epoch in 1349.04s 
-- train score: 0.43644584434058, cost 903.66s 
-- test score: 0.38448700831878, cost 446.62s 
-- epoch 33 
-- finished epoch in 1354.01s 
-- train score: 0.441361003861, cost 904.57s 
-- test score: 0.38515456506111, cost 446.69s 
-- epoch 34 
-- finished epoch in 1355.32s 
-- train score: 0.44763513513514, cost 904.70s 
-- test score: 0.39170175618774, cost 446.39s 
-- epoch 35 
-- finished epoch in 1354.05s 
-- train score: 0.45533174151595, cost 903.97s 
-- test score: 0.39696518434836, cost 446.32s 
-- epoch 36 
-- finished epoch in 1353.12s 
-- train score: 0.46043741109531, cost 903.64s 
-- test score: 0.39999486494814, cost 446.31s 
-- epoch 37 
-- finished epoch in 1355.02s 
-- train score: 0.46732117455802, cost 904.16s 
-- test score: 0.404796138441, cost 446.77s 
-- epoch 38 
-- finished epoch in 1354.11s 
-- train score: 0.46893415972363, cost 904.31s 
-- test score: 0.40651638081545, cost 446.96s 
-- epoch 39 
-- finished epoch in 1353.99s 
-- train score: 0.47353180247917, cost 904.00s 
-- test score: 0.40895553045086, cost 446.68s 
-- epoch 40 
-- finished epoch in 1354.77s 
-- train score: 0.48096169477748, cost 904.33s 
-- test score: 0.41455273698264, cost 446.87s 
-- epoch 41 
-- finished epoch in 1354.53s 
-- train score: 0.48529262345052, cost 904.22s 
-- test score: 0.41786484543494, cost 446.60s 
-- epoch 42 
-- finished epoch in 1353.17s 
-- train score: 0.48928063401748, cost 905.56s 
-- test score: 0.41889185580774, cost 446.86s 
-- epoch 43 
-- finished epoch in 1357.58s 
-- train score: 0.49504673846779, cost 905.90s 
-- test score: 0.4230512478176, cost 446.31s 
-- epoch 44 
-- finished epoch in 1353.66s 
-- train score: 0.49554206462101, cost 903.77s 
-- test score: 0.42405258293109, cost 446.36s 
-- epoch 45 
-- finished epoch in 1352.95s 
-- train score: 0.50069853688275, cost 903.55s 
-- test score: 0.42916195953579, cost 447.15s 
-- epoch 46 
-- finished epoch in 1355.72s 
-- train score: 0.50444523470839, cost 906.50s 
-- test score: 0.43152408339324, cost 447.94s 
-- epoch 47 
-- finished epoch in 1355.57s 
-- train score: 0.5074679943101, cost 906.05s 
-- test score: 0.43499024340146, cost 448.20s 
-- epoch 48 
-- finished epoch in 1356.33s 
-- train score: 0.50853485064011, cost 904.76s 
-- test score: 0.43534969703194, cost 447.15s 
-- epoch 49 
-- finished epoch in 1352.64s 
-- train score: 0.51182432432432, cost 903.77s 
-- test score: 0.43565780014378, cost 446.40s 
-- epoch 50 
-- finished epoch in 1354.53s 
-- train score: 0.51519000203211, cost 904.08s 
-- test score: 0.43814830029783, cost 446.76s 
-- epoch 51 
-- finished epoch in 1354.40s 
-- train score: 0.51947012802276, cost 904.27s 
-- test score: 0.44143473349081, cost 447.50s 
-- epoch 52 
-- finished epoch in 1357.61s 
-- train score: 0.51837787035155, cost 905.44s 
-- test score: 0.44079285200781, cost 446.74s 
-- epoch 53 
-- finished epoch in 1354.75s 
-- train score: 0.52217537085958, cost 903.31s 
-- test score: 0.44466981616514, cost 446.74s 
-- epoch 54 
-- finished epoch in 1353.43s 
-- train score: 0.52791607396871, cost 903.91s 
-- test score: 0.44636438328027, cost 446.81s 
-- epoch 55 
-- finished epoch in 1355.29s 
-- train score: 0.52916073968706, cost 903.29s 
-- test score: 0.44816165143268, cost 446.52s 
-- epoch 56 
-- finished epoch in 1356.35s 
-- train score: 0.53213269660638, cost 905.05s 
-- test score: 0.44911163602752, cost 446.68s 
-- epoch 57 
-- finished epoch in 1354.63s 
-- train score: 0.53326305628937, cost 916.11s 
-- test score: 0.45062647632741, cost 481.05s 
-- epoch 58 
-- finished epoch in 1363.48s 
-- train score: 0.53723836618573, cost 905.16s 
-- test score: 0.45293724966622, cost 446.97s 
-- epoch 59 
-- finished epoch in 1354.55s 
-- train score: 0.53916886811624, cost 904.95s 
-- test score: 0.45324535277806, cost 446.83s 
-- epoch 60 
-- finished epoch in 1354.98s 
-- train score: 0.5420392196708, cost 904.14s 
-- test score: 0.45817500256753, cost 446.43s 
-- epoch 61 
-- finished epoch in 1355.58s 
-- train score: 0.54416023166023, cost 904.25s 
-- test score: 0.45773852315908, cost 447.05s 
-- epoch 62 
-- finished epoch in 1356.61s 
-- train score: 0.54577321682585, cost 903.14s 
-- test score: 0.45604395604396, cost 446.18s 
-- epoch 63 
-- finished epoch in 1352.84s 
-- train score: 0.5483895549685, cost 903.37s 
-- test score: 0.45915066242169, cost 446.43s 
-- epoch 64 
-- finished epoch in 1351.43s 
-- train score: 0.55216165413534, cost 903.21s 
-- test score: 0.45997227071993, cost 446.64s 
-- epoch 65 
-- finished epoch in 1353.25s 
-- train score: 0.55207274944117, cost 903.63s 
-- test score: 0.46143576050118, cost 446.51s 
-- epoch 66 
-- finished epoch in 1353.32s 
-- train score: 0.55470178825442, cost 904.78s 
-- test score: 0.46436274006367, cost 446.36s 
-- epoch 67 
-- finished epoch in 1351.22s 
-- train score: 0.55761024182077, cost 903.38s 
-- test score: 0.46395193591455, cost 446.33s 
-- epoch 68 
-- finished epoch in 1355.91s 
-- train score: 0.56020117862223, cost 903.76s 
-- test score: 0.46361815754339, cost 446.44s 
-- epoch 69 
-- finished epoch in 1354.43s 
-- train score: 0.56122993294046, cost 905.04s 
-- test score: 0.46577487932628, cost 446.79s 
-- epoch 70 
-- finished epoch in 1354.69s 
-- train score: 0.56275401341191, cost 904.17s 
-- test score: 0.46564650302968, cost 446.81s 
-- epoch 71 
-- finished epoch in 1354.26s 
-- train score: 0.56493852875432, cost 903.18s 
-- test score: 0.46770052377529, cost 446.45s 
-- epoch 72 
-- finished epoch in 1353.88s 
-- train score: 0.56733895549685, cost 919.52s 
-- test score: 0.46479921947212, cost 480.47s 
-- epoch 73 
-- finished epoch in 1357.41s 
-- train score: 0.57000609632189, cost 905.00s 
-- test score: 0.46931806511246, cost 447.43s 
-- epoch 74 
-- finished epoch in 1353.29s 
-- train score: 0.57258433245275, cost 903.89s 
-- test score: 0.47067885385642, cost 446.21s 
-- epoch 75 
-- finished epoch in 1353.34s 
-- train score: 0.57262243446454, cost 905.30s 
-- test score: 0.47201396734107, cost 446.96s 
-- epoch 76 
-- finished epoch in 1355.73s 
-- train score: 0.57517526925422, cost 904.95s 
-- test score: 0.47247612200883, cost 446.94s 
-- epoch 77 
-- finished epoch in 1354.49s 
-- train score: 0.5746672424304, cost 903.73s 
-- test score: 0.47221936941563, cost 446.40s 
-- epoch 78 
-- finished epoch in 1350.04s 
-- train score: 0.57607701686649, cost 901.70s 
-- test score: 0.474735544829, cost 445.68s 
-- epoch 79 
-- finished epoch in 1350.26s 
-- train score: 0.5829607803292, cost 902.51s 
-- test score: 0.47591660675773, cost 446.37s 
-- epoch 80 
-- finished epoch in 1355.47s 
-- train score: 0.5804841495631, cost 939.25s 
-- test score: 0.47645578720345, cost 446.46s 
-- epoch 81 
-- finished epoch in 1352.75s 
-- train score: 0.58485318024792, cost 903.22s 
-- test score: 0.47809900379994, cost 446.43s 
-- epoch 82 
-- finished epoch in 1354.87s 
-- train score: 0.58677098150782, cost 906.16s 
-- test score: 0.4777909006881, cost 446.86s 
-- epoch 83 
-- finished epoch in 1354.67s 
-- train score: 0.58694879089616, cost 904.47s 
-- test score: 0.47879223580158, cost 446.13s 
-- epoch 84 
-- finished epoch in 1356.91s 
-- train score: 0.59045417598049, cost 912.50s 
-- test score: 0.47884358632022, cost 446.45s 
-- epoch 85 
-- finished epoch in 1353.37s 
-- train score: 0.59135592359277, cost 903.45s 
-- test score: 0.47902331313546, cost 446.27s 
-- epoch 86 
-- finished epoch in 1354.24s 
-- train score: 0.59368014631173, cost 906.46s 
-- test score: 0.48023005032351, cost 447.19s 
-- epoch 87 
-- finished epoch in 1354.62s 
-- train score: 0.59453109124162, cost 904.22s 
-- test score: 0.48064085447263, cost 445.56s 
-- epoch 88 
-- finished epoch in 1349.83s 
-- train score: 0.59746494614916, cost 902.42s 
-- test score: 0.48171921536408, cost 445.66s 
-- epoch 89 
-- finished epoch in 1352.73s 
-- train score: 0.59793487096119, cost 910.87s 
-- test score: 0.48297730307076, cost 480.99s 
-- epoch 90 
-- finished epoch in 1367.56s 
-- train score: 0.6012243446454, cost 947.33s 
-- test score: 0.48361918455376, cost 473.91s 
-- epoch 91 
-- finished epoch in 1361.92s 
-- train score: 0.60298973785816, cost 962.21s 
-- test score: 0.48533942692821, cost 479.60s 
-- epoch 92 
-- finished epoch in 1479.95s 
-- train score: 0.60390418614103, cost 901.77s 
-- test score: 0.48451781862997, cost 445.70s 
-- epoch 93 
-- finished epoch in 1349.23s 
-- train score: 0.60450111765901, cost 901.74s 
-- test score: 0.48564753004005, cost 445.60s 
-- epoch 94 
-- finished epoch in 1349.06s 
-- train score: 0.60892095102621, cost 901.70s 
-- test score: 0.48544212796549, cost 445.35s 
-- epoch 95 
-- finished epoch in 1348.86s 
-- train score: 0.60820971347287, cost 901.54s 
-- test score: 0.48454349388929, cost 445.90s 
-- epoch 96 
-- finished epoch in 1350.10s 
-- train score: 0.61139758179232, cost 901.68s 
-- test score: 0.48626373626374, cost 445.72s 
-- epoch 97 
-- finished epoch in 1350.22s 
-- train score: 0.60956868522658, cost 903.33s 
-- test score: 0.48644346307898, cost 446.76s 
-- epoch 98 
-- finished epoch in 1351.05s 
-- train score: 0.61355669579354, cost 903.69s 
-- test score: 0.48929341686351, cost 446.33s 
-- epoch 99 
-- finished epoch in 1351.01s 
-- train score: 0.6161603332656, cost 904.28s 
-- test score: 0.4876245250077, cost 446.23s 
-- epoch 100 
-- finished epoch in 1352.38s 
-- train score: 0.61638894533631, cost 903.95s 
-- test score: 0.48718804559926, cost 446.95s 
finished training in 271100.08s 
best dev score is: 0.48929341686351 
writing model to ./done/vqalstm-COCOQA-lstm.l1.d150.e98.c1-2016-01-25T135147.t7 
