[program started on Mon Dec  7 06:15:22 2015] 
[command line arguments] 
[----------------------] 
-------------------------------------------------------------------------------- 
LSTM for VQA 
-------------------------------------------------------------------------------- 
loading datasets 
process data at: /home/deepnet/lyt/vqa/dataset/data/DAQUAR/DAQUAR-ALL 
Process_all_totable ... 
load train set ... 
total lines: 13590 
max length: 31 min length: 7 
#images: 6795 #questions: 6795 #answers: 6795 
normalize image: 6808 
load test set ... 
total lines: 11346 
max length: 28 min length: 7 
#images: 5673 #questions: 5673 #answers: 5673 
normalize image: 5681 
build vocabulary ... 
word vocabulary: 856 
answer vocabulary: 969 
image vocabulary: 1447 
num train = 6795 
num test  = 5673 
loading features 
-------------------------------------------------------------------------------- 
model configuration 
-------------------------------------------------------------------------------- 
max epochs                = 70 
num params                = 326619 
num compositional params  = 180300 
word vector dim           = 50 
LSTM memory dim           = 150 
LSTM structure            = rnn 
LSTM layers               = 1 
regularization strength   = 1.00e-04 
minibatch size            = 1 
learning rate             = 5.00e-02 
word vector learning rate = 1.00e-01 
dropout                   = true 
cuda                      = true 
image feature dim         = 1000 
-------------------------------------------------------------------------------- 
Training model 
-------------------------------------------------------------------------------- 
-- epoch 1 
-- finished epoch in 20.83s 
-- train score: 0.02075055187638, cost 69.30s 
-- test score: 0.020800282037723, cost 59.35s 
-- epoch 2 
-- finished epoch in 20.49s 
-- train score: 0.035025754231052, cost 68.99s 
-- test score: 0.035607262471356, cost 55.05s 
-- epoch 3 
-- finished epoch in 19.16s 
-- train score: 0.045474613686534, cost 66.30s 
-- test score: 0.056583818085669, cost 55.26s 
-- epoch 4 
-- finished epoch in 19.17s 
-- train score: 0.075496688741722, cost 66.16s 
-- test score: 0.076150185087255, cost 55.18s 
-- epoch 5 
-- finished epoch in 20.96s 
-- train score: 0.11449595290655, cost 67.25s 
-- test score: 0.11510664551384, cost 54.17s 
-- epoch 6 
-- finished epoch in 19.28s 
-- train score: 0.13539367181751, cost 64.87s 
-- test score: 0.13661202185792, cost 54.04s 
-- epoch 7 
-- finished epoch in 18.89s 
-- train score: 0.1551140544518, cost 64.78s 
-- test score: 0.1544156530936, cost 54.05s 
-- epoch 8 
-- finished epoch in 18.87s 
-- train score: 0.17895511405445, cost 64.68s 
-- test score: 0.16534461484224, cost 53.92s 
-- epoch 9 
-- finished epoch in 18.89s 
-- train score: 0.1924944812362, cost 64.74s 
-- test score: 0.17239555790587, cost 54.04s 
-- epoch 10 
-- finished epoch in 18.88s 
-- train score: 0.19867549668874, cost 64.81s 
-- test score: 0.17821258593337, cost 54.07s 
-- epoch 11 
-- finished epoch in 18.90s 
-- train score: 0.21604120676968, cost 64.66s 
-- test score: 0.18261942534814, cost 53.95s 
-- epoch 12 
-- finished epoch in 18.87s 
-- train score: 0.23002207505519, cost 64.82s 
-- test score: 0.18896527410541, cost 55.22s 
-- epoch 13 
-- finished epoch in 19.82s 
-- train score: 0.24238410596026, cost 66.56s 
-- test score: 0.19178565133087, cost 54.05s 
-- epoch 14 
-- finished epoch in 18.90s 
-- train score: 0.24032376747609, cost 64.73s 
-- test score: 0.19019918914155, cost 53.97s 
-- epoch 15 
-- finished epoch in 18.89s 
-- train score: 0.26578366445916, cost 64.68s 
-- test score: 0.19531112286268, cost 53.99s 
-- epoch 16 
-- finished epoch in 19.52s 
-- train score: 0.2794701986755, cost 67.93s 
-- test score: 0.18931782125859, cost 56.43s 
-- epoch 17 
-- finished epoch in 19.33s 
-- train score: 0.28373804267844, cost 65.00s 
-- test score: 0.20747399964745, cost 54.23s 
-- epoch 18 
-- finished epoch in 19.97s 
-- train score: 0.29992641648271, cost 65.73s 
-- test score: 0.20236206592632, cost 54.23s 
-- epoch 19 
-- finished epoch in 18.90s 
-- train score: 0.30728476821192, cost 65.00s 
-- test score: 0.20359598096245, cost 54.23s 
-- epoch 20 
-- finished epoch in 18.92s 
-- train score: 0.30919793966152, cost 64.98s 
-- test score: 0.20482989599859, cost 54.23s 
-- epoch 21 
-- finished epoch in 18.82s 
-- train score: 0.33318616629875, cost 65.01s 
-- test score: 0.20641635818791, cost 54.17s 
-- epoch 22 
-- finished epoch in 18.90s 
-- train score: 0.34054451802796, cost 65.02s 
-- test score: 0.20729772607086, cost 54.22s 
-- epoch 23 
-- finished epoch in 18.92s 
-- train score: 0.37674760853569, cost 64.96s 
-- test score: 0.21011810329632, cost 54.18s 
-- epoch 24 
-- finished epoch in 20.34s 
-- train score: 0.35069904341428, cost 66.17s 
-- test score: 0.204653622422, cost 53.98s 
-- epoch 25 
-- finished epoch in 18.85s 
-- train score: 0.3860191317145, cost 64.66s 
-- test score: 0.20676890534109, cost 54.02s 
-- epoch 26 
-- finished epoch in 18.90s 
-- train score: 0.38866813833701, cost 66.08s 
-- test score: 0.20482989599859, cost 53.92s 
-- epoch 27 
-- finished epoch in 18.93s 
-- train score: 0.40735835172921, cost 64.73s 
-- test score: 0.20694517891768, cost 54.01s 
-- epoch 28 
-- finished epoch in 18.86s 
-- train score: 0.40956585724798, cost 64.66s 
-- test score: 0.20447734884541, cost 53.91s 
-- epoch 29 
-- finished epoch in 18.94s 
-- train score: 0.41780721118469, cost 64.63s 
-- test score: 0.20571126388154, cost 53.96s 
-- epoch 30 
-- finished epoch in 18.86s 
-- train score: 0.43340691685063, cost 64.63s 
-- test score: 0.20324343380927, cost 53.93s 
-- epoch 31 
-- finished epoch in 19.85s 
-- train score: 0.45253863134658, cost 64.74s 
-- test score: 0.20430107526882, cost 53.93s 
-- epoch 32 
-- finished epoch in 18.92s 
-- train score: 0.46387049300957, cost 64.68s 
-- test score: 0.20042305658382, cost 53.92s 
-- epoch 33 
-- finished epoch in 18.87s 
-- train score: 0.47402501839588, cost 64.72s 
-- test score: 0.19513484928609, cost 54.04s 
-- epoch 34 
-- finished epoch in 18.91s 
-- train score: 0.48094186902134, cost 64.63s 
-- test score: 0.2065926317645, cost 53.92s 
-- epoch 35 
-- finished epoch in 20.70s 
-- train score: 0.47726269315673, cost 65.52s 
-- test score: 0.20253833950291, cost 54.22s 
-- epoch 36 
-- finished epoch in 18.88s 
-- train score: 0.50757910228109, cost 65.00s 
-- test score: 0.20359598096245, cost 54.28s 
-- epoch 37 
-- finished epoch in 18.89s 
-- train score: 0.50993377483444, cost 65.01s 
-- test score: 0.20306716023268, cost 54.21s 
-- epoch 38 
-- finished epoch in 18.87s 
-- train score: 0.52891832229581, cost 65.05s 
-- test score: 0.19813150008814, cost 54.19s 
-- epoch 39 
-- finished epoch in 18.91s 
-- train score: 0.53156732891832, cost 65.02s 
-- test score: 0.19266701921382, cost 54.15s 
-- epoch 40 
-- finished epoch in 18.89s 
-- train score: 0.54937454010302, cost 64.98s 
-- test score: 0.20183324519655, cost 54.19s 
-- epoch 41 
-- finished epoch in 18.91s 
-- train score: 0.54142752023547, cost 65.05s 
-- test score: 0.20218579234973, cost 54.23s 
-- epoch 42 
-- finished epoch in 18.91s 
-- train score: 0.54142752023547, cost 64.98s 
-- test score: 0.20236206592632, cost 73.41s 
-- epoch 43 
-- finished epoch in 19.65s 
-- train score: 0.57512877115526, cost 93.62s 
-- test score: 0.19901286797109, cost 82.98s 
-- epoch 44 
-- finished epoch in 19.58s 
-- train score: 0.57777777777778, cost 93.46s 
-- test score: 0.19901286797109, cost 82.74s 
-- epoch 45 
-- finished epoch in 19.62s 
-- train score: 0.57777777777778, cost 93.52s 
-- test score: 0.196897585052, cost 82.47s 
-- epoch 46 
-- finished epoch in 19.68s 
-- train score: 0.6, cost 92.23s 
-- test score: 0.20253833950291, cost 82.60s 
-- epoch 47 
-- finished epoch in 19.66s 
-- train score: 0.59985283296542, cost 92.09s 
-- test score: 0.19601621716905, cost 82.42s 
-- epoch 48 
-- finished epoch in 19.62s 
-- train score: 0.60044150110375, cost 92.14s 
-- test score: 0.19425348140314, cost 82.39s 
-- epoch 49 
-- finished epoch in 19.59s 
-- train score: 0.60897718910964, cost 92.19s 
-- test score: 0.20218579234973, cost 82.38s 
-- epoch 50 
-- finished epoch in 19.66s 
-- train score: 0.59470198675497, cost 92.09s 
-- test score: 0.19354838709677, cost 81.04s 
-- epoch 51 
-- finished epoch in 19.62s 
-- train score: 0.63649742457689, cost 94.05s 
-- test score: 0.19160937775427, cost 81.27s 
-- epoch 52 
-- finished epoch in 19.62s 
-- train score: 0.63061074319352, cost 93.69s 
-- test score: 0.200775603737, cost 81.29s 
-- epoch 53 
-- finished epoch in 19.62s 
-- train score: 0.63046357615894, cost 93.44s 
-- test score: 0.20007050943064, cost 81.31s 
-- epoch 54 
-- finished epoch in 19.66s 
-- train score: 0.64120676968359, cost 94.22s 
-- test score: 0.19619249074564, cost 81.65s 
-- epoch 55 
-- finished epoch in 19.67s 
-- train score: 0.6476821192053, cost 94.24s 
-- test score: 0.19178565133087, cost 81.51s 
-- epoch 56 
-- finished epoch in 19.65s 
-- train score: 0.63340691685063, cost 92.34s 
-- test score: 0.19284329279041, cost 82.40s 
-- epoch 57 
-- finished epoch in 20.98s 
-- train score: 0.65445180279617, cost 92.76s 
-- test score: 0.19548739643927, cost 82.56s 
-- epoch 58 
-- finished epoch in 19.79s 
-- train score: 0.65813097866078, cost 92.23s 
-- test score: 0.19284329279041, cost 79.91s 
-- epoch 59 
-- finished epoch in 19.77s 
-- train score: 0.66033848417954, cost 92.90s 
-- test score: 0.19196192490746, cost 82.36s 
-- epoch 60 
-- finished epoch in 22.26s 
-- train score: 0.65504047093451, cost 92.11s 
-- test score: 0.1949585757095, cost 82.33s 
-- epoch 61 
-- finished epoch in 19.66s 
-- train score: 0.68270787343635, cost 92.25s 
-- test score: 0.19019918914155, cost 82.53s 
-- epoch 62 
-- finished epoch in 19.57s 
-- train score: 0.68417954378219, cost 92.62s 
-- test score: 0.18050414242905, cost 82.38s 
-- epoch 63 
-- finished epoch in 19.65s 
-- train score: 0.68285504047093, cost 92.13s 
-- test score: 0.19143310417768, cost 82.49s 
-- epoch 64 
-- finished epoch in 19.69s 
-- train score: 0.68520971302428, cost 92.21s 
-- test score: 0.19390093424996, cost 82.44s 
-- epoch 65 
-- finished epoch in 19.67s 
-- train score: 0.69948491537896, cost 92.24s 
-- test score: 0.1910805570245, cost 82.38s 
-- epoch 66 
-- finished epoch in 19.65s 
-- train score: 0.70066225165563, cost 92.16s 
-- test score: 0.19125683060109, cost 82.45s 
-- epoch 67 
-- finished epoch in 19.67s 
-- train score: 0.69565857247976, cost 92.28s 
-- test score: 0.19742640578177, cost 82.55s 
-- epoch 68 
-- finished epoch in 19.64s 
-- train score: 0.71169977924945, cost 92.45s 
-- test score: 0.18755508549268, cost 82.83s 
-- epoch 69 
-- finished epoch in 20.94s 
-- train score: 0.69050772626932, cost 92.46s 
-- test score: 0.18350079323109, cost 82.55s 
-- epoch 70 
-- finished epoch in 19.61s 
-- train score: 0.71346578366446, cost 92.35s 
-- test score: 0.18561607615019, cost 82.57s 
finished training in 11309.30s 
best dev score is: 0.21011810329632 
writing model to ./done/vqalstm-rnn.l1.d150.e23.c1-2015-12-07T092352.t7 
