[program started on Wed Jan 20 20:55:26 2016] 
[command line arguments] 
[----------------------] 
-------------------------------------------------------------------------------- 
LSTM for VQA with text only 
-------------------------------------------------------------------------------- 
loading COCOQA datasets 
Append captions with question done. 
Remove determiner done. 
num train = 78736 
num test  = 38948 
-------------------------------------------------------------------------------- 
model configuration 
-------------------------------------------------------------------------------- 
max epochs                = 100 
num params                = 186130 
num compositional params  = 121200 
word vector dim           = 50 
LSTM memory dim           = 150 
LSTM structure            = lstm 
LSTM layers               = 1 
regularization strength   = 1.00e-04 
minibatch size            = 1 
learning rate             = 5.00e-02 
word vector learning rate = 1.00e-01 
dropout                   = true 
cuda                      = true 
image feature dim         = [text only] 
-------------------------------------------------------------------------------- 
Training model 
-------------------------------------------------------------------------------- 
-- epoch 1 
-- finished epoch in 2518.25s 
-- train score: 0.44504419833367, cost 1325.61s 
-- test score: 0.44007394474684, cost 675.54s 
-- epoch 2 
-- finished epoch in 2681.89s 
-- train score: 0.53017679333469, cost 1338.65s 
-- test score: 0.51961589812057, cost 639.43s 
-- epoch 3 
-- finished epoch in 2494.48s 
-- train score: 0.55650528347897, cost 1363.95s 
-- test score: 0.54066961076307, cost 672.71s 
-- epoch 4 
-- finished epoch in 2460.92s 
-- train score: 0.57640723430197, cost 1289.43s 
-- test score: 0.55299373523673, cost 637.09s 
-- epoch 5 
-- finished epoch in 2408.79s 
-- train score: 0.59009855720382, cost 1289.57s 
-- test score: 0.5594639005854, cost 636.88s 
-- epoch 6 
-- finished epoch in 2413.72s 
-- train score: 0.59868421052632, cost 1292.36s 
-- test score: 0.56631919482387, cost 636.80s 
-- epoch 7 
-- finished epoch in 2406.51s 
-- train score: 0.61250254013412, cost 1289.96s 
-- test score: 0.57191640135565, cost 639.31s 
-- epoch 8 
-- finished epoch in 2413.28s 
-- train score: 0.61981812639707, cost 1289.76s 
-- test score: 0.57476635514019, cost 637.52s 
-- epoch 9 
-- finished epoch in 2410.75s 
-- train score: 0.62797195691933, cost 1307.15s 
-- test score: 0.57602444284687, cost 679.01s 
-- epoch 10 
-- finished epoch in 2435.30s 
-- train score: 0.63681162365373, cost 1383.25s 
-- test score: 0.57766765944336, cost 683.43s 
-- epoch 11 
-- finished epoch in 2434.42s 
-- train score: 0.64327626498679, cost 1384.25s 
-- test score: 0.57728253055356, cost 683.40s 
-- epoch 12 
-- finished epoch in 2435.04s 
-- train score: 0.64825492786019, cost 1384.29s 
-- test score: 0.5786176440382, cost 683.42s 
-- epoch 13 
-- finished epoch in 2434.32s 
-- train score: 0.65480847388742, cost 1384.30s 
-- test score: 0.57918249974325, cost 679.23s 
-- epoch 14 
-- finished epoch in 2426.62s 
-- train score: 0.66160333265596, cost 1290.48s 
-- test score: 0.58228920612098, cost 637.30s 
-- epoch 15 
-- finished epoch in 2407.46s 
-- train score: 0.66858870148344, cost 1288.74s 
-- test score: 0.58044058744993, cost 636.44s 
-- epoch 16 
-- finished epoch in 2406.43s 
-- train score: 0.67441830928673, cost 1289.33s 
-- test score: 0.57877169559413, cost 636.22s 
-- epoch 17 
-- finished epoch in 2416.26s 
-- train score: 0.67694574273522, cost 1380.85s 
-- test score: 0.58139057204478, cost 682.15s 
-- epoch 18 
-- finished epoch in 2431.31s 
-- train score: 0.68523928063402, cost 1341.81s 
-- test score: 0.58077436582109, cost 638.12s 
-- epoch 19 
-- finished epoch in 2407.20s 
-- train score: 0.69134830319041, cost 1290.45s 
-- test score: 0.57969600492965, cost 637.11s 
-- epoch 20 
-- finished epoch in 2407.18s 
-- train score: 0.69518390571022, cost 1289.05s 
-- test score: 0.58008113381945, cost 636.68s 
-- epoch 21 
-- finished epoch in 2409.36s 
-- train score: 0.69929892298313, cost 1289.24s 
-- test score: 0.5774622573688, cost 636.40s 
-- epoch 22 
-- finished epoch in 2408.09s 
-- train score: 0.70376955903272, cost 1290.03s 
-- test score: 0.57900277292801, cost 636.78s 
-- epoch 23 
-- finished epoch in 2407.29s 
-- train score: 0.70810048770575, cost 1290.21s 
-- test score: 0.57933655129917, cost 636.52s 
-- epoch 24 
-- finished epoch in 2406.63s 
-- train score: 0.71288864052022, cost 1290.19s 
-- test score: 0.57820683988908, cost 636.83s 
-- epoch 25 
-- finished epoch in 2407.02s 
-- train score: 0.71394279617964, cost 1288.87s 
-- test score: 0.57969600492965, cost 636.57s 
-- epoch 26 
-- finished epoch in 2407.27s 
-- train score: 0.72200772200772, cost 1289.49s 
-- test score: 0.57979870596693, cost 636.22s 
-- epoch 27 
-- finished epoch in 2407.22s 
-- train score: 0.72595763056289, cost 1290.57s 
-- test score: 0.57617849440279, cost 636.93s 
-- epoch 28 
-- finished epoch in 2406.35s 
-- train score: 0.73049176996545, cost 1290.11s 
-- test score: 0.57466365410291, cost 636.60s 
-- epoch 29 
-- finished epoch in 2406.07s 
-- train score: 0.73334942084942, cost 1290.44s 
-- test score: 0.57625552018075, cost 636.98s 
-- epoch 30 
-- finished epoch in 2406.64s 
-- train score: 0.73822647835806, cost 1288.74s 
-- test score: 0.57679470062648, cost 636.46s 
-- epoch 31 
-- finished epoch in 2406.28s 
