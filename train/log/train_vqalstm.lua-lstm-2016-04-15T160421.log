[program started on Fri Apr 15 16:04:21 2016] 
[command line arguments] 
rmdeter false 
caponly false 
dataset COCOQA 
cuda true 
caption false 
epochs 50 
modelclass ImageVQA 
capopt origin 
model lstm 
textonly false 
layers 1 
im_fea_dim 4096 
dim 150 
[----------------------] 
-------------------------------------------------------------------------------- 
LSTM for VQA 
-------------------------------------------------------------------------------- 
loading COCOQA datasets 
loading features 
num train = 78736 
num test  = 38948 
-------------------------------------------------------------------------------- 
model configuration 
-------------------------------------------------------------------------------- 
max epochs                = 50 
num params                = 1761710 
num compositional params  = 0 
regularization strength   = 1.00e-04 
minibatch size            = 1 
learning rate             = 5.00e-02 
dropout                   = true 
cuda                      = true 
image (only) feature dim  = 4096 
-------------------------------------------------------------------------------- 
Training model 
-------------------------------------------------------------------------------- 
-- epoch 1 
-- finished epoch in 104.38s 
-- train score: 0.36914499085552, cost 384.70s 
-- test score: 0.24124473657184, cost 197.97s 
-- epoch 2 
-- finished epoch in 105.19s 
-- train score: 0.42041759804918, cost 386.49s 
-- test score: 0.2447622470987, cost 187.00s 
-- epoch 3 
-- finished epoch in 104.69s 
-- train score: 0.4540870757976, cost 381.53s 
-- test score: 0.24740679880867, cost 193.15s 
-- epoch 4 
-- finished epoch in 104.18s 
-- train score: 0.47978053241211, cost 389.44s 
-- test score: 0.24889596384923, cost 191.43s 
-- epoch 5 
-- finished epoch in 104.79s 
-- train score: 0.50158758382443, cost 381.74s 
-- test score: 0.24124473657184, cost 193.15s 
-- epoch 6 
-- finished epoch in 104.71s 
-- train score: 0.51494868929079, cost 387.29s 
-- test score: 0.24373523672589, cost 188.04s 
-- epoch 7 
-- finished epoch in 103.75s 
-- train score: 0.524893314367, cost 385.01s 
-- test score: 0.24412036561569, cost 190.15s 
-- epoch 8 
-- finished epoch in 103.95s 
-- train score: 0.52997358260516, cost 389.10s 
-- test score: 0.24435144294957, cost 188.07s 
-- epoch 9 
-- finished epoch in 104.03s 
-- train score: 0.5550193050193, cost 374.85s 
-- test score: 0.25130943822533, cost 185.87s 
-- epoch 10 
-- finished epoch in 103.52s 
-- train score: 0.54299176996545, cost 383.74s 
-- test score: 0.23536510218753, cost 187.54s 
-- epoch 11 
-- finished epoch in 103.18s 
-- train score: 0.557508636456, cost 386.26s 
-- test score: 0.24530142754442, cost 188.06s 
-- epoch 12 
-- finished epoch in 103.24s 
-- train score: 0.56403678114204, cost 388.30s 
-- test score: 0.25238779911677, cost 183.90s 
-- epoch 13 
-- finished epoch in 103.80s 
-- train score: 0.57403220890063, cost 388.06s 
-- test score: 0.24845948444079, cost 185.05s 
-- epoch 14 
-- finished epoch in 103.47s 
-- train score: 0.58273216825848, cost 375.17s 
-- test score: 0.25269590222861, cost 187.82s 
-- epoch 15 
-- finished epoch in 103.63s 
-- train score: 0.57840123958545, cost 387.34s 
-- test score: 0.25261887645065, cost 182.92s 
-- epoch 16 
-- finished epoch in 103.93s 
-- train score: 0.58156370656371, cost 379.04s 
-- test score: 0.25151484029989, cost 184.21s 
-- epoch 17 
-- finished epoch in 104.94s 
-- train score: 0.59200365779313, cost 382.12s 
-- test score: 0.25724042312827, cost 178.65s 
-- epoch 18 
-- finished epoch in 103.07s 
-- train score: 0.59389605771185, cost 379.45s 
-- test score: 0.25279860326589, cost 186.87s 
-- epoch 19 
-- finished epoch in 103.86s 
-- train score: 0.58249085551717, cost 384.07s 
-- test score: 0.25397966519462, cost 187.93s 
-- epoch 20 
-- finished epoch in 103.23s 
-- train score: 0.59731253810201, cost 380.05s 
-- test score: 0.25426209304714, cost 193.75s 
-- epoch 21 
-- finished epoch in 103.40s 
-- train score: 0.59957325746799, cost 381.98s 
-- test score: 0.2535688610455, cost 188.18s 
-- epoch 22 
-- finished epoch in 103.51s 
-- train score: 0.601770473481, cost 380.29s 
-- test score: 0.25346616000822, cost 187.55s 
-- epoch 23 
-- finished epoch in 103.07s 
-- train score: 0.60385338345865, cost 382.70s 
-- test score: 0.26042415528397, cost 185.90s 
-- epoch 24 
-- finished epoch in 103.52s 
-- train score: 0.60605059947165, cost 384.11s 
-- test score: 0.25962822224504, cost 184.36s 
-- epoch 25 
-- finished epoch in 103.17s 
-- train score: 0.61149918715708, cost 375.17s 
-- test score: 0.25785662935196, cost 186.79s 
-- epoch 26 
-- finished epoch in 103.07s 
-- train score: 0.61101656167446, cost 377.72s 
-- test score: 0.25921741809592, cost 182.66s 
-- epoch 27 
-- finished epoch in 103.22s 
-- train score: 0.6067491363544, cost 379.73s 
-- test score: 0.26042415528397, cost 187.80s 
-- epoch 28 
-- finished epoch in 102.82s 
-- train score: 0.61382340987604, cost 374.88s 
-- test score: 0.26286330491938, cost 172.37s 
-- epoch 29 
-- finished epoch in 97.72s 
-- train score: 0.61605872790083, cost 333.67s 
-- test score: 0.26027010372805, cost 164.94s 
-- epoch 30 
-- finished epoch in 97.76s 
-- train score: 0.61508077626499, cost 333.54s 
-- test score: 0.26527677929547, cost 164.96s 
-- epoch 31 
-- finished epoch in 97.68s 
-- train score: 0.61783682178419, cost 333.73s 
-- test score: 0.25924309335524, cost 165.06s 
-- epoch 32 
-- finished epoch in 97.68s 
-- train score: 0.61539829302987, cost 333.77s 
-- test score: 0.2630173564753, cost 165.08s 
-- epoch 33 
-- finished epoch in 97.65s 
-- train score: 0.61101656167446, cost 333.70s 
-- test score: 0.25521207764198, cost 165.03s 
-- epoch 34 
-- finished epoch in 97.66s 
-- train score: 0.61655405405405, cost 333.62s 
-- test score: 0.2632741090685, cost 164.99s 
-- epoch 35 
-- finished epoch in 97.64s 
-- train score: 0.62021184718553, cost 333.78s 
-- test score: 0.26355653692102, cost 165.02s 
-- epoch 36 
-- finished epoch in 97.65s 
-- train score: 0.62356482422272, cost 333.83s 
-- test score: 0.26597001129711, cost 165.06s 
-- epoch 37 
-- finished epoch in 97.65s 
-- train score: 0.62513970737655, cost 333.72s 
-- test score: 0.26229844921434, cost 164.96s 
-- epoch 38 
-- finished epoch in 97.68s 
-- train score: 0.62146921357448, cost 333.75s 
-- test score: 0.26019307795009, cost 165.01s 
-- epoch 39 
-- finished epoch in 97.66s 
-- train score: 0.62298059337533, cost 333.67s 
-- test score: 0.26270925336346, cost 165.00s 
-- epoch 40 
-- finished epoch in 97.67s 
-- train score: 0.6274893314367, cost 333.44s 
-- test score: 0.26258087706686, cost 164.90s 
-- epoch 41 
-- finished epoch in 97.66s 
-- train score: 0.62642247510669, cost 333.63s 
-- test score: 0.26060388209921, cost 164.97s 
-- epoch 42 
-- finished epoch in 97.65s 
-- train score: 0.62439036781142, cost 333.58s 
-- test score: 0.26496867618363, cost 164.95s 
-- epoch 43 
-- finished epoch in 97.65s 
-- train score: 0.6208468807153, cost 333.62s 
-- test score: 0.26073225839581, cost 164.97s 
-- epoch 44 
-- finished epoch in 97.70s 
-- train score: 0.6222439544808, cost 333.72s 
-- test score: 0.26291465543802, cost 164.99s 
-- epoch 45 
-- finished epoch in 97.64s 
-- train score: 0.6283148750254, cost 333.73s 
-- test score: 0.26278627914142, cost 164.98s 
-- epoch 46 
-- finished epoch in 97.63s 
-- train score: 0.62980085348506, cost 333.67s 
-- test score: 0.2677416041902, cost 164.95s 
-- epoch 47 
-- finished epoch in 97.60s 
-- train score: 0.61811623653729, cost 333.79s 
-- test score: 0.26242682551094, cost 165.07s 
-- epoch 48 
-- finished epoch in 97.59s 
-- train score: 0.63112172322699, cost 333.82s 
-- test score: 0.26283762966006, cost 165.07s 
-- epoch 49 
-- finished epoch in 97.59s 
-- train score: 0.62959764275554, cost 333.65s 
-- test score: 0.26982130019513, cost 165.01s 
-- epoch 50 
-- finished epoch in 97.59s 
-- train score: 0.62220585246901, cost 333.56s 
-- test score: 0.25703502105371, cost 164.96s 
finished training in 31973.17s 
best dev score is: 0.26982130019513 
writing model to ./done/vqalstm-COCOQA-lstm.l1.d150.e49.c1-2016-04-16T005737.t7 
