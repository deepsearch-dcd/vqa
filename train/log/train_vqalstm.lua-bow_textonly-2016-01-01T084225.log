[program started on Fri Jan  1 08:42:25 2016] 
[command line arguments] 
[----------------------] 
-------------------------------------------------------------------------------- 
LSTM for VQA with text only 
-------------------------------------------------------------------------------- 
loading COCOQA datasets 
Remove determiner done. 
num train = 78736 
num test  = 38948 
-------------------------------------------------------------------------------- 
model configuration 
-------------------------------------------------------------------------------- 
max epochs                = 50 
num params                = 72580 
num compositional params  = 7650 
word vector dim           = 50 
LSTM memory dim           = 150 
LSTM structure            = bow 
LSTM layers               = 1 
regularization strength   = 1.00e-04 
minibatch size            = 1 
learning rate             = 5.00e-02 
word vector learning rate = 1.00e-01 
dropout                   = true 
cuda                      = true 
image feature dim         = [text only] 
-------------------------------------------------------------------------------- 
Training model 
-------------------------------------------------------------------------------- 
-- epoch 1 
-- finished epoch in 137.63s 
-- train score: 0.33583113188376, cost 563.20s 
-- test score: 0.30895039539899, cost 247.87s 
-- epoch 2 
-- finished epoch in 131.27s 
-- train score: 0.371138996139, cost 537.81s 
-- test score: 0.3366540002054, cost 249.49s 
-- epoch 3 
-- finished epoch in 130.71s 
-- train score: 0.39509246088193, cost 537.43s 
-- test score: 0.34281606244223, cost 247.48s 
-- epoch 4 
-- finished epoch in 130.80s 
-- train score: 0.4156548465759, cost 545.69s 
-- test score: 0.35419020232104, cost 247.71s 
-- epoch 5 
-- finished epoch in 130.47s 
-- train score: 0.43292775858565, cost 537.17s 
-- test score: 0.36209818219164, cost 247.89s 
-- epoch 6 
-- finished epoch in 130.56s 
-- train score: 0.44733031904085, cost 542.44s 
-- test score: 0.3617900790798, cost 247.43s 
-- epoch 7 
-- finished epoch in 130.44s 
-- train score: 0.45636049583418, cost 538.28s 
-- test score: 0.36510218753209, cost 241.19s 
-- epoch 8 
-- finished epoch in 117.93s 
-- train score: 0.45976427555375, cost 526.34s 
-- test score: 0.3665143267947, cost 241.42s 
-- epoch 9 
-- finished epoch in 118.08s 
-- train score: 0.46950568990043, cost 525.93s 
-- test score: 0.36661702783198, cost 241.48s 
-- epoch 10 
-- finished epoch in 117.93s 
-- train score: 0.47135998780736, cost 528.73s 
-- test score: 0.36266303789668, cost 241.29s 
-- epoch 11 
-- finished epoch in 117.97s 
-- train score: 0.48935683804105, cost 529.51s 
-- test score: 0.36707918249974, cost 241.05s 
-- epoch 12 
-- finished epoch in 118.00s 
-- train score: 0.48493700467385, cost 529.40s 
-- test score: 0.36415220293725, cost 241.13s 
-- epoch 13 
-- finished epoch in 117.97s 
-- train score: 0.50006350335298, cost 529.53s 
-- test score: 0.37080209510116, cost 241.32s 
-- epoch 14 
-- finished epoch in 126.87s 
-- train score: 0.50929689087584, cost 538.40s 
-- test score: 0.37167505391804, cost 248.19s 
-- epoch 15 
-- finished epoch in 130.38s 
-- train score: 0.51103688274741, cost 542.55s 
-- test score: 0.36743863613022, cost 247.52s 
-- epoch 16 
-- finished epoch in 130.26s 
-- train score: 0.5199146514936, cost 543.62s 
-- test score: 0.36921022902331, cost 247.83s 
-- epoch 17 
-- finished epoch in 141.11s 
-- train score: 0.52383915870758, cost 536.21s 
-- test score: 0.36777241450139, cost 247.91s 
-- epoch 18 
-- finished epoch in 127.33s 
-- train score: 0.53728916886812, cost 365.65s 
-- test score: 0.36964670843176, cost 180.69s 
-- epoch 19 
-- finished epoch in 121.99s 
-- train score: 0.53731457020931, cost 365.60s 
-- test score: 0.37239396117901, cost 180.79s 
-- epoch 20 
-- finished epoch in 118.64s 
-- train score: 0.53690814875025, cost 359.01s 
-- test score: 0.37003183732156, cost 178.55s 
-- epoch 21 
-- finished epoch in 122.02s 
-- train score: 0.54026112578744, cost 354.12s 
-- test score: 0.3671562082777, cost 173.04s 
-- epoch 22 
-- finished epoch in 109.78s 
-- train score: 0.5450873806137, cost 350.67s 
-- test score: 0.36813186813187, cost 173.35s 
-- epoch 23 
-- finished epoch in 109.81s 
-- train score: 0.5547652916074, cost 350.59s 
-- test score: 0.36964670843176, cost 173.26s 
-- epoch 24 
-- finished epoch in 109.83s 
-- train score: 0.5514377159114, cost 350.68s 
-- test score: 0.3713669508062, cost 178.38s 
-- epoch 25 
-- finished epoch in 122.41s 
-- train score: 0.55371113594798, cost 367.41s 
-- test score: 0.36815754339119, cost 181.63s 
-- epoch 26 
-- finished epoch in 117.27s 
-- train score: 0.55844848608007, cost 355.50s 
-- test score: 0.37272773955017, cost 181.00s 
-- epoch 27 
-- finished epoch in 118.75s 
-- train score: 0.56697063604958, cost 364.32s 
-- test score: 0.37254801273493, cost 180.82s 
-- epoch 28 
-- finished epoch in 122.25s 
-- train score: 0.56965047754521, cost 366.14s 
-- test score: 0.37277909006881, cost 180.98s 
-- epoch 29 
-- finished epoch in 122.29s 
-- train score: 0.56594188173136, cost 366.18s 
-- test score: 0.36497381123549, cost 181.04s 
-- epoch 30 
-- finished epoch in 118.69s 
-- train score: 0.57365118878277, cost 364.13s 
-- test score: 0.36974940946904, cost 172.05s 
-- epoch 31 
-- finished epoch in 111.65s 
-- train score: 0.57822343019711, cost 361.18s 
-- test score: 0.37265071377221, cost 175.06s 
-- epoch 32 
-- finished epoch in 113.32s 
-- train score: 0.57643263564316, cost 350.75s 
-- test score: 0.37067371880456, cost 173.00s 
-- epoch 33 
-- finished epoch in 110.26s 
-- train score: 0.57856634830319, cost 350.25s 
-- test score: 0.36710485775906, cost 173.10s 
-- epoch 34 
-- finished epoch in 110.16s 
-- train score: 0.58698689290795, cost 349.97s 
-- test score: 0.36962103317244, cost 173.03s 
-- epoch 35 
-- finished epoch in 112.20s 
-- train score: 0.58609784596627, cost 349.67s 
-- test score: 0.36944130635719, cost 173.09s 
-- epoch 36 
-- finished epoch in 111.84s 
-- train score: 0.59134322292217, cost 351.18s 
-- test score: 0.37044264147068, cost 173.60s 
-- epoch 37 
-- finished epoch in 110.22s 
-- train score: 0.59242277992278, cost 351.14s 
-- test score: 0.36885077539283, cost 173.60s 
-- epoch 38 
-- finished epoch in 110.27s 
-- train score: 0.59158453566348, cost 350.80s 
-- test score: 0.37344664681113, cost 173.51s 
-- epoch 39 
-- finished epoch in 110.29s 
-- train score: 0.59242277992278, cost 350.65s 
-- test score: 0.37116154873164, cost 173.40s 
-- epoch 40 
-- finished epoch in 110.30s 
-- train score: 0.59244818126397, cost 350.84s 
-- test score: 0.36309951730512, cost 173.45s 
-- epoch 41 
-- finished epoch in 110.34s 
-- train score: 0.59352773826458, cost 350.27s 
-- test score: 0.36512786279141, cost 173.14s 
-- epoch 42 
-- finished epoch in 110.45s 
-- train score: 0.59215606584028, cost 351.07s 
-- test score: 0.36985211050632, cost 173.58s 
-- epoch 43 
-- finished epoch in 112.02s 
-- train score: 0.59613137573664, cost 350.00s 
-- test score: 0.37167505391804, cost 173.01s 
-- epoch 44 
-- finished epoch in 110.24s 
-- train score: 0.60375177809388, cost 350.06s 
-- test score: 0.3660008216083, cost 173.11s 
-- epoch 45 
-- finished epoch in 110.18s 
-- train score: 0.60189748018695, cost 349.38s 
-- test score: 0.36723323405566, cost 172.77s 
-- epoch 46 
-- finished epoch in 113.48s 
-- train score: 0.60386608412924, cost 349.87s 
-- test score: 0.36751566190819, cost 172.88s 
-- epoch 47 
-- finished epoch in 114.58s 
-- train score: 0.60594899410689, cost 351.02s 
-- test score: 0.36646297627606, cost 173.56s 
-- epoch 48 
-- finished epoch in 110.37s 
-- train score: 0.60335805730543, cost 350.73s 
-- test score: 0.36553866694054, cost 173.45s 
-- epoch 49 
-- finished epoch in 113.90s 
-- train score: 0.61111816703922, cost 350.49s 
-- test score: 0.36566704323714, cost 173.18s 
-- epoch 50 
-- finished epoch in 110.13s 
-- train score: 0.61012751473278, cost 350.02s 
-- test score: 0.36802916709459, cost 173.04s 
finished training in 36708.19s 
best dev score is: 0.37344664681113 
writing model to ./done/vqalstm-COCOQA-bow_textonly.l1.d150.e38.c1-2016-01-01T185418.t7 
