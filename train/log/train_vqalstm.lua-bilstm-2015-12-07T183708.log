[program started on Mon Dec  7 18:37:08 2015] 
[command line arguments] 
[----------------------] 
-------------------------------------------------------------------------------- 
LSTM for VQA 
-------------------------------------------------------------------------------- 
loading datasets 
process data at: /home/deepnet/lyt/vqa/dataset/data/DAQUAR/DAQUAR-ALL 
Process_all_totable ... 
load train set ... 
total lines: 13590 
max length: 31 min length: 7 
#images: 6795 #questions: 6795 #answers: 6795 
normalize image: 6808 
load test set ... 
total lines: 11346 
max length: 28 min length: 7 
#images: 5673 #questions: 5673 #answers: 5673 
normalize image: 5681 
build vocabulary ... 
word vocabulary: 856 
answer vocabulary: 969 
image vocabulary: 1447 
num train = 6795 
num test  = 5673 
loading features 
-------------------------------------------------------------------------------- 
model configuration 
-------------------------------------------------------------------------------- 
max epochs                = 70 
num params                = 1012869 
num compositional params  = 721200 
word vector dim           = 50 
LSTM memory dim           = 150 
LSTM structure            = bilstm 
LSTM layers               = 1 
regularization strength   = 1.00e-04 
minibatch size            = 1 
learning rate             = 5.00e-02 
word vector learning rate = 1.00e-01 
dropout                   = true 
cuda                      = true 
image feature dim         = 1000 
-------------------------------------------------------------------------------- 
Training model 
-------------------------------------------------------------------------------- 
-- epoch 1 
-- finished epoch in 140.17s 
-- train score: 0.078587196467991, cost 114.18s 
-- test score: 0.094658910629297, cost 94.08s 
-- epoch 2 
-- finished epoch in 142.90s 
-- train score: 0.086975717439294, cost 113.97s 
-- test score: 0.096069099242024, cost 94.02s 
-- epoch 3 
-- finished epoch in 137.89s 
-- train score: 0.11979396615158, cost 112.29s 
-- test score: 0.11598801339679, cost 92.62s 
-- epoch 4 
-- finished epoch in 139.02s 
-- train score: 0.1467255334805, cost 113.02s 
-- test score: 0.1371408425877, cost 92.82s 
-- epoch 5 
-- finished epoch in 139.60s 
-- train score: 0.16953642384106, cost 112.32s 
-- test score: 0.15600211528292, cost 92.41s 
-- epoch 6 
-- finished epoch in 139.58s 
-- train score: 0.19426048565121, cost 113.51s 
-- test score: 0.17169046359951, cost 92.51s 
-- epoch 7 
-- finished epoch in 139.14s 
-- train score: 0.21824871228845, cost 111.28s 
-- test score: 0.18367706680769, cost 92.51s 
-- epoch 8 
-- finished epoch in 137.16s 
-- train score: 0.23502575423105, cost 111.29s 
-- test score: 0.19249074563723, cost 92.49s 
-- epoch 9 
-- finished epoch in 137.14s 
-- train score: 0.2588668138337, cost 112.22s 
-- test score: 0.19725013220518, cost 91.56s 
-- epoch 10 
-- finished epoch in 137.09s 
-- train score: 0.28079470198675, cost 110.18s 
-- test score: 0.21011810329632, cost 91.55s 
-- epoch 11 
-- finished epoch in 139.22s 
-- train score: 0.29845474613687, cost 110.41s 
-- test score: 0.2182266878195, cost 91.53s 
-- epoch 12 
-- finished epoch in 137.10s 
-- train score: 0.3252391464312, cost 111.00s 
-- test score: 0.20835536753041, cost 93.07s 
-- epoch 13 
-- finished epoch in 137.16s 
-- train score: 0.34849153789551, cost 110.36s 
-- test score: 0.21487748986427, cost 91.79s 
-- epoch 14 
-- finished epoch in 138.80s 
-- train score: 0.37777777777778, cost 110.25s 
-- test score: 0.20994182971973, cost 91.61s 
-- epoch 15 
-- finished epoch in 138.03s 
-- train score: 0.41221486387049, cost 111.34s 
-- test score: 0.21752159351313, cost 91.66s 
-- epoch 16 
-- finished epoch in 140.52s 
-- train score: 0.4457689477557, cost 110.44s 
-- test score: 0.21857923497268, cost 91.77s 
-- epoch 17 
-- finished epoch in 136.86s 
-- train score: 0.47093451066961, cost 110.42s 
-- test score: 0.21787414066631, cost 91.75s 
-- epoch 18 
-- finished epoch in 136.93s 
-- train score: 0.50066225165563, cost 110.16s 
-- test score: 0.20518244315177, cost 91.57s 
-- epoch 19 
-- finished epoch in 138.97s 
-- train score: 0.51582045621781, cost 110.19s 
-- test score: 0.22157588577472, cost 91.56s 
-- epoch 20 
-- finished epoch in 141.48s 
-- train score: 0.53406916850625, cost 112.92s 
-- test score: 0.22704036664904, cost 92.96s 
-- epoch 21 
-- finished epoch in 138.61s 
-- train score: 0.56924208977189, cost 110.43s 
-- test score: 0.22157588577472, cost 91.76s 
-- epoch 22 
-- finished epoch in 137.78s 
-- train score: 0.59896983075791, cost 110.98s 
-- test score: 0.21910805570245, cost 91.70s 
-- epoch 23 
-- finished epoch in 136.85s 
-- train score: 0.61559970566593, cost 110.36s 
-- test score: 0.21646395205359, cost 91.71s 
-- epoch 24 
-- finished epoch in 138.20s 
-- train score: 0.62604856512141, cost 110.35s 
-- test score: 0.21681649920677, cost 91.67s 
-- epoch 25 
-- finished epoch in 136.76s 
-- train score: 0.64032376747609, cost 110.29s 
-- test score: 0.21188083906222, cost 91.67s 
-- epoch 26 
-- finished epoch in 138.76s 
-- train score: 0.67299484915379, cost 110.38s 
-- test score: 0.21223338621541, cost 91.75s 
-- epoch 27 
-- finished epoch in 136.69s 
-- train score: 0.69418690213392, cost 110.45s 
-- test score: 0.21505376344086, cost 91.74s 
-- epoch 28 
-- finished epoch in 139.11s 
-- train score: 0.69610007358352, cost 111.69s 
-- test score: 0.21523003701745, cost 91.63s 
-- epoch 29 
-- finished epoch in 138.95s 
-- train score: 0.71640912435614, cost 110.41s 
-- test score: 0.20994182971973, cost 91.81s 
-- epoch 30 
-- finished epoch in 137.93s 
-- train score: 0.73289183222958, cost 111.18s 
-- test score: 0.20500616957518, cost 92.34s 
-- epoch 31 
-- finished epoch in 136.69s 
-- train score: 0.74260485651214, cost 110.37s 
-- test score: 0.21699277278336, cost 91.70s 
-- epoch 32 
-- finished epoch in 136.87s 
-- train score: 0.77130242825607, cost 110.23s 
-- test score: 0.20430107526882, cost 91.66s 
-- epoch 33 
-- finished epoch in 139.20s 
-- train score: 0.76247240618102, cost 110.69s 
-- test score: 0.212409659792, cost 91.48s 
-- epoch 34 
-- finished epoch in 138.49s 
-- train score: 0.77586460632818, cost 110.00s 
-- test score: 0.21205711263882, cost 91.40s 
-- epoch 35 
-- finished epoch in 136.64s 
-- train score: 0.7888153053716, cost 110.05s 
-- test score: 0.2065926317645, cost 91.45s 
-- epoch 36 
-- finished epoch in 136.52s 
-- train score: 0.78631346578366, cost 110.05s 
-- test score: 0.20553499030495, cost 92.88s 
-- epoch 37 
-- finished epoch in 136.77s 
-- train score: 0.80426784400294, cost 110.04s 
-- test score: 0.212409659792, cost 91.49s 
-- epoch 38 
-- finished epoch in 137.02s 
-- train score: 0.80044150110375, cost 110.09s 
-- test score: 0.20941300898995, cost 93.91s 
-- epoch 39 
-- finished epoch in 142.22s 
-- train score: 0.81898454746137, cost 111.60s 
-- test score: 0.20817909395382, cost 91.46s 
-- epoch 40 
-- finished epoch in 136.81s 
-- train score: 0.82575423105224, cost 110.05s 
-- test score: 0.20782654680063, cost 91.42s 
-- epoch 41 
-- finished epoch in 139.26s 
-- train score: 0.83473142016188, cost 110.21s 
-- test score: 0.2065926317645, cost 91.55s 
-- epoch 42 
-- finished epoch in 136.92s 
-- train score: 0.83635025754231, cost 110.18s 
-- test score: 0.208531641107, cost 91.54s 
-- epoch 43 
-- finished epoch in 152.26s 
-- train score: 0.84944812362031, cost 110.31s 
-- test score: 0.20042305658382, cost 91.61s 
-- epoch 44 
-- finished epoch in 137.33s 
-- train score: 0.85401030169242, cost 110.29s 
-- test score: 0.19672131147541, cost 91.64s 
-- epoch 45 
-- finished epoch in 140.57s 
-- train score: 0.86475349521707, cost 112.70s 
-- test score: 0.20324343380927, cost 91.55s 
-- epoch 46 
-- finished epoch in 137.26s 
-- train score: 0.85989698307579, cost 110.14s 
-- test score: 0.19901286797109, cost 91.52s 
-- epoch 47 
-- finished epoch in 137.39s 
-- train score: 0.85916114790287, cost 110.07s 
-- test score: 0.20200951877314, cost 91.56s 
-- epoch 48 
-- finished epoch in 138.75s 
-- train score: 0.87093451066961, cost 111.76s 
-- test score: 0.20377225453904, cost 92.80s 
-- epoch 49 
-- finished epoch in 138.26s 
-- train score: 0.87593818984547, cost 110.58s 
-- test score: 0.20518244315177, cost 91.78s 
-- epoch 50 
-- finished epoch in 139.36s 
-- train score: 0.88050036791759, cost 109.98s 
-- test score: 0.20482989599859, cost 91.47s 
-- epoch 51 
-- finished epoch in 136.90s 
-- train score: 0.88668138337013, cost 110.15s 
-- test score: 0.20500616957518, cost 91.53s 
-- epoch 52 
-- finished epoch in 136.80s 
-- train score: 0.88771155261221, cost 110.14s 
-- test score: 0.20289088665609, cost 91.52s 
-- epoch 53 
-- finished epoch in 136.91s 
-- train score: 0.89462840323767, cost 109.98s 
-- test score: 0.19971796227745, cost 91.46s 
-- epoch 54 
-- finished epoch in 138.60s 
-- train score: 0.88520971302428, cost 110.06s 
-- test score: 0.20236206592632, cost 91.38s 
-- epoch 55 
-- finished epoch in 137.18s 
-- train score: 0.89977924944812, cost 111.33s 
-- test score: 0.19619249074564, cost 91.59s 
-- epoch 56 
-- finished epoch in 136.83s 
-- train score: 0.89992641648271, cost 110.22s 
-- test score: 0.19654503789882, cost 91.64s 
-- epoch 57 
-- finished epoch in 137.87s 
-- train score: 0.9037527593819, cost 110.89s 
-- test score: 0.19548739643927, cost 91.69s 
-- epoch 58 
-- finished epoch in 137.03s 
-- train score: 0.91184694628403, cost 110.30s 
-- test score: 0.19531112286268, cost 91.64s 
-- epoch 59 
-- finished epoch in 136.98s 
-- train score: 0.90905077262693, cost 110.34s 
-- test score: 0.20024678300723, cost 91.67s 
-- epoch 60 
-- finished epoch in 137.01s 
-- train score: 0.9177336276674, cost 110.24s 
-- test score: 0.20218579234973, cost 93.20s 
-- epoch 61 
-- finished epoch in 136.94s 
-- train score: 0.91199411331862, cost 110.22s 
-- test score: 0.19866032081791, cost 91.51s 
-- epoch 62 
-- finished epoch in 136.98s 
-- train score: 0.91272994849154, cost 110.35s 
-- test score: 0.196897585052, cost 91.70s 
-- epoch 63 
-- finished epoch in 136.91s 
-- train score: 0.91994113318617, cost 110.39s 
-- test score: 0.19936541512427, cost 91.73s 
-- epoch 64 
-- finished epoch in 138.20s 
-- train score: 0.92288447387785, cost 111.12s 
-- test score: 0.19954168870086, cost 91.45s 
-- epoch 65 
-- finished epoch in 136.86s 
-- train score: 0.92362030905077, cost 110.02s 
-- test score: 0.20024678300723, cost 91.50s 
-- epoch 66 
-- finished epoch in 137.57s 
-- train score: 0.9233259749816, cost 111.73s 
-- test score: 0.19760267935836, cost 92.56s 
-- epoch 67 
-- finished epoch in 138.27s 
-- train score: 0.92877115526122, cost 110.37s 
-- test score: 0.19795522651155, cost 91.62s 
