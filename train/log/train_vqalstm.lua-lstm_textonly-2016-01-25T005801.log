[program started on Mon Jan 25 00:58:01 2016] 
[command line arguments] 
[----------------------] 
-------------------------------------------------------------------------------- 
LSTM for VQA with text only 
-------------------------------------------------------------------------------- 
loading COCOQA datasets 
Append captions with question done. 
Remove determiner done. 
num train = 78736 
num test  = 38948 
-------------------------------------------------------------------------------- 
model configuration 
-------------------------------------------------------------------------------- 
max epochs                = 100 
num params                = 186130 
num compositional params  = 121200 
word vector dim           = 50 
LSTM memory dim           = 150 
LSTM structure            = lstm 
LSTM layers               = 1 
regularization strength   = 1.00e-04 
minibatch size            = 1 
learning rate             = 5.00e-02 
word vector learning rate = 1.00e-01 
dropout                   = true 
cuda                      = true 
image feature dim         = [text only] 
-------------------------------------------------------------------------------- 
Training model 
-------------------------------------------------------------------------------- 
-- epoch 1 
-- finished epoch in 919.81s 
-- train score: 0.38178215809795, cost 621.79s 
-- test score: 0.37406285303482, cost 307.03s 
-- epoch 2 
-- finished epoch in 940.83s 
-- train score: 0.5188096931518, cost 617.81s 
-- test score: 0.50688096949779, cost 305.23s 
-- epoch 3 
-- finished epoch in 903.15s 
-- train score: 0.55744513310303, cost 629.10s 
-- test score: 0.53671562082777, cost 305.19s 
-- epoch 4 
-- finished epoch in 894.51s 
-- train score: 0.57705496850234, cost 619.49s 
-- test score: 0.5519410496046, cost 334.54s 
-- epoch 5 
-- finished epoch in 937.97s 
-- train score: 0.59218146718147, cost 619.11s 
-- test score: 0.55987470473452, cost 304.79s 
-- epoch 6 
-- finished epoch in 892.68s 
-- train score: 0.60104653525706, cost 619.06s 
-- test score: 0.5643165245969, cost 306.02s 
-- epoch 7 
-- finished epoch in 893.58s 
-- train score: 0.60856533224954, cost 635.22s 
-- test score: 0.56896374653384, cost 304.36s 
-- epoch 8 
-- finished epoch in 899.73s 
-- train score: 0.6208595813859, cost 631.47s 
-- test score: 0.5723528807641, cost 319.31s 
-- epoch 9 
-- finished epoch in 941.48s 
-- train score: 0.62799735826052, cost 617.69s 
-- test score: 0.57589606655027, cost 305.09s 
-- epoch 10 
-- finished epoch in 891.83s 
-- train score: 0.63394127209917, cost 669.30s 
-- test score: 0.57730820581288, cost 310.96s 
-- epoch 11 
-- finished epoch in 898.54s 
-- train score: 0.63879292826661, cost 672.93s 
-- test score: 0.5779757625552, cost 305.72s 
-- epoch 12 
-- finished epoch in 890.40s 
-- train score: 0.64873755334282, cost 616.60s 
-- test score: 0.57874602033481, cost 304.59s 
-- epoch 13 
-- finished epoch in 907.60s 
-- train score: 0.65386862426336, cost 616.63s 
-- test score: 0.5812878710075, cost 304.06s 
-- epoch 14 
-- finished epoch in 899.40s 
-- train score: 0.66086669376143, cost 638.15s 
-- test score: 0.58372702064291, cost 305.36s 
-- epoch 15 
-- finished epoch in 914.21s 
-- train score: 0.66518492176387, cost 645.45s 
-- test score: 0.58267433501078, cost 330.68s 
-- epoch 16 
-- finished epoch in 892.49s 
-- train score: 0.66872840885999, cost 620.44s 
-- test score: 0.58629454657492, cost 306.05s 
-- epoch 17 
-- finished epoch in 940.74s 
-- train score: 0.67468502336923, cost 657.75s 
-- test score: 0.58498510834959, cost 305.87s 
-- epoch 18 
-- finished epoch in 894.90s 
-- train score: 0.6811369640317, cost 622.33s 
-- test score: 0.5863972476122, cost 319.80s 
-- epoch 19 
-- finished epoch in 900.15s 
-- train score: 0.68451534241008, cost 616.98s 
-- test score: 0.58850261887645, cost 304.76s 
-- epoch 20 
-- finished epoch in 891.65s 
-- train score: 0.68873196504775, cost 629.34s 
-- test score: 0.58732155694773, cost 305.66s 
-- epoch 21 
-- finished epoch in 896.06s 
-- train score: 0.69306289372079, cost 618.61s 
-- test score: 0.58539591249872, cost 305.51s 
-- epoch 22 
-- finished epoch in 895.76s 
-- train score: 0.69909571225361, cost 618.73s 
-- test score: 0.58778371161549, cost 305.56s 
-- epoch 23 
-- finished epoch in 908.56s 
-- train score: 0.70444269457427, cost 634.89s 
-- test score: 0.58742425798501, cost 323.18s 
-- epoch 24 
-- finished epoch in 942.11s 
-- train score: 0.7082528957529, cost 618.11s 
-- test score: 0.58811748998665, cost 305.24s 
-- epoch 25 
-- finished epoch in 911.45s 
-- train score: 0.71332046332046, cost 633.31s 
-- test score: 0.58837424257985, cost 312.89s 
-- epoch 26 
-- finished epoch in 906.81s 
-- train score: 0.71551767933347, cost 638.80s 
-- test score: 0.58834856732053, cost 347.11s 
-- epoch 27 
-- finished epoch in 971.63s 
-- train score: 0.72045824019508, cost 703.65s 
-- test score: 0.58655129916812, cost 309.18s 
-- epoch 28 
-- finished epoch in 894.45s 
-- train score: 0.72307457833774, cost 625.18s 
-- test score: 0.58606346924104, cost 310.85s 
-- epoch 29 
-- finished epoch in 894.86s 
-- train score: 0.72722769762243, cost 617.29s 
-- test score: 0.58924720139673, cost 304.94s 
-- epoch 30 
-- finished epoch in 890.64s 
-- train score: 0.73112680349522, cost 620.16s 
-- test score: 0.58590941768512, cost 305.02s 
-- epoch 31 
-- finished epoch in 981.35s 
-- train score: 0.73688020727494, cost 616.99s 
-- test score: 0.58737290746637, cost 304.70s 
-- epoch 32 
-- finished epoch in 889.06s 
-- train score: 0.73985216419427, cost 637.25s 
-- test score: 0.58693642805792, cost 347.06s 
-- epoch 33 
-- finished epoch in 900.46s 
-- train score: 0.74366236537289, cost 668.67s 
-- test score: 0.58439457738523, cost 346.08s 
-- epoch 34 
-- finished epoch in 944.06s 
-- train score: 0.74664702296281, cost 700.80s 
-- test score: 0.5871675053918, cost 332.31s 
-- epoch 35 
-- finished epoch in 892.89s 
-- train score: 0.7488823409876, cost 619.10s 
-- test score: 0.58444592790387, cost 305.75s 
-- epoch 36 
-- finished epoch in 895.97s 
-- train score: 0.75308626295468, cost 622.04s 
-- test score: 0.58501078360891, cost 306.05s 
-- epoch 37 
-- finished epoch in 948.31s 
-- train score: 0.75697266815688, cost 645.84s 
-- test score: 0.58539591249872, cost 347.39s 
-- epoch 38 
-- finished epoch in 962.33s 
-- train score: 0.76311979272506, cost 650.78s 
-- test score: 0.58226353086166, cost 305.55s 
-- epoch 39 
-- finished epoch in 1035.40s 
-- train score: 0.76510109733794, cost 652.67s 
-- test score: 0.58457430420047, cost 305.64s 
-- epoch 40 
-- finished epoch in 897.22s 
-- train score: 0.76755232676285, cost 615.56s 
-- test score: 0.58364999486495, cost 338.02s 
-- epoch 41 
-- finished epoch in 1018.39s 
-- train score: 0.76865728510465, cost 618.29s 
-- test score: 0.58254595871418, cost 305.14s 
-- epoch 42 
-- finished epoch in 894.23s 
-- train score: 0.77418207681366, cost 618.95s 
-- test score: 0.58246893293622, cost 305.67s 
-- epoch 43 
-- finished epoch in 893.06s 
-- train score: 0.77199756147125, cost 618.33s 
-- test score: 0.58226353086166, cost 305.43s 
-- epoch 44 
-- finished epoch in 915.15s 
-- train score: 0.77639199349726, cost 615.89s 
-- test score: 0.58300811338195, cost 312.86s 
-- epoch 45 
