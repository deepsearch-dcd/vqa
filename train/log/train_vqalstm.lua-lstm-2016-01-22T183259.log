[program started on Fri Jan 22 18:32:59 2016] 
[command line arguments] 
[----------------------] 
-------------------------------------------------------------------------------- 
LSTM for VQA 
-------------------------------------------------------------------------------- 
loading COCOQA datasets 
Remove determiner done. 
loading features 
num train = 78736 
num test  = 38948 
-------------------------------------------------------------------------------- 
model configuration 
-------------------------------------------------------------------------------- 
max epochs                = 100 
num params                = 2643730 
num compositional params  = 2578800 
word vector dim           = 50 
LSTM memory dim           = 150 
LSTM structure            = lstm 
LSTM layers               = 1 
regularization strength   = 1.00e-04 
minibatch size            = 1 
learning rate             = 5.00e-02 
word vector learning rate = 1.00e-01 
dropout                   = true 
cuda                      = true 
image feature dim         = 4096 
-------------------------------------------------------------------------------- 
Training model 
-------------------------------------------------------------------------------- 
-- epoch 1 
-- finished epoch in 860.04s 
-- train score: 0.20040388132493, cost 686.89s 
-- test score: 0.19654411009551, cost 332.87s 
-- epoch 2 
-- finished epoch in 838.00s 
-- train score: 0.23113950416582, cost 677.91s 
-- test score: 0.22707199342713, cost 333.29s 
-- epoch 3 
-- finished epoch in 839.82s 
-- train score: 0.23757874415769, cost 677.05s 
-- test score: 0.23082058128787, cost 332.46s 
-- epoch 4 
-- finished epoch in 839.78s 
-- train score: 0.25596931517984, cost 679.09s 
-- test score: 0.24360686042929, cost 335.31s 
-- epoch 5 
-- finished epoch in 893.19s 
-- train score: 0.2599573257468, cost 678.11s 
-- test score: 0.24602033480538, cost 336.83s 
-- epoch 6 
-- finished epoch in 838.83s 
-- train score: 0.26912720991668, cost 675.32s 
-- test score: 0.25403101571326, cost 332.61s 
-- epoch 7 
-- finished epoch in 841.24s 
-- train score: 0.27869081487503, cost 678.16s 
-- test score: 0.2586782376502, cost 336.01s 
-- epoch 8 
-- finished epoch in 841.33s 
-- train score: 0.3293664905507, cost 676.61s 
-- test score: 0.30399507035021, cost 332.77s 
-- epoch 9 
-- finished epoch in 838.70s 
-- train score: 0.34776976224345, cost 675.06s 
-- test score: 0.32029886001849, cost 332.25s 
-- epoch 10 
-- finished epoch in 840.43s 
-- train score: 0.35775248933144, cost 673.46s 
-- test score: 0.32386772106398, cost 332.05s 
-- epoch 11 
-- finished epoch in 845.26s 
-- train score: 0.36617303393619, cost 677.39s 
-- test score: 0.32884872137209, cost 334.64s 
-- epoch 12 
-- finished epoch in 843.33s 
-- train score: 0.37371723226986, cost 673.95s 
-- test score: 0.33439457738523, cost 332.74s 
-- epoch 13 
-- finished epoch in 841.38s 
-- train score: 0.38062639707377, cost 677.48s 
-- test score: 0.3362688713156, cost 336.05s 
-- epoch 14 
-- finished epoch in 838.15s 
-- train score: 0.39425421662264, cost 673.28s 
-- test score: 0.3455889904488, cost 337.62s 
-- epoch 15 
-- finished epoch in 846.04s 
-- train score: 0.40924100792522, cost 674.01s 
-- test score: 0.35591044469549, cost 332.60s 
-- epoch 16 
-- finished epoch in 841.53s 
-- train score: 0.43332147937411, cost 674.84s 
-- test score: 0.3759628222245, cost 332.09s 
-- epoch 17 
-- finished epoch in 842.20s 
-- train score: 0.44548872180451, cost 676.90s 
-- test score: 0.38068706993941, cost 333.92s 
-- epoch 18 
-- finished epoch in 839.03s 
-- train score: 0.45590327169275, cost 677.20s 
-- test score: 0.38546266817295, cost 337.37s 
-- epoch 19 
-- finished epoch in 839.15s 
-- train score: 0.46441272099167, cost 675.52s 
-- test score: 0.39044366848105, cost 369.04s 
-- epoch 20 
-- finished epoch in 841.60s 
-- train score: 0.4709662670189, cost 675.80s 
-- test score: 0.39247201396734, cost 332.88s 
-- epoch 21 
-- finished epoch in 832.94s 
-- train score: 0.48353993090835, cost 684.60s 
-- test score: 0.4010989010989, cost 334.91s 
-- epoch 22 
-- finished epoch in 850.20s 
-- train score: 0.49179536679537, cost 679.80s 
-- test score: 0.40287049399199, cost 336.35s 
-- epoch 23 
-- finished epoch in 839.18s 
-- train score: 0.49987299329405, cost 674.43s 
-- test score: 0.40554072096128, cost 333.59s 
-- epoch 24 
-- finished epoch in 840.75s 
-- train score: 0.51141790286527, cost 674.98s 
-- test score: 0.41280681934888, cost 331.62s 
-- epoch 25 
-- finished epoch in 840.51s 
-- train score: 0.51407234301971, cost 680.58s 
-- test score: 0.41231898942179, cost 333.07s 
-- epoch 26 
-- finished epoch in 840.84s 
-- train score: 0.52810658402764, cost 677.38s 
-- test score: 0.42130533018383, cost 333.16s 
-- epoch 27 
-- finished epoch in 837.46s 
-- train score: 0.53225970331233, cost 679.05s 
-- test score: 0.42135668070248, cost 334.84s 
-- epoch 28 
-- finished epoch in 843.23s 
-- train score: 0.53825441983337, cost 672.54s 
-- test score: 0.42867412960871, cost 331.95s 
-- epoch 29 
-- finished epoch in 842.70s 
-- train score: 0.54365220483642, cost 675.04s 
-- test score: 0.43067679983568, cost 334.00s 
-- epoch 30 
-- finished epoch in 836.67s 
-- train score: 0.55611156269051, cost 677.13s 
-- test score: 0.43665913525727, cost 336.07s 
-- epoch 31 
-- finished epoch in 838.99s 
-- train score: 0.56488772607194, cost 677.98s 
-- test score: 0.4393807127452, cost 334.60s 
-- epoch 32 
-- finished epoch in 840.49s 
-- train score: 0.56643720788458, cost 674.07s 
-- test score: 0.43953476430112, cost 331.93s 
-- epoch 33 
-- finished epoch in 838.86s 
-- train score: 0.57907437512701, cost 679.31s 
-- test score: 0.44315497586526, cost 334.46s 
-- epoch 34 
-- finished epoch in 838.10s 
-- train score: 0.58162720991668, cost 672.19s 
-- test score: 0.44549142446339, cost 332.09s 
-- epoch 35 
-- finished epoch in 842.78s 
-- train score: 0.58355771184719, cost 677.22s 
-- test score: 0.44495224401766, cost 333.44s 
-- epoch 36 
-- finished epoch in 842.06s 
-- train score: 0.59351503759398, cost 674.52s 
-- test score: 0.44585087809387, cost 332.49s 
-- epoch 37 
-- finished epoch in 843.39s 
-- train score: 0.59475970331233, cost 680.76s 
-- test score: 0.44757112046832, cost 336.92s 
-- epoch 38 
-- finished epoch in 841.21s 
-- train score: 0.60570768136558, cost 680.12s 
-- test score: 0.45101160521721, cost 338.82s 
-- epoch 39 
-- finished epoch in 845.09s 
-- train score: 0.61410282462914, cost 673.94s 
-- test score: 0.45429803841019, cost 334.49s 
-- epoch 40 
-- finished epoch in 844.21s 
-- train score: 0.61351859378175, cost 675.89s 
-- test score: 0.45121700729177, cost 337.64s 
-- epoch 41 
-- finished epoch in 844.06s 
-- train score: 0.62101198943304, cost 677.20s 
-- test score: 0.45237239396118, cost 332.01s 
-- epoch 42 
-- finished epoch in 842.66s 
-- train score: 0.62925472464946, cost 677.99s 
-- test score: 0.45758447160316, cost 332.13s 
-- epoch 43 
-- finished epoch in 837.41s 
-- train score: 0.63291251778094, cost 683.37s 
-- test score: 0.45586422922872, cost 335.26s 
-- epoch 44 
-- finished epoch in 842.32s 
-- train score: 0.64487654948181, cost 673.69s 
-- test score: 0.45989524494197, cost 336.23s 
-- epoch 45 
-- finished epoch in 839.38s 
-- train score: 0.64681975208291, cost 675.81s 
-- test score: 0.46038307486906, cost 332.68s 
-- epoch 46 
-- finished epoch in 846.49s 
-- train score: 0.64929638284901, cost 680.53s 
-- test score: 0.46066550272158, cost 336.10s 
-- epoch 47 
-- finished epoch in 842.11s 
-- train score: 0.65377971956919, cost 683.24s 
-- test score: 0.4614614357605, cost 335.80s 
-- epoch 48 
-- finished epoch in 838.28s 
-- train score: 0.66692491363544, cost 674.50s 
-- test score: 0.46359248228407, cost 335.77s 
-- epoch 49 
-- finished epoch in 836.70s 
-- train score: 0.66728053241211, cost 676.89s 
-- test score: 0.4647735442128, cost 331.69s 
-- epoch 50 
-- finished epoch in 846.56s 
-- train score: 0.66909672830725, cost 676.21s 
-- test score: 0.46220601828078, cost 335.05s 
-- epoch 51 
-- finished epoch in 839.49s 
-- train score: 0.67500254013412, cost 673.80s 
-- test score: 0.46556947725172, cost 335.47s 
-- epoch 52 
-- finished epoch in 846.16s 
-- train score: 0.67777128632392, cost 681.68s 
-- test score: 0.46408031221115, cost 334.96s 
-- epoch 53 
-- finished epoch in 841.14s 
-- train score: 0.6863950416582, cost 674.13s 
-- test score: 0.46708431755161, cost 333.91s 
-- epoch 54 
-- finished epoch in 845.21s 
-- train score: 0.69125939849624, cost 682.97s 
-- test score: 0.46716134332957, cost 338.19s 
-- epoch 55 
-- finished epoch in 835.30s 
-- train score: 0.69473938223938, cost 673.28s 
-- test score: 0.46723836910753, cost 332.91s 
-- epoch 56 
-- finished epoch in 837.39s 
-- train score: 0.69724141434668, cost 674.08s 
-- test score: 0.4661856834754, cost 332.93s 
-- epoch 57 
-- finished epoch in 840.42s 
-- train score: 0.6982955700061, cost 673.74s 
-- test score: 0.46798295162781, cost 332.59s 
-- epoch 58 
-- finished epoch in 842.46s 
-- train score: 0.70688122332859, cost 672.14s 
-- test score: 0.47008832289206, cost 332.53s 
-- epoch 59 
-- finished epoch in 837.12s 
-- train score: 0.71253302174355, cost 680.38s 
-- test score: 0.46780322481257, cost 332.71s 
-- epoch 60 
-- finished epoch in 837.85s 
-- train score: 0.71704175980492, cost 672.60s 
-- test score: 0.46944644140906, cost 332.93s 
-- epoch 61 
-- finished epoch in 839.95s 
-- train score: 0.72130918512497, cost 681.58s 
-- test score: 0.47114100852419, cost 334.31s 
-- epoch 62 
-- finished epoch in 838.43s 
-- train score: 0.71880715301768, cost 679.68s 
-- test score: 0.46849645681421, cost 331.73s 
-- epoch 63 
-- finished epoch in 838.55s 
-- train score: 0.72217283072546, cost 675.27s 
-- test score: 0.47019102392934, cost 332.19s 
-- epoch 64 
-- finished epoch in 837.71s 
-- train score: 0.72932330827068, cost 680.12s 
-- test score: 0.47019102392934, cost 338.19s 
-- epoch 65 
-- finished epoch in 838.15s 
-- train score: 0.73674049989839, cost 673.06s 
-- test score: 0.47139776111739, cost 332.35s 
-- epoch 66 
-- finished epoch in 836.29s 
-- train score: 0.73956004877058, cost 680.60s 
-- test score: 0.46954914244634, cost 335.81s 
-- epoch 67 
-- finished epoch in 839.32s 
-- train score: 0.73962355212355, cost 672.25s 
-- test score: 0.47147478689535, cost 335.74s 
-- epoch 68 
-- finished epoch in 838.21s 
-- train score: 0.74508484047958, cost 676.75s 
-- test score: 0.47270719934271, cost 335.01s 
-- epoch 69 
-- finished epoch in 839.52s 
-- train score: 0.74690103637472, cost 672.61s 
-- test score: 0.47386258601212, cost 332.30s 
-- epoch 70 
-- finished epoch in 840.80s 
-- train score: 0.75339107904897, cost 677.40s 
-- test score: 0.47283557563931, cost 331.77s 
-- epoch 71 
-- finished epoch in 845.30s 
-- train score: 0.75671865474497, cost 677.57s 
-- test score: 0.47316935401048, cost 331.48s 
-- epoch 72 
-- finished epoch in 840.18s 
-- train score: 0.76419934972567, cost 673.86s 
-- test score: 0.47517202423744, cost 333.68s 
-- epoch 73 
-- finished epoch in 839.47s 
-- train score: 0.76502489331437, cost 675.82s 
-- test score: 0.47404231282736, cost 331.74s 
-- epoch 74 
-- finished epoch in 835.85s 
-- train score: 0.76793334688072, cost 672.80s 
-- test score: 0.47324637978844, cost 333.29s 
-- epoch 75 
-- finished epoch in 838.02s 
-- train score: 0.77477900833164, cost 675.44s 
-- test score: 0.47386258601212, cost 333.24s 
-- epoch 76 
-- finished epoch in 844.61s 
-- train score: 0.77945285511075, cost 671.09s 
-- test score: 0.47709766868645, cost 331.32s 
-- epoch 77 
-- finished epoch in 837.54s 
-- train score: 0.78004978662873, cost 672.56s 
-- test score: 0.47653281298141, cost 333.56s 
-- epoch 78 
-- finished epoch in 836.12s 
-- train score: 0.78420290591343, cost 672.10s 
-- test score: 0.47571120468317, cost 331.71s 
-- epoch 79 
-- finished epoch in 833.89s 
-- train score: 0.78791150172729, cost 673.07s 
-- test score: 0.47406798808668, cost 332.41s 
-- epoch 80 
-- finished epoch in 842.42s 
-- train score: 0.79262345051819, cost 676.07s 
-- test score: 0.47555715312725, cost 333.35s 
-- epoch 81 
-- finished epoch in 840.02s 
-- train score: 0.79273775655355, cost 674.11s 
-- test score: 0.47542877683065, cost 334.16s 
-- epoch 82 
-- finished epoch in 840.13s 
-- train score: 0.78921967079862, cost 675.63s 
-- test score: 0.47745712231694, cost 332.48s 
-- epoch 83 
-- finished epoch in 845.95s 
-- train score: 0.7992277992278, cost 678.18s 
-- test score: 0.47961384409983, cost 331.71s 
-- epoch 84 
-- finished epoch in 843.46s 
-- train score: 0.80322851046535, cost 676.23s 
-- test score: 0.47748279757626, cost 331.90s 
-- epoch 85 
-- finished epoch in 840.62s 
-- train score: 0.80866439748019, cost 676.92s 
-- test score: 0.47707199342713, cost 332.29s 
-- epoch 86 
-- finished epoch in 843.32s 
-- train score: 0.8055908351961, cost 673.38s 
-- test score: 0.4748639211256, cost 333.51s 
-- epoch 87 
-- finished epoch in 838.85s 
-- train score: 0.81225868725869, cost 679.59s 
-- test score: 0.47789360172538, cost 337.39s 
-- epoch 88 
-- finished epoch in 839.49s 
-- train score: 0.81219518390571, cost 673.66s 
-- test score: 0.47625038512889, cost 334.39s 
-- epoch 89 
-- finished epoch in 835.18s 
-- train score: 0.81509093680146, cost 674.99s 
-- test score: 0.47758549861354, cost 335.25s 
-- epoch 90 
-- finished epoch in 841.26s 
-- train score: 0.82132696606381, cost 674.40s 
-- test score: 0.47627606038821, cost 331.51s 
-- epoch 91 
-- finished epoch in 840.68s 
-- train score: 0.82175878886405, cost 675.63s 
-- test score: 0.47750847283558, cost 334.79s 
-- epoch 92 
-- finished epoch in 835.30s 
-- train score: 0.82238112172323, cost 673.63s 
-- test score: 0.47653281298141, cost 332.15s 
-- epoch 93 
-- finished epoch in 833.59s 
-- train score: 0.82122536069904, cost 676.34s 
-- test score: 0.47619903461025, cost 333.35s 
-- epoch 94 
-- finished epoch in 846.36s 
-- train score: 0.82988721804511, cost 672.04s 
-- test score: 0.47714901920509, cost 332.32s 
-- epoch 95 
-- finished epoch in 839.88s 
-- train score: 0.82777890672628, cost 674.77s 
-- test score: 0.47730307076101, cost 334.09s 
-- epoch 96 
-- finished epoch in 839.88s 
-- train score: 0.83147480186954, cost 675.65s 
-- test score: 0.47601930779501, cost 332.05s 
-- epoch 97 
-- finished epoch in 840.65s 
-- train score: 0.83478967689494, cost 678.52s 
-- test score: 0.47586525623909, cost 335.84s 
-- epoch 98 
-- finished epoch in 835.55s 
-- train score: 0.82897276976224, cost 676.24s 
-- test score: 0.47542877683065, cost 333.26s 
-- epoch 99 
-- finished epoch in 837.48s 
-- train score: 0.83345610648242, cost 682.09s 
-- test score: 0.47530040053405, cost 334.80s 
-- epoch 100 
-- finished epoch in 844.77s 
-- train score: 0.8329607803292, cost 679.46s 
-- test score: 0.47784225120674, cost 337.04s 
finished training in 185185.50s 
best dev score is: 0.47961384409983 
writing model to ./done/vqalstm-COCOQA-lstm.l1.d150.e83.c1-2016-01-24T215931.t7 
