[program started on Tue Dec  8 01:31:50 2015] 
[command line arguments] 
[----------------------] 
-------------------------------------------------------------------------------- 
LSTM for VQA 
-------------------------------------------------------------------------------- 
loading datasets 
process data at: /home/deepnet/lyt/vqa/dataset/data/DAQUAR/DAQUAR-ALL 
Process_all_totable ... 
load train set ... 
total lines: 13590 
max length: 31 min length: 7 
#images: 6795 #questions: 6795 #answers: 6795 
normalize image: 6808 
load test set ... 
total lines: 11346 
max length: 28 min length: 7 
#images: 5673 #questions: 5673 #answers: 5673 
normalize image: 5681 
build vocabulary ... 
word vocabulary: 856 
answer vocabulary: 969 
image vocabulary: 1447 
num train = 6795 
num test  = 5673 
loading features 
-------------------------------------------------------------------------------- 
model configuration 
-------------------------------------------------------------------------------- 
max epochs                = 70 
num params                = 867519 
num compositional params  = 721200 
word vector dim           = 50 
LSTM memory dim           = 150 
LSTM structure            = rlstm 
LSTM layers               = 1 
regularization strength   = 1.00e-04 
minibatch size            = 1 
learning rate             = 5.00e-02 
word vector learning rate = 1.00e-01 
dropout                   = true 
cuda                      = true 
image feature dim         = 1000 
-------------------------------------------------------------------------------- 
Training model 
-------------------------------------------------------------------------------- 
-- epoch 1 
-- finished epoch in 72.89s 
-- train score: 0.080500367917586, cost 85.18s 
-- test score: 0.093953816322933, cost 70.82s 
-- epoch 2 
-- finished epoch in 71.35s 
-- train score: 0.10036791758646, cost 87.77s 
-- test score: 0.10911334390975, cost 72.25s 
-- epoch 3 
-- finished epoch in 79.18s 
-- train score: 0.12877115526122, cost 86.46s 
-- test score: 0.13185263528997, cost 72.84s 
-- epoch 4 
-- finished epoch in 70.79s 
-- train score: 0.14407652685798, cost 86.72s 
-- test score: 0.14401551207474, cost 70.48s 
-- epoch 5 
-- finished epoch in 70.70s 
-- train score: 0.15570272259014, cost 84.80s 
-- test score: 0.15494447382337, cost 70.49s 
-- epoch 6 
-- finished epoch in 73.73s 
-- train score: 0.17512877115526, cost 85.83s 
-- test score: 0.15459192667019, cost 70.61s 
-- epoch 7 
-- finished epoch in 70.67s 
-- train score: 0.18425312729948, cost 84.72s 
-- test score: 0.16375815265292, cost 70.48s 
-- epoch 8 
-- finished epoch in 70.08s 
-- train score: 0.20912435614422, cost 84.74s 
-- test score: 0.17644985016746, cost 70.52s 
-- epoch 9 
-- finished epoch in 70.15s 
-- train score: 0.22649006622517, cost 84.60s 
-- test score: 0.19002291556496, cost 70.52s 
-- epoch 10 
-- finished epoch in 70.05s 
-- train score: 0.24267844002943, cost 84.78s 
-- test score: 0.19707385862859, cost 70.48s 
-- epoch 11 
-- finished epoch in 70.04s 
-- train score: 0.2532744665195, cost 85.51s 
-- test score: 0.19566367001586, cost 72.27s 
-- epoch 12 
-- finished epoch in 70.78s 
-- train score: 0.27740986019132, cost 84.63s 
-- test score: 0.20148069804336, cost 71.74s 
-- epoch 13 
-- finished epoch in 70.01s 
-- train score: 0.29506990434143, cost 84.90s 
-- test score: 0.21082319760268, cost 70.59s 
-- epoch 14 
-- finished epoch in 70.14s 
-- train score: 0.31258278145695, cost 84.69s 
-- test score: 0.2143486691345, cost 70.55s 
-- epoch 15 
-- finished epoch in 69.96s 
-- train score: 0.33495217071376, cost 84.84s 
-- test score: 0.22245725365768, cost 70.60s 
-- epoch 16 
-- finished epoch in 70.67s 
-- train score: 0.35688005886681, cost 84.69s 
-- test score: 0.20958928256654, cost 70.46s 
-- epoch 17 
-- finished epoch in 70.08s 
-- train score: 0.37130242825607, cost 84.70s 
-- test score: 0.21664022563018, cost 70.51s 
-- epoch 18 
-- finished epoch in 70.14s 
-- train score: 0.40338484179544, cost 84.65s 
-- test score: 0.21205711263882, cost 70.53s 
-- epoch 19 
-- finished epoch in 70.07s 
-- train score: 0.41854304635762, cost 84.75s 
-- test score: 0.21646395205359, cost 70.47s 
-- epoch 20 
-- finished epoch in 70.05s 
-- train score: 0.43944076526858, cost 84.69s 
-- test score: 0.216287678477, cost 70.48s 
-- epoch 21 
-- finished epoch in 69.99s 
-- train score: 0.46887417218543, cost 84.73s 
-- test score: 0.21593513132381, cost 70.50s 
-- epoch 22 
-- finished epoch in 70.01s 
-- train score: 0.47814569536424, cost 84.79s 
-- test score: 0.22157588577472, cost 70.55s 
-- epoch 23 
-- finished epoch in 70.14s 
-- train score: 0.50566593083149, cost 84.71s 
-- test score: 0.21875550854927, cost 70.42s 
-- epoch 24 
-- finished epoch in 69.99s 
-- train score: 0.51994113318617, cost 84.74s 
-- test score: 0.22157588577472, cost 70.52s 
-- epoch 25 
-- finished epoch in 70.10s 
-- train score: 0.53789551140545, cost 84.58s 
-- test score: 0.21752159351313, cost 70.46s 
-- epoch 26 
-- finished epoch in 70.05s 
-- train score: 0.5570272259014, cost 84.76s 
-- test score: 0.21857923497268, cost 70.50s 
-- epoch 27 
-- finished epoch in 70.02s 
-- train score: 0.58837380426784, cost 84.70s 
-- test score: 0.21593513132381, cost 70.46s 
-- epoch 28 
-- finished epoch in 70.03s 
-- train score: 0.58660779985283, cost 84.72s 
-- test score: 0.22298607438745, cost 72.20s 
-- epoch 29 
-- finished epoch in 70.20s 
-- train score: 0.61280353200883, cost 84.71s 
-- test score: 0.22245725365768, cost 70.54s 
-- epoch 30 
-- finished epoch in 70.05s 
-- train score: 0.63208241353937, cost 84.95s 
-- test score: 0.22051824431518, cost 70.60s 
-- epoch 31 
-- finished epoch in 69.99s 
-- train score: 0.63708609271523, cost 84.84s 
-- test score: 0.22333862154063, cost 70.59s 
-- epoch 32 
-- finished epoch in 69.95s 
-- train score: 0.67152317880795, cost 84.89s 
-- test score: 0.2065926317645, cost 70.56s 
-- epoch 33 
-- finished epoch in 69.94s 
-- train score: 0.68005886681383, cost 84.88s 
-- test score: 0.22104706504495, cost 70.67s 
-- epoch 34 
-- finished epoch in 69.97s 
-- train score: 0.68697571743929, cost 84.87s 
-- test score: 0.21152829190904, cost 70.56s 
-- epoch 35 
-- finished epoch in 70.00s 
-- train score: 0.70331125827815, cost 84.84s 
-- test score: 0.21205711263882, cost 70.61s 
-- epoch 36 
-- finished epoch in 70.13s 
-- train score: 0.71272994849154, cost 84.77s 
-- test score: 0.21417239555791, cost 70.56s 
-- epoch 37 
-- finished epoch in 69.99s 
-- train score: 0.70272259013981, cost 84.75s 
-- test score: 0.212409659792, cost 70.53s 
-- epoch 38 
-- finished epoch in 70.16s 
-- train score: 0.73245033112583, cost 84.76s 
-- test score: 0.216287678477, cost 70.68s 
-- epoch 39 
-- finished epoch in 70.13s 
-- train score: 0.74554819720383, cost 84.68s 
-- test score: 0.21258593336859, cost 70.53s 
-- epoch 40 
-- finished epoch in 70.01s 
-- train score: 0.74746136865342, cost 84.72s 
-- test score: 0.21258593336859, cost 70.42s 
-- epoch 41 
-- finished epoch in 70.00s 
-- train score: 0.7551140544518, cost 84.80s 
-- test score: 0.20588753745814, cost 70.51s 
-- epoch 42 
-- finished epoch in 70.10s 
-- train score: 0.77306843267108, cost 84.62s 
-- test score: 0.20817909395382, cost 70.51s 
-- epoch 43 
-- finished epoch in 70.03s 
-- train score: 0.7766004415011, cost 84.82s 
-- test score: 0.20729772607086, cost 70.71s 
-- epoch 44 
-- finished epoch in 70.89s 
-- train score: 0.78734363502575, cost 84.75s 
-- test score: 0.21258593336859, cost 72.07s 
-- epoch 45 
-- finished epoch in 70.21s 
-- train score: 0.786902133922, cost 84.60s 
-- test score: 0.21258593336859, cost 70.49s 
-- epoch 46 
-- finished epoch in 70.07s 
-- train score: 0.80338484179544, cost 84.73s 
-- test score: 0.20800282037723, cost 70.48s 
-- epoch 47 
-- finished epoch in 70.01s 
-- train score: 0.79852832965416, cost 84.69s 
-- test score: 0.20430107526882, cost 70.50s 
-- epoch 48 
-- finished epoch in 70.03s 
-- train score: 0.80323767476085, cost 84.70s 
-- test score: 0.21099947117927, cost 71.95s 
-- epoch 49 
-- finished epoch in 70.05s 
-- train score: 0.80618101545254, cost 84.67s 
-- test score: 0.21276220694518, cost 72.41s 
-- epoch 50 
-- finished epoch in 71.29s 
-- train score: 0.82178072111847, cost 85.58s 
-- test score: 0.20800282037723, cost 70.33s 
-- epoch 51 
-- finished epoch in 70.18s 
-- train score: 0.82958057395143, cost 84.77s 
-- test score: 0.20624008461132, cost 70.29s 
-- epoch 52 
-- finished epoch in 70.11s 
-- train score: 0.83311258278146, cost 84.50s 
-- test score: 0.20112815089018, cost 70.27s 
-- epoch 53 
-- finished epoch in 70.06s 
-- train score: 0.84782928623988, cost 84.49s 
-- test score: 0.20817909395382, cost 70.29s 
-- epoch 54 
-- finished epoch in 70.26s 
-- train score: 0.84606328182487, cost 84.40s 
-- test score: 0.20042305658382, cost 70.31s 
-- epoch 55 
-- finished epoch in 70.05s 
-- train score: 0.84797645327447, cost 84.41s 
-- test score: 0.20236206592632, cost 70.27s 
-- epoch 56 
-- finished epoch in 70.07s 
-- train score: 0.85298013245033, cost 84.46s 
-- test score: 0.20888418826018, cost 70.29s 
-- epoch 57 
-- finished epoch in 70.10s 
-- train score: 0.85504047093451, cost 84.44s 
-- test score: 0.1988365943945, cost 70.25s 
-- epoch 58 
-- finished epoch in 70.12s 
-- train score: 0.86460632818249, cost 84.49s 
-- test score: 0.20412480169223, cost 70.30s 
-- epoch 59 
-- finished epoch in 70.14s 
-- train score: 0.85150846210449, cost 84.49s 
-- test score: 0.20518244315177, cost 70.30s 
-- epoch 60 
-- finished epoch in 70.04s 
-- train score: 0.86666666666667, cost 84.49s 
-- test score: 0.20236206592632, cost 71.39s 
-- epoch 61 
-- finished epoch in 70.06s 
-- train score: 0.87520235467255, cost 84.44s 
-- test score: 0.19548739643927, cost 70.26s 
-- epoch 62 
-- finished epoch in 70.02s 
-- train score: 0.88108903605592, cost 84.39s 
-- test score: 0.19936541512427, cost 70.22s 
-- epoch 63 
-- finished epoch in 70.06s 
-- train score: 0.87888153053716, cost 84.41s 
-- test score: 0.20183324519655, cost 70.19s 
-- epoch 64 
-- finished epoch in 70.15s 
-- train score: 0.87829286239882, cost 84.25s 
-- test score: 0.20148069804336, cost 70.23s 
-- epoch 65 
-- finished epoch in 70.05s 
-- train score: 0.88550404709345, cost 84.43s 
-- test score: 0.20183324519655, cost 70.24s 
-- epoch 66 
-- finished epoch in 79.26s 
-- train score: 0.88712288447388, cost 86.91s 
-- test score: 0.19055173629473, cost 70.43s 
-- epoch 67 
-- finished epoch in 70.24s 
-- train score: 0.88962472406181, cost 84.44s 
-- test score: 0.19231447206064, cost 70.39s 
-- epoch 68 
-- finished epoch in 70.07s 
-- train score: 0.89580573951435, cost 84.57s 
-- test score: 0.19337211352018, cost 70.34s 
-- epoch 69 
-- finished epoch in 70.13s 
-- train score: 0.89683590875644, cost 84.52s 
-- test score: 0.196897585052, cost 70.35s 
-- epoch 70 
-- finished epoch in 70.23s 
-- train score: 0.89860191317145, cost 84.51s 
-- test score: 0.19513484928609, cost 70.37s 
finished training in 15823.46s 
best dev score is: 0.22333862154063 
writing model to ./done/vqalstm-rlstm.l1.d150.e31.c1-2015-12-08T055534.t7 
